
<!DOCTYPE html PUBLIC
  "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml" lang="en">

    
    
    
    
    


<head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />

    
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />

    
        <base href="http://crisewing.com/cover/++contextportlets++ContentWellPortlets.BelowPortletManager3/open-source-posts" /><!--[if lt IE 7]></base><![endif]-->
    

    
        <meta content="2011/04/01 - " name="DC.date.valid_range" />
<link rel="kss-base-url" href="http://crisewing.com/cover/++contextportlets++ContentWellPortlets.BelowPortletManager3/open-source-posts/" />

  
    <link rel="stylesheet" type="text/css" href="http://crisewing.com/portal_css/crisewing.com%20Theme/base-cachekey-6a4288b1f5ff58cb412d24a5d7699aed.css" />
        <!--[if lt IE 8]>    
    
    <link rel="stylesheet" type="text/css" media="screen" href="http://crisewing.com/portal_css/crisewing.com%20Theme/IEFixes-cachekey-9a1e4208c06a6186371efdfcf3c964e1.css" />
        <![endif]-->
    
    <style type="text/css" media="all">@import url(http://crisewing.com/portal_css/crisewing.com%20Theme/resourceContentWellPortlets.stylesContentWellPortlets-cachekey-ac0e6153e4d00db59895d2ab03124ca6.css);</style>
    <link rel="stylesheet" type="text/css" media="screen" href="http://crisewing.com/portal_css/crisewing.com%20Theme/resourcejquery-ui-themessunburstjqueryui-cachekey-a018f472896b20488a2ad02a2dca9359.css" />
    <style type="text/css">@import url(http://crisewing.com/portal_css/crisewing.com%20Theme/resourcecollective.flowplayer.cssflowplayer-cachekey-1f0ec8cd6776345992478af55d55d5e2.css);</style>
    <link rel="stylesheet" type="text/css" media="all" href="http://crisewing.com/portal_css/crisewing.com%20Theme/ploneCustom-cachekey-8ee8fc1cdd61211ec52a0f8181b78ed7.css" />

  
    <link rel="kinetic-stylesheet" type="text/css" href="http://crisewing.com/portal_kss/crisewing.com%20Theme/resourcetinymce.ksstinymce-cachekey-b6bfc5c09a03b431f201c86a1359995a.kss" />
    <link rel="kinetic-stylesheet" type="text/css" href="http://crisewing.com/portal_kss/crisewing.com%20Theme/at-cachekey-cc70007125bd046aa0c600b617cb1d7e.kss" />
  
    <script type="text/javascript" src="http://crisewing.com/portal_javascripts/crisewing.com%20Theme/jquery-cachekey-3d3aee2c96dd957234da67d45127b287.js"></script>
       <!--[if lt IE 8]>
     
    <script type="text/javascript" src="http://crisewing.com/portal_javascripts/crisewing.com%20Theme/iefixes-cachekey-42597b17d0273334e8607aa5425f69e4.js"></script>
       <![endif]-->
     
    <script type="text/javascript" src="http://crisewing.com/portal_javascripts/crisewing.com%20Theme/collective.js.jqueryui.custom.min-cachekey-47bebbba21dbd85bd82204b3588251c6.js"></script>


<title>Open Source Posts &mdash; CrisEwing.com</title>
        

    <link rel="shortcut icon" type="image/x-icon" href="http://crisewing.com/favicon.ico" />
    <link rel="apple-touch-icon" href="http://crisewing.com/touch_icon.png" />


<link rel="alternate" href="http://crisewing.com/cover/++contextportlets++ContentWellPortlets.BelowPortletManager3/open-source-posts/atom.xml" title="Atom 2005" type="application/atom+xml" />
<link rel="alternate" href="http://crisewing.com/cover/++contextportlets++ContentWellPortlets.BelowPortletManager3/open-source-posts/feed.rdf" title="RDF 1.0" type="application/rdf+xml" />
<link rel="alternate" href="http://crisewing.com/cover/++contextportlets++ContentWellPortlets.BelowPortletManager3/open-source-posts/feed11.rdf" title="RDF 1.1" type="application/rdf+xml" />
<link rel="alternate" href="http://crisewing.com/cover/++contextportlets++ContentWellPortlets.BelowPortletManager3/open-source-posts/rss.xml" title="RSS 1.0" type="application/rss+xml" />
<link rel="alternate" href="http://crisewing.com/cover/++contextportlets++ContentWellPortlets.BelowPortletManager3/open-source-posts/itunes.xml" title="RSS 2.0" type="application/rss+xml" />

<script type="text/javascript">
        jQuery(function($){
            $.datepicker.setDefaults(
                jQuery.extend($.datepicker.regional[''],
                {dateFormat: 'mm/dd/yy'}));
        });
        </script>

    <link rel="home" href="http://crisewing.com" title="Front page" />

    <link rel="contents" href="http://crisewing.com/sitemap" title="Site Map" />






    <link rel="search" href="http://crisewing.com/search_form" title="Search this site" />



        
        
        
        
        

        <meta name="viewport" content="width=device-width; initial-scale=0.6666; maximum-scale=1.0; minimum-scale=0.6666" />
        <meta name="generator" content="Plone - http://plone.org" />
    
</head>

<body class="template-full_feed portaltype-collage site-Plone section-cover" dir="ltr">

<div id="visual-portal-wrapper">

        <div id="portal-top" class="row">
<div class="cell width-full position-0">
            <div id="portal-header">
    <p class="hiddenStructure">
  <a accesskey="2" href="http://crisewing.com/cover/++contextportlets++ContentWellPortlets.BelowPortletManager3/open-source-posts/full_feed#content">Skip to content.</a> |

  <a accesskey="6" href="http://crisewing.com/cover/++contextportlets++ContentWellPortlets.BelowPortletManager3/open-source-posts/full_feed#portal-globalnav">Skip to navigation</a>
</p>

<div id="portal-personaltools-wrapper">

<h5 class="hiddenStructure">Personal tools</h5>



<dl class="actionMenu deactivated" id="portal-personaltools">
  <dt id="anon-personalbar">
    
        <a href="http://crisewing.com/login" id="personaltools-login">Log in</a>
    
  </dt>
</dl>

</div>



<div id="portal-searchbox">
    <form name="searchform" id="searchGadget_form" action="http://crisewing.com/search">

        <div class="LSBox">
        <label class="hiddenStructure" for="searchGadget">Search Site</label>

        <input name="SearchableText" type="text" size="18" title="Search Site" accesskey="4" class="searchField inputLabel" id="searchGadget" />

        <input class="searchButton" type="submit" value="Search" />

        <div class="searchSection">
            <input id="searchbox_currentfolder_only" class="noborder" type="checkbox" name="path" value="/Plone/cover/++contextportlets++ContentWellPortlets.BelowPortletManager3" />
            <label for="searchbox_currentfolder_only" style="cursor: pointer">
                only in current section
            </label>
        </div>

        <div class="LSResult" id="LSResult" style=""><div class="LSShadow" id="LSShadow"></div></div>
        </div>
    </form>

    <div id="portal-advanced-search" class="hiddenStructure">
        <a href="http://crisewing.com/search_form" accesskey="5">
            Advanced Search&hellip;
        </a>
    </div>

</div>

<a id="portal-logo" title="CrisEwing.com" accesskey="1" href="http://crisewing.com">
    <img src="http://crisewing.com/logo.png" alt="CrisEwing.com" title="CrisEwing.com" height="63" width="238" /></a>


    <h5 class="hiddenStructure">Sections</h5>

    <ul id="portal-globalnav"><li id="portaltab-index_html" class="selected"><a href="http://crisewing.com" title="">Home</a></li><li id="portaltab-dev" class="plain"><a href="http://crisewing.com/dev" title="What can we do for you?">Development</a></li><li id="portaltab-edu" class="plain"><a href="http://crisewing.com/edu" title="What do you want to learn?">Training</a></li><li id="portaltab-about" class="plain"><a href="http://crisewing.com/about" title="Who am I?">About</a></li><li id="portaltab-blog" class="plain"><a href="http://crisewing.com/blog" title="Writings about open source software, programming, teaching and life in general">Blog</a></li></ul>

</div>


    <div id="portlets-in-header" class="row">
         
         
    </div>

    


</div>
        </div>
    <div id="portal-columns" class="row">

        <div id="portal-column-content" class="cell width-full position-0">

            <div id="viewlet-above-content"><div id="portal-breadcrumbs">

    <span id="breadcrumbs-you-are-here">You
are here:</span>
    <span id="breadcrumbs-home">
        <a href="http://crisewing.com">Home</a>
        
    </span>

</div>

<div id="portlets-above" class="row">
    
    
</div>

</div>

            
                <div class="">

                    

                    

    <dl class="portalMessage info" id="kssPortalMessage" style="display:none">
        <dt>Info</dt>
        <dd></dd>
    </dl>



                    
                        <div id="content">

                            

                            

    

    <h1 class="documentFirstHeading">Open Source Posts</h1>

    


    

    <div class="feedEntry">

        <a href="http://adpgtech.blogspot.com/2015/02/i-feel-so-proud.html" title="Andrew Dunstan: I feel so proud :-)">
            <h2>Andrew Dunstan: I feel so proud :-)</h2>
        </a>

        <p class="discreet">
            
            
                  From Planet PostgreSQL.
            
            
                Published on <span name="publication_time">Feb 16, 2015</span>.
            
        </p>

        <div class="separator" style="clear: both; text-align: center;"><a href="http://1.bp.blogspot.com/-_BVhZvJo6wo/VOIfaqULngI/AAAAAAAAASo/osvVT5Oqkfk/s1600/mongo-bug-jsonb-fix.jpg" style="margin-left: 1em; margin-right: 1em;"><img border="0" height="320" src="http://1.bp.blogspot.com/-_BVhZvJo6wo/VOIfaqULngI/AAAAAAAAASo/osvVT5Oqkfk/s1600/mongo-bug-jsonb-fix.jpg" width="209" /></a></div><br />
    </div>
    <div class="feedEntry">

        <a href="http://blog.taadeem.net///english/2015/02/16/Introducing_PostgreSQL_Dashboard" title="damien clochard: Introducing PostgreSQL Dashboard">
            <h2>damien clochard: Introducing PostgreSQL Dashboard</h2>
        </a>

        <p class="discreet">
            
            
                  From Planet PostgreSQL.
            
            
                Published on <span name="publication_time">Feb 16, 2015</span>.
            
        </p>

        <h2 id="a-real-time-monitoring-screen-based-on-dashing-and-sinatra">A real-time monitoring screen based on Dashing and Sinatra</h2>

<p>PostgreSQL Dashboard is simple monitoring tool that provides a live activity report of a PostgreSQL instance.</p>

<!-- More -->

<p><img alt="" src="https://raw.githubusercontent.com/daamien/pgDashboard/master/public/pgdashboard.screenshot2.png" /></p>

<p>It is designed to be displayed on a large screen in a monitoring room or an open space office. The current dashboard is currently composed of 5 widgets :</p>

<ul>
  <li>General Info : Version, number of host databases, etc.</li>
  <li>Hit Ratio : The % of data found in cache</li>
  <li>Buffers : The number of new buffers allocated</li>
  <li>Queries : The number of active queries currently running of the instance</li>
  <li>Twitter : A glimpse of the #PostgreSQL feed</li>
</ul>

<h2 id="extensibility">Extensibility</h2>

<p>Adding a new widget should be fairly easy. This tool is designed so that you can write a custom widget to display the stats you find relevant or a dynamic graph on some “business logic” valuation.</p>

<p>The layout is also entirely flexible. You can easily drag’n’drop any widget to put it wherever you want on the screen. And HTML code of the dashboard can be modified for specific needs, such as specific screen dimensions.</p>

<h2 id="links--credits">Links &amp; Credits</h2>

<p>Some parts of this tool are based on the work done on other PostgreSQL tools, especially <a href="https://github.com/gleu/pgstats">pgstats</a> and <a href="http://pgcluu.darold.net/">pgcluu</a></p>

<p>PostgreSQL Dashboard is an open project distributed under the PostgreSQL licence. Any contribution to build a better tool is welcome. You just have to send your ideas, features requests or patches using the GitHub tools.</p>

<p><strong>Links :</strong></p>

<ul>
  <li>website: <a href="http://blog.taadeem.net/feed.planetpg.xml">http://daamien.github.io/PostgreSQL-Dashboard/</a></li>
  <li>code: <a href="http://blog.taadeem.net/feed.planetpg.xml">https://github.com/daamien/PostgreSQL-Dashboard</a></li>
</ul>
    </div>
    <div class="feedEntry">

        <a href="http://www.databasesoup.com/2015/02/running-with-scissors-mode.html" title="Josh Berkus: Running with scissors mode">
            <h2>Josh Berkus: Running with scissors mode</h2>
        </a>

        <p class="discreet">
            
            
                  From Planet PostgreSQL.
            
            
                Published on <span name="publication_time">Feb 15, 2015</span>.
            
        </p>

        <a href="https://www.flickr.com/photos/gavinmroy/4638958958" title="DBAs Running with Scissors by Gavin M. Roy, on Flickr"><img alt="DBAs Running with Scissors" height="333" src="https://farm5.staticflickr.com/4006/4638958958_80706ae8cc.jpg" width="500" /></a><br /><br />Based on some comments in my<a href="http://www.databasesoup.com/2015/02/in-memory-is-not-feature-its-bug.html"> post about "in-memory" databases</a>, I realized that my post about running Postgres without disk sync was no longer available on Database Soup.&nbsp; So I'm reposting the instructions here.<br /><br />Running PostgreSQL this way was christened "running with scissors mode" by Gavin Roy, because you're operating completely without crash-safety; if something happens to the server, even a power fluctuation, your database contents are untrustworthy and may be corrupt.&nbsp; However, it can be a useful way to run Postgres for extra, read-only replicas used strictly for load-balancing, or if what you're loading into Postgres is completely disposable/replaceable.<br /><br />Note that these settings do not, in fact, disable all disk writes.&nbsp; What they do instead is minimize disk writes, and make all disk writes asynchronous, dependant entirely on the OS's own memory swapping and dirty block flushing for any disk writes.&nbsp; This is what you want; you don't want the database to halt because, for example, you simply ran out of space in memory.<br /><br />So, without further ado, here's the settings:<br /><br /><span>&nbsp;&nbsp;&nbsp; work_mem = 5% to 10% of RAM</span><br /><span>&nbsp;&nbsp;&nbsp; temp_buffers = 5% to 10% of RAM</span><br /><span>&nbsp; &nbsp; temp_file_limit = 0 </span><br /><br />Set these two high in order to prevent on-disk sorts.&nbsp; Note that this may cause memory eviction if too many connections are actually using that much RAM.&nbsp; Set temp_file_limit = 0 to cause queries to be cancelled instead of doing disk sorts.<br /><br /><span><span class="VARNAME">&nbsp;&nbsp;&nbsp;&nbsp; bgwriter_lru_maxpages</span> = 0</span><br /><br /><span>&nbsp;&nbsp;&nbsp;&nbsp; wal_level = minimal</span><br /><span>&nbsp;&nbsp;&nbsp;&nbsp; fsync = off</span><br /><span>&nbsp;&nbsp;&nbsp;&nbsp; synchronous_commit = off<br />&nbsp;&nbsp;&nbsp;&nbsp; full_page_writes = off</span><br /><span>&nbsp;&nbsp;&nbsp;&nbsp; wal_log_hints = off<br />&nbsp;&nbsp;&nbsp;&nbsp; wal_buffers = 64MB</span><br /><br />Here we're minimizing the amount of writing we do to the transaction log, and making said writing completely asynchronous.&nbsp; We're also disabling background writing.<br /><br />&nbsp;&nbsp;&nbsp;&nbsp; <span>checkpoint_segments = 16 to 128</span><br /><span>&nbsp;&nbsp; checkpoint_timeout = 60min</span><br />&nbsp;&nbsp;&nbsp;&nbsp; checkpoint_completion_target = 0.0<br /><br />Checkpoint segments is a bit trickier.&nbsp; On the one hand, you want it to be large enough that it's not cycling a lot and triggering disk flushes. On the other hand, you want all the segments to stay cached in RAM.&nbsp; So something moderate, 500MB to 2GB, depending on how much RAM you have.<br /><br /><tt class="VARNAME">&nbsp;&nbsp; </tt><span><span class="VARNAME">stats_temp_directory = '/pgramdisk/stats_tmp'</span></span><br /><br />You will also want to move the stats file to a ramdisk so that it's not being written out.&nbsp; This is a good optimization in general, even outside of running with scissors mode.<br /><br />&nbsp;&nbsp;&nbsp;&nbsp; <span>restart_after_crash = false</span><br /><br />This last setting is very important; it's your safety vest to wear while running with scissors.&nbsp; It tells PostgreSQL "my database is not crash-safe, therefore if it crashes, don't restart."&nbsp; Without it, a restart might result in a database which is corrupted in some non-obvious way.<br /><br />Next up, we'll run some performance tests to see how much this benefits us.<br /><br />Continued in Part II.<br /><br /><i>Photo of "DBAs running with scissors" taken by Gavin Roy.</i>
    </div>
    <div class="feedEntry">

        <a href="http://willmcgugan.com/blog/tech/2015/2/15/a-method-for-rendering-templates-with-python/" title="A method for rendering templates with Python">
            <h2>A method for rendering templates with Python</h2>
        </a>

        <p class="discreet">
            
                  By Will McGugan from Django community aggregator: Community blog posts.
            
            
            
                Published on <span name="publication_time">Feb 15, 2015</span>.
            
        </p>

        <p>I never intended to write a template system for <a class="external-link" href="http://www.moyaproject.com" title="www.moyaproject.com">Moya</a>. Originally, I was going to offer a plugin system to use any template format you wish, with <a class="external-link" href="http://jinja.pocoo.org/docs/dev/" title="jinja.pocoo.org">Jinja</a> as the default. Jinja was certainly up to the task; it is blindingly fast, with a comfortable Django-like syntax. But it was never going to work exactly how I wanted it to, and since I don't have to be pragmatic on my hobby projects, I decided to re-invent the wheel. Because otherwise, how do we get better wheels?</p>
<p>The challenge of writing a template language, I discovered, was keeping the code manageable. If you want to make it both flexible <em>and</em> fast, it can quickly descend in to a mass of special cases and compromises. After a few aborted attempts, I worked out a system that was both flexible and reasonable fast. Not as fast as template systems that compile directly in to Python, but not half bad. Moya's template system is about 10-25% faster than Django templates with a similar feature set.</p>
<p>There are a two main steps in rendering a template. First the template needs to be <em>tokenized</em>, i.e. split up in a data structure of text / tags. This part is less interesting I think, because it can be done in advance and cached. The interesting part is the following step that turns that data structure in to HTML output.</p>
<p>This post will explain how Moya renders templates, by implementing a new template system that works the same way.</p>
<p>Let's render the following template:</p>



<div class="code"><pre><span class="nt">&lt;h1&gt;</span>Hobbit Index<span class="nt">&lt;/h1&gt;</span>
<span class="nt">&lt;ul&gt;</span>
    {% for hobbit in hobbits %}
    <span class="nt">&lt;li</span><span class="err">{%</span> <span class="na">if</span> <span class="na">hobbit=</span><span class="s">=active</span> <span class="err">%}</span> <span class="na">class=</span><span class="s">&quot;active&quot;</span><span class="err">{%</span> <span class="na">endif</span> <span class="err">%}</span><span class="nt">&gt;</span>
        {hobbit}
    <span class="nt">&lt;/li&gt;</span>
    {% endfor %}
<span class="nt">&lt;/ul&gt;</span>
</pre></div>

<p>This somewhat similar to a Django or Moya template. It generates HTML with unordered list of hobbits, one of which has the attribute <code>class="active"</code> on the <code>&lt;li&gt;</code>. You can see there is a loop and conditional in there.</p>
<p>The tokenizer scans the template and generates a hierarchical data structure of text, and tag tokens (markup between {% and %}). Tag tokens consist of a parameters extracted from the tag and <em>children</em> nodes (e.g the tokens between the <code>{% for %}</code> and <code>{% endfor %}</code>).</p>
<p>I'm going to omit the tokenize functionality as an exercise for the reader (sorry, I hate that too). We'll assume that we have implemented the tokenizer, and the end result is a data structure that looks like this:</p>



<div class="code"><pre><span class="p">[</span>
    <span class="s">&quot;&lt;h1&gt;Hobbit Index&lt;/h1&gt;&quot;</span><span class="p">,</span>
    <span class="s">&quot;&lt;ul&gt;&quot;</span><span class="p">,</span>
    <span class="n">ForNode</span><span class="p">(</span>
        <span class="p">{</span><span class="s">&quot;src&quot;</span><span class="p">:</span> <span class="s">&quot;hobbits&quot;</span><span class="p">,</span> <span class="s">&quot;dst&quot;</span><span class="p">:</span> <span class="s">&quot;hobbit&quot;</span><span class="p">},</span>
        <span class="p">[</span>
            <span class="s">&quot;&lt;li&quot;</span><span class="p">,</span>
            <span class="n">IfNode</span><span class="p">(</span>
                <span class="p">{</span><span class="s">&quot;test&quot;</span><span class="p">:</span> <span class="s">&quot;hobbit==active&quot;</span><span class="p">},</span>
                <span class="p">[</span>
                    <span class="s">' class=&quot;active&quot;'</span>
                <span class="p">]</span>
            <span class="p">),</span>
            <span class="s">&quot;&gt;&quot;</span><span class="p">,</span>
            <span class="s">&quot;{hobbit}&quot;</span><span class="p">,</span>
            <span class="s">&quot;&lt;/li&gt;&quot;</span><span class="p">,</span>
        <span class="p">]</span>
     <span class="p">),</span>
    <span class="s">&quot;&lt;/ul&gt;&quot;</span>
<span class="p">]</span>
</pre></div>

<p>Essentially this is a list of strings or <em>nodes</em>, where a node can contain further nested strings and other nodes. A node is defined as a class instance that handles the functionality of a given tag, i.e. IfNode for the {% if %} tag and ForNode for the {% for %} tag.</p>
<p>Nodes have the following trivial base class, which stores the parameters and the list of children:</p>



<div class="code"><pre><span class="k">class</span> <span class="nc">Node</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">children</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">params</span> <span class="o">=</span> <span class="n">params</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">children</span> <span class="o">=</span> <span class="n">children</span>
</pre></div>

<p>Nodes also have an additional method, <code>render</code>, which takes a mapping of the data we want to render (the <em>conext</em>). This method should be a generator, which may yield] one of two things; either strings containing output text <em>or</em> an iterator that yields further nodes. Let's look at the IfNode first:</p>



<div class="code"><pre><span class="k">class</span> <span class="nc">IfNode</span><span class="p">(</span><span class="n">Node</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">render</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">context</span><span class="p">):</span>
        <span class="n">test</span> <span class="o">=</span> <span class="nb">eval</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s">'test'</span><span class="p">],</span> <span class="nb">globals</span><span class="p">(),</span> <span class="n">context</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">test</span><span class="p">:</span>
            <span class="k">yield</span> <span class="nb">iter</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">children</span><span class="p">)</span>
</pre></div>

<p>The first thing the render method does is to get the <code>test</code> parameter and evaluate it with the data in the context. If the result of that test is truthy, then the render method yields an iterator of it's children. Essentially all this node object does is render its children (i.e. the template code between {% if %} and {% endif %}) if the test passes.</p>
<p>The <code>ForNode</code> is similar, here's the implementation:</p>



<div class="code"><pre><span class="k">class</span> <span class="nc">ForNode</span><span class="p">(</span><span class="n">Node</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">render</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">context</span><span class="p">):</span>
        <span class="n">src</span> <span class="o">=</span> <span class="nb">eval</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s">'src'</span><span class="p">],</span> <span class="nb">globals</span><span class="p">(),</span> <span class="n">context</span><span class="p">)</span>
        <span class="n">dst</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s">'dst'</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">obj</span> <span class="ow">in</span> <span class="n">src</span><span class="p">:</span>
            <span class="n">context</span><span class="p">[</span><span class="n">dst</span><span class="p">]</span> <span class="o">=</span> <span class="n">obj</span>
            <span class="k">yield</span> <span class="nb">iter</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">children</span><span class="p">)</span>
</pre></div>

<p>The ForNode render method iterates over each item in a sequence, and assigns the value to an intermediate variable. It also yields to its children each pass through the loop. So the code inside the {% for %} tag is rendered once per item in the sequence.</p>
<p>Because we are using generators to handle the state for control structures, we can keep the main render loop free from such logic. This makes the code that renders the template trivially easy to follow:</p>



<div class="code"><pre><span class="k">def</span> <span class="nf">render</span><span class="p">(</span><span class="n">template</span><span class="p">,</span> <span class="o">**</span><span class="n">context</span><span class="p">):</span>
    <span class="n">output</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">stack</span> <span class="o">=</span> <span class="p">[</span><span class="nb">iter</span><span class="p">(</span><span class="n">template</span><span class="p">)]</span>

    <span class="k">while</span> <span class="n">stack</span><span class="p">:</span>
        <span class="n">node</span> <span class="o">=</span> <span class="n">stack</span><span class="o">.</span><span class="n">pop</span><span class="p">()</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="nb">basestring</span><span class="p">):</span>
            <span class="n">output</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="o">**</span><span class="n">context</span><span class="p">))</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="n">Node</span><span class="p">):</span>
            <span class="n">stack</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">render</span><span class="p">(</span><span class="n">context</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">new_node</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="bp">None</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">new_node</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
                <span class="n">stack</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">node</span><span class="p">)</span>
                <span class="n">stack</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">new_node</span><span class="p">)</span>
    <span class="k">return</span> <span class="s">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</pre></div>

<p>The render loop manages a stack of iterators, initialized to the template data structure. Each pass through the loop it pops an item off the stack. If that item is a string, it performs a string format operation with the context data. If the item is a Node, it calls the render method and pushes the generator back on to the stack. When the stack item is an iterator (such as a generator created by Node.render) it gets one value from the iterator and pushes it back on to the stack, or discards it if is empty.</p>
<p>In essence, the inner loop is running the generators and collecting the output. A more naive approach might have the render methods also rendering their children and returning the result as a string. Using generators frees the nodes from having to build strings. Generators also makes error reporting much easier, because exceptions won't be obscured by deeply nested render methods. Consider a node throwing an exception inside a for loop; if ForNode.render was responsible for rendering its children, it would also have to trap and report such errors. The generator system makes error reporting simpler, and confines it to one place.</p>
<p>There is a very similar loop at the heart of Moya's template system. I suspect the main reason that Moya templates are moderately faster than Django's is due to this lean inner loop. See this <a class="external-link" href="https://gist.github.com/willmcgugan/00c3427ef5a5e04d3c86" title="gist.github.com">GutHub</a> gist for the code from this post.</p>
    </div>
    <div class="feedEntry">

        <a href="http://feedproxy.google.com/~r/no0p/~3/sy3Oy8JjBhQ/artisanal-stopwords.html" title="robert berry: Artisanal Stop Words">
            <h2>robert berry: Artisanal Stop Words</h2>
        </a>

        <p class="discreet">
            
            
                  From Planet PostgreSQL.
            
            
                Published on <span name="publication_time">Feb 14, 2015</span>.
            
        </p>

        <h1>Artisanal Stop Words</h1>
<p class="meta">Feb 15, 2015 &#8211; Portland</p>
<p>The default English stop word list is pretty good, but you may want to get a little more aggressive.  Consider the following index built using the default english stop word list.</p>
<pre><code>\di+ core_search_idx 
                                  List of relations
 Schema |      Name       | Type  | Owner  |        Table         | Size  | Description 
--------+-----------------+-------+--------+----------------------+-------+-------------
 public | core_search_idx | index | robert | composited_documents | 61 GB | 
(1 row)</code></pre>
<p>That&#8217;s a lot of words &#8212; in fact a sample of 10% of the documents has 4,665,436 unique tokens and that&#8217;s after excluding most token types.  It seems quite likely that this corpus has some issues, and some of these tokens are not providing much information.  This post describes how to create a hand crafted stop word list with the <b>ts_stat</b> function by calculating a normalized inverse document frequency for each term.</p>
<h3>Normalized Inverse Document Frequency</h3>
<p>When selecting terms to remove from a search index, we intuitively want to identify terms which contain the least amount of information for distinguishing documents.  The frequency at which a term appears in documents <a href="http://terrierteam.dcs.gla.ac.uk/publications/rtlo_DIRpaper.pdf">is a simple and effective metric</a> for the amount of distinguishing information the presence of a term contains.</p>
<p>$idf_{k} = log(\frac{(D_{n} &#8211; D_{k}) + 0.5}{D_{k} + 0.5})$</p>
<table border="1" class="list_table">
<tr>
    <td>k</td><td>A token</td>
</tr>
<tr>
    <td>D<sub>n</sub></td><td>the total number of documents</td>
</tr>
<tr>
    <td>D<sub>k</sub></td>
    <td>the number of documents where the term <b>k</b> is present.</td>
</tr>
</table>
<p><br /></p>
<h3>ts_stat(query text)</h3>
<p>The <a href="http://www.postgresql.org/docs/8.3/static/textsearch-features.html#AEN18666">ts_stat</a> function produces tuples containing the token as field &#8216;word&#8217; (<b>k</b>), the number of times a token is used in field &#8216;nentry&#8217;, and the number of documents where the token is present &#8216;ndoc&#8217; (D<sub>k</sub>).</p>
<p>To illustrate, consider the result from a simple table containing a content tsvector column:</p>
<pre><code>=# select * from ts_stat('select content from composited_documents')
      order by ndoc desc, nentry desc
        limit 3;</code>
        
<code> word  | ndoc  | nentry  
-------+-------+---------
 may   | 46065 | 2384528
 first | 43844 | 2093459
 one   | 47257 | 1996176
(3 rows)</code></pre>
<p>ts_stat is quite convenient, as it provides most of the information needed.</p>
<h2><strike>Calculating</strike> Crafting a stop word list</h2>
<p>A list of candidate stop words will be a result set ordered by a term&#8217;s idf.  This will allow for farkling with a threshold value to exclude terms.</p>
<p>First create a result set with components matching the variables in the idf definition.</p>
<pre><code>=# select word as k, ndoc as D_k, (select count(*) from composited_documents) as D_n
     from ts_stat('select content from composited_documents')
       order by nentry desc limit 3;</code>
       
<code>   k   |  d_k  |  d_n  
-------+-------+-------
 may   | 77976 | 87500
 first | 74258 | 87500
 one   | 80008 | 87500
(3 rows)</code></pre>
<p>Next use a subquery to get term-idf pairs.  Note the switch in the order by clause.</p>
<pre><code># select k, log(((d_n - d_k) + 0.5) / (d_k + 0.5)) as idf
    from (select word as k, 
                 ndoc as d_k, 
                 (select count(*) from composited_documents) as d_n
            from ts_stat('select content from composited_documents')
              order by nentry asc limit 3
         ) as word_metrics;</code>
       
<code>   k   |           idf           
-------+-------------------------
 may   | -0.91312155170483241232
 first | -0.74877619074948192116
 one   | -1.02850937671174830200
(3 rows)</code></pre>
<p>Ok looks pretty good.  These are the most common words, sorting by the idf where it is greater than 2 we see some more meaty words.</p>
<pre><code>    k      |        idf         
------------+--------------------
 till       | 2.0004288139736811
 octob      | 2.0009359014391109
 inaccess   | 2.0014435699516726
 shifter    | 2.0014435699516726
 scalar     | 2.0019518208580772
 veterinari | 2.0034800814778920</code></pre>
<p>Consider where idf &gt; 4</p>
<pre><code>       k        |        idf         
----------------+--------------------
 zuniga         | 4.0125519004712559
 zool           | 4.0125519004712559
 zwicker        | 4.0125519004712559</code></pre>
<p><img src="http://feeds.feedburner.com/images/artisinal_knots.jpg" style="float: right; margin-left: 30px;" width="400" /> Those are looking pretty informative.  So we can select an artisanal threshold for now, and generate a stop word list.</p>
<div style="clear: both;">
<p><br /></p>
<pre><code>copy ( select k as word
    from (select word as k, 
                 ndoc as d_k, 
                 (select count(*) from composited_documents) as d_n
            from ts_stat('select content from composited_documents')
         ) as word_metrics
    where log(((d_n - d_k) + 0.5) / (d_k + 0.5)) &lt; 2) to '/tmp/additional_stopwords';</code></pre>
<p>To use this list, create a file in the text search configuration directory.  This will vary by system but should be the shared location where the english.stop file exists.</p>
<pre><code>cat /usr/share/postgresql/9.4/tsearch_data/english.stop \
        /tmp/additional_stopwords &gt; \
        /usr/share/postgresql/9.4/tsearch_data/artisanal.stop</code></pre>
<p>This stopword list can be used <a href="http://www.postgresql.org/docs/9.1/static/textsearch-dictionaries.html#TEXTSEARCH-SIMPLE-DICTIONARY">creating dictionaries</a>.</p>
<h3>A Note on Optimal Thresholds</h3>
<p>In this case, the goal is to reduce the 61GB <span class="caps">GIN</span> index to something more in line with home Desktop&#8217;s 32GB of memory.  However in many cases the goal would be to optimize the accuracy of query results.  The former requires applying stop word lists and measuring index size, while the later requires a method for evaluating a test set of queries.</p>
<h2>Sampling: <span class="caps">OOM</span> Killer Takes No Hostages</h2>
<p><img src="http://feeds.feedburner.com/images/psycho1.png" style="float: right; margin-left: 30px;" width="500" /></p>
<p>The above queries simply die because the token set is simply too large.  A naive approach is to use a point estimator for each term&#8217;s idf by taking a single simple random sample of documents.</p>
<div style="clear: both;">
<p><br /></p>
<pre><code>=# select k, log(((d_n - d_k) + 0.5) / (d_k + 0.5)) as idf
    from (select word as k, 
                 ndoc as d_k, 
                 (select count(*) from composited_documents) as d_n
            from ts_stat('select content from composited_documents where random() &lt; 0.2')
         ) as word_metrics;</code></pre>
<p>More efficient ways to take a random sample exist, but are beyond the scope of this post.  Additionally, a more complete approach would include creating sampling distributions for each term&#8217;s idf, and excluding terms with non-significant estimators.  This is left as an academic exercise &#8212; because 128 GB of DDR4 is in the mail.</p>
    </div>
    <div class="feedEntry">

        <a href="http://adpgtech.blogspot.com/2015/02/statistics-and-ordering-operations-on.html" title="Andrew Dunstan: Statistics and ordering operations on JSON fields">
            <h2>Andrew Dunstan: Statistics and ordering operations on JSON fields</h2>
        </a>

        <p class="discreet">
            
            
                  From Planet PostgreSQL.
            
            
                Published on <span name="publication_time">Feb 14, 2015</span>.
            
        </p>

        The JSON type is not provided with any comparison operators built in, unlike the new JSONB type. One reason for this is that it's not really clear how to do the comparison. In particular, comparing the text values seems wrong, because the white space should not matter, and arguably the order of object keys should not matter either. JSONB doesn't have these problems because it dissolves all the white space and stores object keys in a canonical order, so we have come up with sane if slightly counter-intuitive comparison operations.<br /><br />This limitation on JSON is somewhat irksome, however. It restricts you from doing some operations on JSON such as DISTINCT, GROUP BY, and ORDER BY.<br /><br />Another issue is that it causes ANALYZE not to create any rows at all in pg_statistic for JSON columns, so even if all you want to know is the average column width, you can't find it. That makes doing things like measuring table bloat just about impossible. <br /><br />If you have PLV8 available, you can create operators that work fairly sanely on JSON and that let you generate stats, use DISTINCT etc. The steps are <a href="http://hyperthese.net/post/sorting-json-fields-in-postgresql/">outlined here</a>.<br /><br />But what if you don't want to load PLV8 just for this? Or what of you can't, like say on a managed service that doesn't provide it? All is not lost.&nbsp; <a href="https://gist.github.com/adunstan/32ad224d7499d2603708">Here</a> is a version which uses text comparison instead of a PLV8 function.&nbsp; That means you don't need to have PLV8 loaded. Since it uses text comparison, it is subject to the caveats mentioned about about white space and object keys. But it will work, and you will see rows for the column in pg_statistic. Just be careful using ordering operations or creating indexes, as the results, while consistent, might be surprising.
    </div>
    <div class="feedEntry">

        <a href="http://www.databasesoup.com/2015/02/in-memory-is-not-feature-its-bug.html" title="Josh Berkus: &quot;In-memory&quot; is not a feature, it's a bug">
            <h2>Josh Berkus: "In-memory" is not a feature, it's a bug</h2>
        </a>

        <p class="discreet">
            
            
                  From Planet PostgreSQL.
            
            
                Published on <span name="publication_time">Feb 13, 2015</span>.
            
        </p>

        So, I'm hearing again about the latest generation of "in-memory databases". Apparently Gartner even has a category for them now.&nbsp; Let me define an in-memory database for you:<br /><i><br /></i><i>&nbsp;&nbsp;&nbsp;&nbsp; An in-memory database is one which lacks the capability of spilling to disk.</i><br /><br />As far as I know in my industry literature reading, nobody has demonstrated any useful way in which data should be stored differently if it never spills to disk.&nbsp;&nbsp; While the talented engineers of several database products have focused on other performance optimizations to the exclusion of making disk access work, that's not an optimization of the database; it's an optimization of engineer time.&nbsp;&nbsp; The exact same database, with disk access capabilities, would be automatically superior to its predecessor, because users would now have more options.<br /><br />PostgreSQL can be an "in-memory" database too, if you simply turn all of the disk storage features off.&nbsp; This is known as "running with scissors" mode, and people do it for useful effect on public clouds with disposable replicas. <br /><br />So an "in-memory" database is a database with a major limitation.&nbsp; It's not a feature, any more than an incapability of supporting SQL access is a feature.&nbsp; Let's define databases by their useful features, not by what they lack, please. <br /><br />Besides which, with the <a href="http://www.enterprisetech.com/2014/06/12/hp-puts-memristors-heart-new-machine/">new types of persistent memory</a> and fast random access storage coming down the pipe in a couple years, there soon won't be any difference between disk and memory anyway.
    </div>
    <div class="feedEntry">

        <a href="http://michael.otacoo.com/postgresql-2/postgres-9-5-feature-highlight-pglz-compression-libpqcommon/" title="Michael Paquier: Postgres 9.5 feature highlight: Compression with PGLZ in libpqcommon">
            <h2>Michael Paquier: Postgres 9.5 feature highlight: Compression with PGLZ in libpqcommon</h2>
        </a>

        <p class="discreet">
            
            
                  From Planet PostgreSQL.
            
            
                Published on <span name="publication_time">Feb 12, 2015</span>.
            
        </p>

        <p>As a preparation of an upcoming patch for full-page write compression in
<a href="http://www.postgresql.org/docs/devel/static/wal.html">WAL</a>, a patch has
been pushed this week to make PGLZ, the in-core compression algorithm
of PostgreSQL used for TOAST tables, more pluggable for plugins and frontend
applications, particularly pg_xlogdump that needs to be able to decode a WAL
record using the XLOG reader facility even if blocks are compressed to be
able to reconstitute them. It makes as well sense to expose this algorithm
as PGLZ compressed data would not be limited only to the internal backend
usage of TOAST tables in a PostgreSQL instance, but as well to WAL data, be
it simple WAL archive or a WAL streaming flow. So, here is the commit:</p>
<div class="highlight"><pre><code class="language-text">commit: 40bede5477bb5bce98ce9548841cb414634c26f7
author: Fujii Masao &lt;fujii@postgresql.org&gt;
date: Mon, 9 Feb 2015 15:15:24 +0900
Move pg_lzcompress.c to src/common.

The meta data of PGLZ symbolized by PGLZ_Header is removed, to make
the compression and decompression code independent on the backend-only
varlena facility. PGLZ_Header is being used to store some meta data
related to the data being compressed like the raw length of the uncompressed
record or some varlena-related data, making it unpluggable once PGLZ is
stored in src/common as it contains some backend-only code paths with
the management of varlena structures. The APIs of PGLZ are reworked
at the same time to do only compression and decompression of buffers
without the meta-data layer, simplifying its use for a more general usage.

On-disk format is preserved as well, so there is no incompatibility with
previous major versions of PostgreSQL for TOAST entries.

Exposing compression and decompression APIs of pglz makes possible its
use by extensions and contrib modules. Especially this commit is required
for upcoming WAL compression feature so that the WAL reader facility can
decompress the WAL data by using pglz_decompress.

Michael Paquier, reviewed by me.
</code></pre></div>
<p>Compared to previous versions of PGLZ, its dependency on the varlena header
has been removed, and its compression and decompression routines have been
reworked as follows:</p>
<div class="highlight"><pre><code class="language-text">extern int32 pglz_compress(const char *source, int32 slen, char *dest,
                           const PGLZ_Strategy *strategy);
extern int32 pglz_decompress(const char *source, int32 slen, char *dest,
                             int32 rawsize);
</code></pre></div>
<p>An error should occur, those routines would return -1. And in case of success,
are returned respectively the number of bytes compressed and decompressed,
in a manner close to lz4 (except that lz4 returns 0 in case of processing
error). Note: PGLZ is more CPU consuming than other compression algorithms.</p>

<p>Using those APIs, I implemented a simple extension able to do compression
and decompression of bytea, combined with a rough copy of the function
get_raw_page already present in the in-core contrib module <a href="http://www.postgresql.org/docs/devel/static/pageinspect.html">pageinspect</a>, with a new
option able to suppress the hole of a page, replacing with zeros the hole
of a page if it is wanted as this is more performant for compression. But, in
any case, any type of bytea data can be passed to the compression and
decompression functions.</p>
<div class="highlight"><pre><code class="language-text">=# CREATE EXTENSION compression_test;
CREATE EXTENSION
=# \dx+ compression_test
  Objects in extension &quot;compression_test&quot;
             Object Description
--------------------------------------------
 function compress_data(bytea)
 function decompress_data(bytea,smallint)
 function get_raw_page(oid,integer,boolean)
(3 rows)
</code></pre></div>
<p>Using this extension is rather simple, let's see for example with a sample
table that contains some data, like one tuple:</p>
<div class="highlight"><pre><code class="language-text">=# CREATE TABLE compressed_tab (id int);
CREATE TABLE
=# INSERT INTO compressed_tab VALUES (1); -- 60 bytes on page without hole
INSERT 0 1
=# SELECT substring(page, 1, 20), hole_offset
   FROM get_raw_page('compressed_tab'::regclass, 0, false);
                 substring                  | hole_offset
--------------------------------------------+-------------
 \x0000000060662413000000001c00e01f00200420 |          28
(1 row)
</code></pre></div>
<p>The third argument of get_raw_page can be set to &quot;false&quot; to fetch a page
without hole, and to &quot;true&quot; to get a hole filled with zeros. The hole
offset is returned as well to be able to reconstitue the page. Now playing
with the compression and the decompression, here are some results:</p>
<div class="highlight"><pre><code class="language-text">=# SELECT substring(compress_data(page), 1, 20), hole_offset
   FROM get_raw_page('compressed_tab'::regclass, 0, false);
                 substring                  | hole_offset
--------------------------------------------+-------------
 \x0000000000606624130101081c00e01f00200402 |          28
(1 row)
=# SELECT substring(decompress_data(compress_data(page), 60::smallint), 1, 20),
          hole_offset
   FROM get_raw_page('compressed_tab'::regclass, 0, false);
                 substring                  | hole_offset
--------------------------------------------+-------------
 \x0000000060662413000000001c00e01f00200420 |          28
(1 row)
</code></pre></div>
<p>The data page gets down to 46 bytes from 60 bytes if compressed without hole
(this page contains not much data). Also, when requesting a decompression,
be sure to pass the raw length of the data that needs to be decompressed.</p>

<p>This extension is named <a href="https://github.com/michaelpq/pg_plugins/tree/master/compress_test">compress_test</a> and is
present in my <a href="https://github.com/michaelpq/pg_plugins">plugin repository</a>.
Note as well that the compression strategy used is PGLZ_strategy_always,
meaning that the data compression will always be attempted. Perhaps that is
useful, or not...</p>
    </div>
    <div class="feedEntry">

        <a href="http://www.databasesoup.com/2015/02/tree-join-tables-preventing-cycles.html" title="Josh Berkus: Tree Join Tables: preventing cycles">
            <h2>Josh Berkus: Tree Join Tables: preventing cycles</h2>
        </a>

        <p class="discreet">
            
            
                  From Planet PostgreSQL.
            
            
                Published on <span name="publication_time">Feb 12, 2015</span>.
            
        </p>

        Searching Google, I was surprised to find that there were few solutions published for a common issue: preventing users from creating a cycle when you create a self-join table.&nbsp; So here's one solution, which will be "good enough" for most people, but has some caveats (see below).<br /><br />First, the setup: we have a table of items.&nbsp; Items can be in one or more collections.&nbsp; Each item can itself be a collection, allowing users to create collections of collections.&nbsp; So the first thing we need is a self-join table on the "adjacency list" model:<br /><br /><span>&nbsp;&nbsp;&nbsp; create table collections (</span><br /><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; collection_id int not null references items(id) on delete cascade,</span><br /><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; item_id int not null references items(id) on delete cascade,</span><br /><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; constraint collections_pk primary key ( collection_id, item_id )</span><br /><span>&nbsp;&nbsp;&nbsp; );</span><br /><span>&nbsp;&nbsp;&nbsp; create index on collections(item_id);</span><br /><br />So the first part of preventing cycles is to prevent the simplest cycle, where a collection collects itself.&nbsp; That can be done with a constraint:<br /><br /><span>&nbsp;&nbsp;&nbsp;&nbsp; alter table collections add constraint </span><br /><span>&nbsp;&nbsp;&nbsp;&nbsp; no_self_join check ( collection_id &lt;&gt; item_id )</span><br /><br />Now comes the tough part, preventing cycles of more than one, two, or N collections in a chain.&nbsp; This requires us to look down a chain of possible collections and make sure that each inserted tuple doesn't complete a loop.&nbsp; Fortunately, WITH RECURSIVE works for this provided we do it in a BEFORE trigger.&nbsp; If we did it in an AFTER trigger, the trigger itself would cycle, which would be no good.<br /><br /><span>&nbsp;&nbsp;&nbsp; CREATE OR REPLACE FUNCTION collections_prevent_cycle ()</span><br /><span>&nbsp;&nbsp;&nbsp; returns trigger</span><br /><span>&nbsp;&nbsp;&nbsp; language plpgsql</span><br /><span>&nbsp;&nbsp;&nbsp; as $f$</span><br /><span>&nbsp;&nbsp;&nbsp; BEGIN</span><br /><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -- select recusively, looking for all child items of the new collection</span><br /><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -- and making sure that they don't include the new collection</span><br /><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; IF EXISTS ( WITH recursive colitem as (</span><br /><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; select collection_id, item_id</span><br /><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; from collections</span><br /><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; where collection_id = NEW.item_id</span><br /><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; UNION ALL</span><br /><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; select colitem.collection_id, collections.item_id</span><br /><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; from collections</span><br /><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; join colitem on colitem.item_id = collections.collection_id</span><br /><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; )</span><br /><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; SELECT collection_id from colitem</span><br /><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; WHERE item_id = NEW.collection_id</span><br /><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; LIMIT 1 ) THEN</span><br /><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; RAISE EXCEPTION 'You may not create a cycle of collections.';</span><br /><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; END IF;</span><br /><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><br /><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; RETURN NEW;</span><br /><span>&nbsp;&nbsp;&nbsp; END; $f$;</span><br /><span><br /></span><span>&nbsp;&nbsp;&nbsp; CREATE TRIGGER collections_prevent_cycle </span><br /><span>&nbsp;&nbsp;&nbsp; BEFORE INSERT OR UPDATE ON collections</span><br /><span>&nbsp;&nbsp;&nbsp; FOR EACH ROW EXECUTE PROCEDURE collections_prevent_cycle();</span><br /><br />As I said, this solution will be "good enough" for a variety of uses.&nbsp; However, it has some defects:<br /><br /><b>Concurrency</b>: It is vulnerable to concurrency failure.&nbsp; That is, if two users simultaneously insert "A collects B" and "B collects A", this trigger would not prevent it.&nbsp; The alternative is locking the entire table on each commit, which is also problematic.<br /><br /><b>Cost</b>: we're running a pretty expensive recursive query with every insert.&nbsp; For applications where the tree table is write-heavy, this will decrease throughput significantly.<br /><br />So my, challenge to you is this: come up with a better solution for this, which solves either the concurrency or cost problem without making the other problem worse.<br /><br />P.S.: this blog has reached half a million views.&nbsp; Thanks, readers!
    </div>
    <div class="feedEntry">

        <a href="http://theplateisbad.blogspot.com/2015/02/finding-mass-spectra-with-postgresql_11.html" title="Ernst-Georg Schmid: Finding mass spectra with PostgreSQL: Indexing">
            <h2>Ernst-Georg Schmid: Finding mass spectra with PostgreSQL: Indexing</h2>
        </a>

        <p class="discreet">
            
            
                  From Planet PostgreSQL.
            
            
                Published on <span name="publication_time">Feb 11, 2015</span>.
            
        </p>

        When naively searching for a specific spectral contrast angle, e.g.<br /><br /><span>select id from spectrum, round(spectral_contrast('[{"m/z":144.1150218,"intensity":0.908209840784744},{"m/z":145.118459841064,"intensity":0.0841924148716925}]'::json, id),2) as spectral_contrast where spectral_contrast = 1.0;</span><br /><br />performance is not really stellar on my ~ 270k spectra database:<br /><br /><span>Execution time: 18695.619 ms</span> for 71 hits.<br /><br />This is no surprise, since the statement has to calculate the spectral contrast angle for all rows and filter each row. How about indexing?<br /><br />The simplest method I can envision, is to precalculate the number of peaks for each spectrum, index the column and add it to the query. Since the spectral contrast angle requires the number of peaks of the compared spectra to be equal, this is a safe restriction.<br /><br /><span>select  id from spectrum,  round(spectral_contrast('[{"m/z":144.1150218,"intensity":0.908209840784744},{"m/z":145.118459841064,"intensity":0.0841924148716925}]'::json,  id),2) as spectral_contrast where spectral_contrast = 1.0 and num_peaks = 2;</span><br /><br />&nbsp;<span>Execution time: 797.346 ms</span> for 71 hits.<br /><br />OK, but can we do better? Yes, by using a more selective restriction, like the lower and upper bounds of the m/z values of the spectra, index the column and add it to the query. These can easily be obtained by <span>min(m/z)</span>and <span>max(m/z)</span> and then be stored in a <span>numrange</span> column. Since the spectral contrast angle requires the m/z values of the peaks of the compared spectra to be equal, this again is a safe restriction.<br /><br /><span>select   id from spectrum,  round(spectral_contrast('[{"m/z":144.1150218,"intensity":0.908209840784744},{"m/z":145.118459841064,"intensity":0.0841924148716925}]'::json,   id),2) as spectral_contrast where spectral_contrast = 1.0 and mzrange = numrange(144.1150218,145.118459841064,'[]');</span> <br /><br /><span>Execution time: 35.128 ms</span> for 71 hits. <br /><br />About 534 times faster.<br /><br />Using a range type instead of storing the lower and upper bound in discrete columns gives more flexibility when querying with other criteria, like the Tanimoto index. Then, PostgreSQL's <a href="http://www.postgresql.org/docs/9.4/static/functions-range.html#RANGE-OPERATORS-TABLE" target="_blank">range operators</a>, like <span>&amp;&amp;</span>&nbsp; (overlap), might come in handy.<br /><br />
    </div>
    <div class="feedEntry">

        <a href="http://reinout.vanrees.org/weblog/2015/02/11/dont_import_in_settings.html" title="Don't import (too much) in your django settings">
            <h2>Don't import (too much) in your django settings</h2>
        </a>

        <p class="discreet">
            
                  By Reinout van Rees' weblog from Django community aggregator: Community blog posts.
            
            
            
                Published on <span name="publication_time">Feb 10, 2015</span>.
            
        </p>

        <div class="document">
<p>One of our production Django sites broke this afternoon with a database error
&quot;relation xyz doesn't exist&quot;. So: a missing table.</p>
<div class="section" id="why-1">
<h1>Why 1</h1>
<p>I helped debugging it and eventually found the cause by doing a <tt class="docutils literal">select *
from south_migrationhistory</tt>. This lists the south migrations and lo and
behold, a migration had just been applied 25 minutes earlier. The migration
name suggested a rename of tables, which of course matches the &quot;missing table&quot;
error.</p>
</div>
<div class="section" id="why-2">
<h1>Why 2</h1>
<p>Cause found. But you have to ask yourself &quot;why&quot; again. So: &quot;why was this
migration applied?&quot;.</p>
<p>Well, someone was working on a bit of database cleanup and refactoring. Naming
consistency, proper use of permissions, that sort of thing. Of course, locally
in a branch. And on a development database. Now <strong>why</strong> did the local command
result in a migration on the production database?</p>
</div>
<div class="section" id="why-3">
<h1>Why 3</h1>
<p>So, effectively, &quot;why don't the development settings work as intended&quot;? We
normally use <tt class="docutils literal">settings.py</tt> as the production settings and a
<tt class="docutils literal">developmentsettings.py</tt> that is used in development. It imports from
<tt class="docutils literal">settings.py</tt> and sets the debug mode and development database and so.</p>
<p>This project is a bit different in that there's only a <tt class="docutils literal">settings.py</tt>. It
does however try to import <tt class="docutils literal">localsettings.py</tt>. This is generated for you
when you set up your project environment with ansible. A bit less clear (in my
opinion) than a real .py file in your github repository, but <strong>it
works</strong>. We saw the generated localsettings file with development database and
<tt class="docutils literal">DEBUG = True</tt>. This wasn't the cause. What then?</p>
<p>Normally, calling django's <tt class="docutils literal">diffsettings</tt> command (see <a class="reference external" href="https://docs.djangoproject.com/en/1.7/ref/django-admin/#diffsettings">the django
documentation</a>)
shows you any settings errors by printing all the settings in your config that
are different from Django's defaults. In this case, nothing was wrong. The
<tt class="docutils literal">DATABASES</tt> setting was the right one with the local development
database. Huh?</p>
<p>The developer mentioned one other thing he changed recently: <strong>importing some
django signal registration module in the ``settings.py``</strong>. Ah! Django's
signals often work on the database. Yes, the signals in this module did
database work, too.</p>
<p>So the <tt class="docutils literal">settings.py</tt> effectively looked like this:</p>
<pre class="literal-block">
DATABASES = { .... 'server': 'productiondatabase' ....}
import my_project.signal_stuff_that_works_on_the_database
try:
    from .localsettings import *
    # This normally sets DATABASES = { .... 'server': 'developmentdatabase' ....}
except ImportError:
    pass
</pre>
<p>The import of the signal registration module apparently triggered something in
Django's database layer so that the database connection was already
active. The subsequent change of the <tt class="docutils literal">DATABASES</tt> config to the local
development database didn't have any effect anymore.</p>
<p><tt class="docutils literal">diffsettings</tt> just shows you what the settings are and doesn't catch the
fact that the <tt class="docutils literal">DATABASES</tt> isn't really used in the form that comes out of
diffsettings.</p>
</div>
<div class="section" id="why-4">
<h1>Why 4</h1>
<p>Why the import, then?</p>
<p>Well, it <em>has</em> to be executed when django starts up. The settings file looked
like a good spot. It isn't, though.</p>
<p>The traditional location to place imports like this is the <tt class="docutils literal">urls.py</tt> or
<tt class="docutils literal">models.py</tt> file. That's why the <tt class="docutils literal">admin.autodiscover()</tt> line is often in
your <tt class="docutils literal">urls.py</tt>, for instance.</p>
<p>So... put imports like this in <tt class="docutils literal">models.py</tt> or <tt class="docutils literal">urls.py</tt> instead of in your
settings file.</p>
</div>
<div class="section" id="why-5">
<h1>Why 5</h1>
<p>Digging even deeper... isn't this sort of weird and ugly? Why isn't there a
more obvious place for initialization code like this? Now you have to have the
arcane knowledge to somehow know where you can import and where not, right?</p>
<p>The answer: there <strong>is</strong> a good spot, in django 1.7. The <a class="reference external" href="https://docs.djangoproject.com/en/1.7/ref/applications/#django.apps.AppConfig.ready">AppConfig.ready()
method</a>!
Quote from the documentation: <em>Subclasses can override this method to perform
initialization tasks such as registering signals</em>. Bingo!</p>
</div>
</div>
    </div>
    <div class="feedEntry">

        <a href="http://www.sqlobjectifier.com/2015/02/sqlobjectifier-scalable-entity.html" title="Erik Van Norstrand: SQLObjectifier - A scalable Entity-Attribute-Value Model with Relationship Support">
            <h2>Erik Van Norstrand: SQLObjectifier - A scalable Entity-Attribute-Value Model with Relationship Support</h2>
        </a>

        <p class="discreet">
            
            
                  From Planet PostgreSQL.
            
            
                Published on <span name="publication_time">Feb 10, 2015</span>.
            
        </p>

        I started SQLObjectifier to build a core database model that would be able to fit multiple domains with ease. Today, I am proud to release version 1.0 of SQLObjectifier to the public!

SQLObjectifier is a SQL powered web application that provides the ability to quickly model one or more domains. SQLObjectifier is powered by PostGreSQL, Node.JS, and EXTJS 5.1 (GPL). SQLObjectifier is Free and Open
    </div>
    <div class="feedEntry">

        <a href="http://blog.endpoint.com/2015/02/postgres-custom-casts-and-pgdump.html" title="Greg Sabino Mullane: Postgres custom casts and pg_dump">
            <h2>Greg Sabino Mullane: Postgres custom casts and pg_dump</h2>
        </a>

        <p class="discreet">
            
            
                  From Planet PostgreSQL.
            
            
                Published on <span name="publication_time">Feb 10, 2015</span>.
            
        </p>

        <!--
span.gsm{font-family:monospace; color: green; background-color: white; background-image: none; display: block; margin-bottom: 20px; font-weight: bolder}
span.gsm pre { white-space: pre-wrap; white-space:-o-pre-wrap; word-wrap: break-word; }
span.gsm_c { color: #111111; }
span.gsm_p { color: #444444; }
span.gsm_p2 { color: #222222; }
span.gsm_o { color: #0022cc; }
span.gsm_gb { font-weight: boldest; color: #cc2200; }
span.gsm_indent { color: black; background-color: white; background-image: none; display: block; margin: 1em 2em 2em 2em; font-size: smaller;}
-->
<p>We recently upgraded a client from Postgres 
<a href="http://www.postgresql.org/docs/current/static/release-8-3.html">version 8.3</a> to <a href="http://www.postgresql.org/docs/current/static/release-9-4.html">version 9.4</a>. Yes, that is quite the jump! In the process, I was reminded about the old implicit cast issue. A major change of Postgres 8.3 was the removal of some of the built-in <a href="http://www.postgresql.org/docs/current/static/sql-createcast.html">casts</a>, meaning that many applications that worked fine on Postgres 8.2 and earlier started throwing errors. The correct response to fixing such things is to adjust the underlying application and its SQL. Sometimes this meant a big code difference.  This is not always possible because of the size and/or complexity of the code, or simply the sheer inability to change it for various other reasons. Thus, another solution was to add some of the casts back in. However, this has its own drawback, as seen below.</p>

<div class="separator" style="clear: both; float: right; text-align: center;"><a href="http://2.bp.blogspot.com/-NQMoH7uzpOg/VNUu2FlnuXI/AAAAAAAAAg8/rL7VoFNpDU4/s1600/eleshade.jpg" style="clear: right; float: right; margin-bottom: 1em; margin-left: 1em;"><img border="0" id="rqgqiaqdaliu2rcuvcocuwdazfpyynogiahcxh3f4tcwrz3rzmoeffepr47gh4sdgu27buhpuxn3glanpqprx4qv2tumhy34umm7qtzlbr2eopluomihrr3evhmip7lsv2tcf767ylzzcdhjgn4rtoczrmqo7fmzrcvuxrqtqe4qgqgncz6q" src="http://2.bp.blogspot.com/-NQMoH7uzpOg/VNUu2FlnuXI/AAAAAAAAAg8/rL7VoFNpDU4/s320/eleshade.jpg" /></a><br /><small><a href="https://flic.kr/p/dKfNnR">Image</a> by <a href="https://www.flickr.com/photos/teaem/">Tarek Mohamed</a></small></div>

<p>While this may seem a little academic, given how old 8.3 is, we still see that version in the field. Indeed, we have more than a few clients running versions even older than that!. While <a href="http://www.postgresql.org/docs/current/static/pgupgrade.html">pg_upgrade</a> is the preferred method for upgrading between major versions (even upgrading from 8.3), its use is not always possible. For the client in this story, in addition to some system catalog corruption, we wanted to move to using <a href="http://www.postgresql.org/docs/current/static/app-initdb.html#APP-INITDB-DATA-CHECKSUMS">data checksums</a>. A logical dump via pg_dump was therefore a better choice.</p>

<p>The implicit casts can be added back in via a two-step approach of adding a support function, and then a new cast that uses that function to bind two data types. The canonical list of "missing" casts can be found at <a href="http://petereisentraut.blogspot.com/2008/03/readding-implicit-casts-in-postgresql.html">this blog post by Peter Eisentraut</a>. The first rule of adding back in implicit casts is "don't do it, fix your code instead". The second rule is "only add the bare minimum needed to get your application working". The basic format for re-adding the casts is:</p>

<span class="gsm"><pre>
create function pg_catalog.text(int) returns text immutable language sql as $$select textin(int4out($1))$$

create cast (int as text) with function pg_catalog.text(int) as implicit
</pre></span>

<p>Once we got the pg_dump and import working from version 8.3 to 9.4, some old but familiar errors started popping up that looked like this:</p>

<span class="gsm"><pre>
ERROR:  operator does not exist: text = bigint at character 32
HINT: No operator matches the given name and argument type(s). You might need to
add explicit casts.
</pre></span>

<p>This was quickly fixed by applying the FUNCTION and CAST from above, but why did we have to apply it twice (the original, and after the migration)? The reason is that pg_dump does *NOT* dump custom casts. Yes, this is a bit surprising as pg_dump is supposed to dump a complete logical dump of the database, but casts are a specific exception. Not all casts are ignored by pg_dump - only if both sides of the cast are built-in data types, and everything is in the pg_catalog namespace. It would be nice if this were fixed someday, such that *any* user-created objects are dumped, regardless of their namespace.</p>

<p>There is a way around this, however, and that is to create the function and cast in another namespace. When this is done, pg_dump *WILL* dump the casts. The drawback is that you must ensure the namespace you use is in everyone's search_path, else the casting errors will still occur. The nice thing about pg_catalog is that the namespace is always in your search_path. Being able to dump the added casts has another advantage: creating copies of the database via pg_dump for QA or testing will always work.</p>

<p>So, there is a hard choice when creating custom casts (and this applies to all custom casts, not just the ones to fix the 8.3 implicit cast mess). You can either create your casts inside of pg_catalog, which ensures they are available to all users, but cannot be pg_dumped. Thus, you will need to reapply them anytime you make a copy of the database via a pg_dump (including backups!). Or, you can create them in another schema (e.g. "public"), which means search_path becomes critical, but that you can pg_dump them. I really dislike pg_dump breaking its contract, and lean towards the public schema solution when possible.</p>

<p>Here's a demonstration of the problem and each solution. This is using a Postgres 9.4 instance, and a very simple query to illustrate the problem, using the TEXT datatype and the INT datatype. First, let's create a brand new database and demonstrate the issue:</p>

<span class="gsm"><pre>
psql -c 'drop database if exists casting_test'
<span class="gsm_o">NOTICE:  database "casting_test" does not exist, skipping
DROP DATABASE</span>

psql -c 'create database casting_test'
<span class="gsm_o">CREATE DATABASE</span>

psql casting_test -xtc 'select 123::text = 123::int'
<span class="gsm_o">ERROR:  operator does not exist: text = integer
LINE 1: select 123::text = 123::int
                                 ^
HINT:  No operator matches the given name and argument type(s). You might need to add explicit type casts.</span>
</pre></span>

<p>Now we will fix it by creating a new cast and a supporting function for it. The error disappears. We also confirm that copying the database by using CREATE DATABASE .. TEMPLATE copies our new casts as well:</p>

<span class="gsm"><pre>
psql casting_test -c 'create function <span class="gsm_gb">pg_catalog</span>.text(int) returns text immutable language sql as $$select textin(int4out($1))$$'
<span class="gsm_o">CREATE FUNCTION</span>

psql casting_test -c 'create cast (int as text) with function <span class="gsm_gb">pg_catalog</span>.text(int) as implicit'
<span class="gsm_o">CREATE CAST</span>

psql casting_test -xtc 'select 123::text = 123::int'
<span class="gsm_o"> ?column? | t</span>

psql -c 'create database clone template casting_test'
<span class="gsm_o">CREATE DATABASE</span>

psql clone -xtc 'select 123::text = 123::int'
<span class="gsm_o"> ?column? | t</span>
</pre></span>

<p>Now let's see how pg_dump fails us:</p>

<span class="gsm"><pre>
psql -qc 'drop database if exists casting_test2'
psql -qc 'create database casting_test2'
pg_dump casting_test | psql -q casting_test2
psql casting_test2 -xtc 'select 123::text = 123::int'
<span class="gsm_o">ERROR:  operator does not exist: text = integer
LINE 1: select 123::text = 123::int
                                 ^
HINT:  No operator matches the given name and argument type(s). You might need to add explicit type casts.</span>
</pre></span>

<p>Now let's try it again, this time by putting things into the <b>public</b> schema:</p>

<span class="gsm"><pre>
psql -qc 'drop database if exists casting_test'
psql -qc 'create database casting_test'
psql casting_test -xtc 'select 123::text = 123::int'
<span class="gsm_o">ERROR:  operator does not exist: text = integer
LINE 1: select 123::text = 123::int
                                 ^
HINT:  No operator matches the given name and argument type(s). You might need to add explicit type casts.</span>
psql casting_test -c 'create function <span class="gsm_gb">public</span>.text(int) returns text immutable language sql as $$select textin(int4out($1))$$'
<span class="gsm_o">CREATE FUNCTION</span>

psql casting_test -c 'create cast (int as text) with function <span class="gsm_gb">public</span>.text(int) as implicit'
<span class="gsm_o">CREATE CAST</span>

psql casting_test -xtc 'select 123::text = 123::int'
<span class="gsm_o"> ?column? | t</span>

psql -qc 'drop database if exists casting_test2'
psql -qc 'create database casting_test2'
pg_dump casting_test | psql -q casting_test2
psql casting_test2 -xtc 'select 123::text = 123::int'
<span class="gsm_o"> ?column? | t</span>
</pre></span>

<p>So why does it succeed the second time when using the public schema? By creating the function in a "non-pg" namespace, pg_dump will now dump it and the cast that uses it. This rule is set out in the file <tt>src/bin/pg_dump/pg_dump.c</tt>, with a source code comment stating:</p>

<span class="gsm_indent"><pre>/*
* As per discussion we dump casts if one or more of the underlying
* objects (the conversion function and the data types) are not
* builtin AND if all of the non-builtin objects namespaces are
* included in the dump. Builtin meaning, the namespace name does not
* start with "pg_".
*/</pre></span>

<p>The moral of the story here is to avoid re-adding the implicit casts if at all possible, for it causes a ripple effect of woes. If you do add them, add only the ones you really need, only add them to the databases that need them, and consider using the public schema, not pg_catalog, for the new function. Remember that you can only fix this per database, so any new databases that get created or used by your application will need them applied. As a final blow against using them, the string concatenation operator will probably start giving you new errors if you try to combine any of the data type combinations used in your custom casts!</p>
    </div>
    <div class="feedEntry">

        <a href="http://www.cybertec.at/earthdistance-from-saigon-to-frankfurt/" title="Hans-Juergen Schoenig: Earthdistance: From Saigon to Frankfurt">
            <h2>Hans-Juergen Schoenig: Earthdistance: From Saigon to Frankfurt</h2>
        </a>

        <p class="discreet">
            
            
                  From Planet PostgreSQL.
            
            
                Published on <span name="publication_time">Feb 10, 2015</span>.
            
        </p>

        On my way back from Vietnam I was watching the screen in front of me displaying the “Distance to destination”. On such a long flight the number you see in front of you can be quite depressing so I spent some time to figure out, how this number could be calculated with PostgreSQL. Earthdistance comes [&#8230;]
    </div>
    <div class="feedEntry">

        <a href="http://www.postgresonline.com/journal/archives/346-Querying-MS-Access-and-other-ODBC-data-sources-with-OGR_FDW.html" title="Leo Hsu and Regina Obe: Querying MS Access and other ODBC data sources with OGR_FDW">
            <h2>Leo Hsu and Regina Obe: Querying MS Access and other ODBC data sources with OGR_FDW</h2>
        </a>

        <p class="discreet">
            
            
                  From Planet PostgreSQL.
            
            
                Published on <span name="publication_time">Feb 09, 2015</span>.
            
        </p>

        <p>If you have the OGR_FDW we discussed in <a href="http://www.postgresonline.com/journal/journal/archives/339-OGR-foreign-data-wrapper-on-Windows-first-taste.html" target="_blank">OGR FDW Windows first taste</a> built with ODBC support,
then you can access most any ODBC datasource from PostgreSQL.  This is especially useful for Windows users.  Two of the data sources I've been experimenting with are SQL Server
and MS Access.  In this article, I'll demonstrate how to connect to MS Access with PostgreSQL running on a windows box. I think there is an Access driver for Unix/Linux most robust utilizes java. I won't go there.</p> <br /><a href="http://www.postgresonline.com/journal/archives/346-Querying-MS-Access-and-other-ODBC-data-sources-with-OGR_FDW.html#extended">Continue reading "Querying MS Access and other ODBC data sources with OGR_FDW"</a>
    </div>
    <div class="feedEntry">

        <a href="http://adpgtech.blogspot.com/2015/02/moving-plv8-to-ecmascript6.html" title="Andrew Dunstan: Moving PLV8 to ECMAScript6">
            <h2>Andrew Dunstan: Moving PLV8 to ECMAScript6</h2>
        </a>

        <p class="discreet">
            
            
                  From Planet PostgreSQL.
            
            
                Published on <span name="publication_time">Feb 09, 2015</span>.
            
        </p>

        Taras Mitran has just published <a href="http://ivc.com/blog/better-sql-strings-in-node-js/">a blog post</a> about using some of the advanced features of ECMAScript version 6 to make programming with SQL in JavaScript nicer.<br /><br />He notes that Template Strings allow for multiline strings, which is in itself a significant advance, and that you can also have Tagged Template Strings which can transform the Template String automagically in many interesting ways. His example turns a Template String with embedded variables into a preparable query with a list of parameters. It's very nifty, quite clever in fact.<br /><br />The other feature that I would really like is proper lexically scoped variables. Perl got these donkeys years ago, and their absence this long in JavaScript has been reprehensible. They are provided for in ES 6.<br /><br />My understanding is that to get these features we need to provide for PLV8 to build against the latest version of V8 (and possibly provide some initialization flags too.) Unfortunately, the V8 API seems to have changed significantly since the 3.14.5.10 that's available on my Fedora 20 workstation, so enabling it to build with, say, V8 version 4.1.0.14, which is what <a href="https://iojs.org/">io.js</a> is using, will take quite a bit of work, probably by someone whose C++-fu is greater than mine.
    </div>
    <div class="feedEntry">

        <a href="http://tapoueh.org/blog/2015/02/09-back-from-fosdem-2015.html" title="Dimitri Fontaine: Back From FOSDEM 2015">
            <h2>Dimitri Fontaine: Back From FOSDEM 2015</h2>
        </a>

        <p class="discreet">
            
            
                  From Planet PostgreSQL.
            
            
                Published on <span name="publication_time">Feb 09, 2015</span>.
            
        </p>

        <p>The 
<a href="https://fosdem.org/2015/">FOSDEM 2015</a> edition has been awesome this year, the usual mix of meeting
with old friends, talking about interesting topics, seeing tremendous
activity in all Open Source domains, and having Beldium beers in the
evenings.
</p><center><a href="https://fosdem.org/2015/"><img src="http://tapoueh.org/images/Fosdem-2015-Tizen-Developer2.jpg" /></a></center><h2>FOSDEM PGDAY</h2><p>On the Friday before the real FOSDEM event our own 
<a href="https://www.postgresql.eu/">PostgreSQL Europe</a>
orgnized a one-day event, the 
<a href="http://fosdem2015.pgconf.eu/">FOSDEM PGDAY</a>. It as an intense day of
conferences about PostgreSQL, where I had the opportunity to present
<a href="http://pgloader.io/">pgloader</a> in the context of dealing with database migrations.
</p><center><a href="http://tapoueh.org/images/confs/Fosdem_2015_pgloader.pdf"><img src="http://tapoueh.org/images/confs/Fosdem_2015_pgloader.png" /></a></center><center><em>Migrate from MySQL to PostgreSQL in one command</em></center><h2>PostgreSQL User Group, Paris Meetup</h2><p>This presentation about migrating to PostgreSQL was also given at the
<a href="http://www.meetup.com/PostgreSQL-User-Group-Paris/events/220230052/">PostgreSQL User Group Meetup in Paris</a> more recently, and I'm happy to
announce here that we have more than 200 registered members in the group
now!
</p><p>Check out our 
<a href="http://www.meetup.com/PostgreSQL-User-Group-Paris/events/220351563/">next meetup</a> which is already scheduled!
</p><h2>FOSDEM</h2><p>The at the FOSDEM event proper I had the pleasure to present my recent talk
about backups:
</p><center><a href="http://tapoueh.org/images/confs/Fosdem_2015_backups.pdf"><img src="http://tapoueh.org/images/confs/Fosdem_2015_backups.png" /></a></center><center><em>Nobody cares about backups, think about data recovery</em></center><p>If you want to remember only one thing about that presentation, it must be
that we don't care about how you take backups, we only care about if you're
able to recover data in worst case scenarios. The only to check a backup is
to recover it. Do automated testing of your backups, which means automated
recovery.
</p>
    </div>
    <div class="feedEntry">

        <a href="http://theplateisbad.blogspot.com/2015/02/finding-mass-spectra-with-postgresql_9.html" title="Ernst-Georg Schmid: Finding mass spectra with PostgreSQL: Spectra as function arguments">
            <h2>Ernst-Georg Schmid: Finding mass spectra with PostgreSQL: Spectra as function arguments</h2>
        </a>

        <p class="discreet">
            
            
                  From Planet PostgreSQL.
            
            
                Published on <span name="publication_time">Feb 09, 2015</span>.
            
        </p>

        If the spectra are represented as tables/recordets, like in my last posts on the topic, the question arises how to use a table as an argument to a function in PostgreSQL without creating a custom datatype or using temporary tables.<br /><br />1. As one dimensional array of m/z values followed by the corresponding peak values. The array can then be cut in half and unnested inside the function into a set of records:<br /><br /><span style="font-family: Courier New, Courier, monospace;">select unnest(sdarr[1:1]) as "m/z", unnest(sdarr[2:2]) as peak from ...;</span><br /><br />2. As two dimensional array of m/z values and their corresponding peak values. The partial arrays can then be unnested inside the  function into a set of records:<br /><span style="font-family: Courier New, Courier, monospace;"><br /></span><span style="font-family: Courier New, Courier, monospace;">select unnest(tdarray[1:3]) as "m/z", unnest(tdarray[4:6]) as peak from ...;</span><br /><br />3. As JSON of m/z values and their corresponfing peak values. The JSON can then be converted inside the  function into a set of records:<br /><span style="font-family: Courier New, Courier, monospace;">&nbsp; </span><br /><span style="font-family: Courier New, Courier, monospace;">select * from json_to_recordset( '[{"m/z":1.0,"peak":2.2},{"m/z":3.3,"peak":4.8}]') as x("m/z" double precision, peak double precision);</span><br /><br />All statements above generate a recordset like:<br /><br /><span>m/z&nbsp;&nbsp;&nbsp;&nbsp;peak</span><br /><span>1.0&nbsp;&nbsp;&nbsp;&nbsp;2.2</span><br /><span>3.3&nbsp;&nbsp;&nbsp;&nbsp;4.8</span><br /><span>...&nbsp;&nbsp;&nbsp;&nbsp;...</span><br /><br />In an application, I'd go with JSON, since it has the most understandable structure for a developer against this API and it does not require fiddling around with array support functions of the driver, e.g. like <i>createArrayOf()</i> in JDBC.
    </div>
    <div class="feedEntry">

        <a href="http://okbob.blogspot.com/2015/02/plpgsqlcheck-is-available-for-microsoft.html" title="Pavel Stehule: plpgsql_check is available for Microsoft Windows">
            <h2>Pavel Stehule: plpgsql_check is available for Microsoft Windows</h2>
        </a>

        <p class="discreet">
            
            
                  From Planet PostgreSQL.
            
            
                Published on <span name="publication_time">Feb 07, 2015</span>.
            
        </p>

        I compiled the <a href="https://github.com/okbob/plpgsql_check/">plpgsql_check</a> by Visual Studio 2010 Express. The dll for PostgreSQL 9.2, 9.3, 9.4 and x86 and x64 platform are available in zip archive <a href="http://pgsql.cz/files/plpgsql_check-1.0.1-mswin.zip">http://pgsql.cz/files/plpgsql_check-1.0.1-mswin.zip</a>.<br /><h3>Installation</h3><ol><li>Download, unzip and choose related dll file</li><li>rename to <code>plpgsql_check.dll</code> and copy to PostgreSQL's lib directory (<code>Program Files/PostgreSQL/9.2/lib</code>)</li><li>copy <code>plpgsql_check-1.0.sql</code> and <code>plpgsql_check.control</code> to PostgreSQL's share/extension directory (<code>PostgreSQL/9.2/share/extension</code>).</li></ol><br />It<i> </i>can needed installed a Microsoft Visual C++ 2010 SP1 Redistributable Package <a href="http://www.microsoft.com/en-us/download/details.aspx?id=8328">http://www.microsoft.com/en-us/download/details.aspx?id=8328</a>.
    </div>
    <div class="feedEntry">

        <a href="http://bajis-postgres.blogspot.com/2015/02/someone-asked-me-how-to-change-location.html" title="Baji Shaik: Someone asked me.. &quot;how to change the location of core file generated by postgres&quot;.">
            <h2>Baji Shaik: Someone asked me.. "how to change the location of core file generated by postgres".</h2>
        </a>

        <p class="discreet">
            
            
                  From Planet PostgreSQL.
            
            
                Published on <span name="publication_time">Feb 07, 2015</span>.
            
        </p>

        <div dir="ltr" style="text-align: left;">I remember someone asking me about changing the location of core file generated by postgres. We all know it creates under PGDATA by default, however some people want to avoid that as core file size will be huge some times and eats all space of data directory which will turn into shutdown of cluster. So I thought it will be good if we have an article which shows changing location.<br /><br />On Linux servers, <a href="https://wiki.postgresql.org/wiki/Getting_a_stack_trace_of_a_running_PostgreSQL_backend_on_Linux/BSD#Getting_a_trace_from_a_randomly_crashing_backend">core file generation can be enabled by running "ulimit -c unlimited" before starting the server, or by using the -c option to pg_ctl start. </a>On Windows, if you're running PostgreSQL 9.1, <a href="http://www.postgresql.org/docs/current/static/installation-platform-notes.html#WINDOWS-CRASH-DUMPS">you can create a "crashdumps" subdirectory inside the data directory</a>. &nbsp;On earlier versions, it's <a href="https://wiki.postgresql.org/wiki/Getting_a_stack_trace_of_a_running_PostgreSQL_backend_on_Windows#Random_and_unpredictable_backend_crashes">harder</a>.<br /><br />Before enabling/disabling, if you want to verify if your cluster started to generate core files or not. Ok, I have enabled core file gneration for my cluster, let change the location. Here are detailed steps:<br /><br />-- Start the cluster using "-c" option(cluster user must be set to generate core files).<br />-- Check the core file pattern as root user using below command:<br /><pre class="cpp" name="code">[root@localhost ~]# sysctl kernel.core_pattern<br />kernel.core_pattern = |/usr/libexec/abrt-hook-ccpp %s %c %p %u %g %t e</pre><br />-- Change the kernel.core_pattern to the location in which you want to generate core files(Contact your Admin to do that). Please note that location given in kernel.core_pattern must be writable by the cluster user, or else the kernel will decline to write a core file there.<br /><pre class="cpp" name="code">[root@localhost ~]# echo "kernel.core_pattern=/tmp/core-%e-%s-%u-%g-%p-%t" &gt;&gt; /etc/sysctl.conf<br />[root@localhost ~]# tail -5 /etc/sysctl.conf<br /># max OS transmit buffer size in bytes<br />net.core.wmem_max = 1048576<br />fs.file-max = 6815744<br />########<br />kernel.core_pattern=/tmp/core-%e-%s-%u-%g-%p-%t<br />[root@localhost ~]#<br />[root@localhost ~]#<br />[root@localhost ~]# sysctl -p |tail -5<br />net.core.rmem_max = 4194304<br />net.core.wmem_default = 262144<br />net.core.wmem_max = 1048576<br />fs.file-max = 6815744<br />kernel.core_pattern = /tmp/core-%e-%s-%u-%g-%p-%t<br />[root@localhost ~]#<br />%% - A single % character<br />%p - PID of dumped process<br />%u - real UID of dumped process<br />%g - real GID of dumped process<br />%s - number of signal causing dump<br />%t - time of dump (seconds since 0:00h, 1 Jan 1970)<br />%h - hostname (same as ’nodename’ returned by uname(2))<br />%e - executable filename</pre><br />-- Verify if cluster is started to generate core file.<br /><pre class="cpp" name="code">bash-4.1$ ps -ef|grep data|grep "9.3"<br />504       3405     1  0 20:44 ?        00:00:00 /opt/PostgresPlus/9.3AS/bin/edb-postgres -D /opt/PostgresPlus/9.3AS/data<br />postgres  6155     1  0 21:37 pts/0    00:00:00 /opt/PostgreSQL/9.3/bin/postgres -D /opt/PostgreSQL/9.3/data<br />bash-4.1$ grep -i core /proc/6155/limits<br />Max core file size        unlimited            unlimited            bytes  <br />bash-4.1$</pre><br />-- Check if cluster crash creates core files in the given location. Let me kill a process to do generate core.<br /><pre class="sql" name="code">bash-4.1$ ps -ef|grep 6155<br />postgres  6155     1  0 21:37 pts/0    00:00:00 /opt/PostgreSQL/9.3/bin/postgres -D /opt/PostgreSQL/9.3/data<br />postgres  6156  6155  0 21:37 ?        00:00:00 postgres: logger process                                  <br />postgres  6158  6155  0 21:37 ?        00:00:00 postgres: checkpointer process                            <br />postgres  6159  6155  0 21:37 ?        00:00:00 postgres: writer process                                  <br />postgres  6160  6155  0 21:37 ?        00:00:00 postgres: wal writer process                              <br />postgres  6161  6155  0 21:37 ?        00:00:00 postgres: autovacuum launcher process                    <br />postgres  6162  6155  0 21:37 ?        00:00:00 postgres: stats collector process                        <br />postgres  6527  6001  0 21:38 pts/0    00:00:00 grep 6155<br /><br />bash-4.1$ kill -ABRT 6159  -- Killing writer process to get core dump.<br />bash-4.1$<br />bash-4.1$<br />bash-4.1$ ls -ltrh /tmp/core*postgre*<br />-rw-------. 1 postgres postgres 143M Feb  7 21:41 /tmp/core-postgres-6-501-501-6159-1423325468<br />bash-4.1$<br />bash-4.1$ date<br />Sat Feb  7 21:41:25 IST 2015</pre><br />-- Check the log entries<br /><pre class="cpp" name="code">-bash-4.1$ grep "6159"  postgresql-2015-02-07_213749.log<br />2015-02-07 21:41:09 IST LOG:  background writer process (PID 6159) was terminated by signal 6: Aborted</pre><br />Wow, it generated in new location. Any comments/suggestions are most welcome.<br /><br /></div>
    </div>
    <div class="feedEntry">

        <a href="http://www.databasesoup.com/2015/02/a-statement-on-recent-conference-events.html" title="Josh Berkus: A statement on recent conference events">
            <h2>Josh Berkus: A statement on recent conference events</h2>
        </a>

        <p class="discreet">
            
            
                  From Planet PostgreSQL.
            
            
                Published on <span name="publication_time">Feb 06, 2015</span>.
            
        </p>

        The PostgreSQL user group in Moscow is currently conducting their <a href="http://www.pgconf.ru/">first-ever PostgreSQL-themed conference</a>, which has been a tremendous success.&nbsp; Unfortunately, the venue booked by the conference chose to include inappropriate dancers as part of their entertaiment package. The conference organizers and the Russian PostgreSQL community were not aware of the nature of the entertainment supplied ahead of time.<br /><br />The PostgreSQL Core Team believes there is no place for inappropriate or discriminatory behaviour at PostgreSQL conferences and try to ensure that all our conferences are suitable for anyone to attend. As PostgreSQL is an Open Source project with volunteer contributors and a federated organizational structure, we do not have supervisory control over how individual conferences are organized, which means that sometimes they do not benefit from general community experience.<br /><br />The Russian conference organizers are expected to comment on this unforseen incident once the conference is concluded. The international community will be working with them to make sure that this mistake is not repeated.<br /><br />Josh Berkus<br />On Behalf of the PostgreSQL Core Team<br />and the PostgreSQL Global Development Project
    </div>
    <div class="feedEntry">

        <a href="http://pgedit.com:80/pgedit-textmate-2-2" title="John DeSoi: pgEdit 2.2 released">
            <h2>John DeSoi: pgEdit 2.2 released</h2>
        </a>

        <p class="discreet">
            
            
                  From Planet PostgreSQL.
            
            
                Published on <span name="publication_time">Feb 05, 2015</span>.
            
        </p>

        <div class="field field-name-body field-type-text-with-summary field-label-hidden"><div class="field-items"><div class="field-item even"><p>pgEdit has been updated to work with TextMate 2. The syntax highlighting grammar now supports all PostgreSQL 9.3 keywords and SQL commands.</p>
<p>This update also includes other minor fixes and improvements related to syntax highlighting, completion, and dropping SQL objects.</p>
<p>See the <a href="http://pgedit.com:80/download">Download page</a> for the latest release of pgEdit.</p>
<p>The source code for the pgEdit TextMate bundle available on GitHub at <a href="https://github.com/desoi/pgedit-textmate"> https://github.com/desoi/pgedit-textmate</a>.</p>
<!--break--></div></div></div>
    </div>
    <div class="feedEntry">

        <a href="https://pdxpug.wordpress.com/2015/02/05/pdxpug-february-meeting-in-two-weeks/" title="gabrielle roth: PDXPUG: February meeting in two weeks">
            <h2>gabrielle roth: PDXPUG: February meeting in two weeks</h2>
        </a>

        <p class="discreet">
            
            
                  From Planet PostgreSQL.
            
            
                Published on <span name="publication_time">Feb 05, 2015</span>.
            
        </p>

        <p><strong>When:</strong> 6-8pm Thu Feb 19, 2015<br />
<strong>Where:</strong> Iovation<br />
<strong>Who:</strong> David Kerr<br />
<strong>What:</strong> Using Bucardo to Migrate your Pg database to RDS with minimal downtime</p>
<p>As a followup to January&#8217;s RDS discussion, Dave Kerr works through strategies to move your existing Postgres database into RDS.</p>
<p>Using Bucardo and Master/Master Replication we can achieve a migration to RDS with minimal or no downtime.</p>
<p>Dave will show some tools and techniques so help facilitate this transition as well as go over the idiosyncrasies of using Bucardo with RDS.</p>
<p>&#8212;</p>
<p>Our meeting will be held at Iovation, on the 32nd floor of the US Bancorp Tower at 111 SW 5th (5th &amp; Oak).  It&#8217;s right on the Green &amp; Yellow Max lines.  Underground bike parking is available in the parking garage;  outdoors all around the block in the usual spots.  No bikes in the office, sorry!</p>
<p>Elevators open at 5:45 and building security closes access to the floor at 6:30.</p>
<p>The building is on the Green &amp; Yellow Max lines.  Underground bike parking is available in the parking garage;  outdoors all around the block in the usual spots.</p>
<p>See you there!</p><br />  <a href="http://feeds.wordpress.com/1.0/gocomments/pdxpug.wordpress.com/419/" rel="nofollow"><img alt="" border="0" src="http://feeds.wordpress.com/1.0/comments/pdxpug.wordpress.com/419/" /></a> <img alt="" border="0" height="1" src="https://pixel.wp.com/b.gif?host=pdxpug.wordpress.com&#038;blog=30930172&#038;post=419&#038;subd=pdxpug&#038;ref=&#038;feed=1" width="1" />
    </div>
    <div class="feedEntry">

        <a href="http://www.databasesoup.com/2015/02/some-notes-on-todays-update-release.html" title="Josh Berkus: Some notes on today's update release">
            <h2>Josh Berkus: Some notes on today's update release</h2>
        </a>

        <p class="discreet">
            
            
                  From Planet PostgreSQL.
            
            
                Published on <span name="publication_time">Feb 05, 2015</span>.
            
        </p>

        We released a security and <a href="http://www.postgresql.org/about/news/1569/">cumulative bugfix release to all supported versions today</a>.&nbsp; That means it's update time.&nbsp; What follows is my personal advice on the update.<br /><br />For the first time in a while, we have a bunch of "low-risk" security fixes in this release, but no "critical" security fixes.&nbsp; The reason I put those terms in quotes is that it doesn't matter how critical the fixes are in general; it matters how critical they are <i>to you</i>.&nbsp; So you should definitely read over <a href="http://www.postgresql.org/docs/current/static/release-9-4-1.html">the release notes</a> and the <a href="http://www.postgresql.org/support/security/">CVE notices</a> to check how they affect you.<br /><br />All five of the security holes patched require prior authentication.&nbsp; Four of the five have not been proven to have an actual privilege escalation vector; they may be only denial-of-service attacks.&nbsp; And the fifth security issue only affects you if you are using per-column privileges for columns with constraints on them.&nbsp; That's why I regard these issues as relatively "low-risk".<br /><br />There are also some important fixes to performance and replication for versions 9.4 and 9.3, so users of those versions should apply the update soon.&nbsp; For other users, unless you live in the Fiji Islands or other places affected by timezone changes, you can probably wait for your next scheduled maintenance window.&nbsp; You do have scheduled maintenance windows, yes?<br /><br />Other people who might care to apply this update sooner rather than later include:<br /><ul><li>Users who have already had issues with autovacuum</li><li>People using the new logical decoding</li><li>Users who have a single archive which is shared between master and replicas.</li><li>Folks who create a bunch of tablespaces.</li><li>Developers who use tsquery, xpath(), and/or complex regular expression searches</li><li>JSONB users.</li><li>Norwegians who use Postgres on Windows</li><li>Users who have reported bugs with explicit locking and deadlocking in the last few months.</li></ul>Again, though, read <a href="http://www.postgresql.org/docs/current/static/release.html">the release notes</a>.&nbsp; Because it's always possible that we fixed a bug that already affects you.
    </div>
    <div class="feedEntry">

        <a href="http://www.sqlobjectifier.com/2015/02/enity-attribute-value-model-for-or.html" title="Erik Van Norstrand: Enity-Attribute-Value Model - For or Against">
            <h2>Erik Van Norstrand: Enity-Attribute-Value Model - For or Against</h2>
        </a>

        <p class="discreet">
            
            
                  From Planet PostgreSQL.
            
            
                Published on <span name="publication_time">Feb 05, 2015</span>.
            
        </p>

        Earlier today, much to my excitement, I got my first comment on one of my blog posts! That comment mentioned that I might be reinventing the "Entity-Attribute-Value Anti Pattern." I had never heard of this term, I am still quite young in my professional development career, so I turned to the best resource for discovering new things: Google!

So what is an Entity-Attribute-Value (EAV) Anti Pattern
    </div>
    <div class="feedEntry">

        <a href="http://obartunov.livejournal.com/179994.html" title="Oleg Bartunov: My first postgres post (Sep 8, 1995) !">
            <h2>Oleg Bartunov: My first postgres post (Sep 8, 1995) !</h2>
        </a>

        <p class="discreet">
            
            
                  From Planet PostgreSQL.
            
            
                Published on <span name="publication_time">Feb 05, 2015</span>.
            
        </p>

        I always said I joined postgres community in 1996, but today I found an archive of old emails and found this message I sent Sep 8, 1995 year (a day before my birthday) ! Another message from Sep 7, 1995 was my subscription to mailing list postgres95@postgres.berkeley.edu, managed by "The Postgres95 Team (Jolly Chen & Andrew Yu)"<br /><br />=============================================================================================================<br />From owner-postgres95@postgres.Berkeley.EDU Fri Sep  8 14:18 MSK 1995<br />Received: from nobozo.CS.Berkeley.EDU (nobozo.CS.Berkeley.EDU [128.32.34.58]) by ra.sai.msu.su (8.6.9/8.6.9) with ESMTP id OAA13008 for &lt;megera@sai.msu.su&gt;; Fri, 8 Sep 1995 14:13:23 +0400<br />Received: from localhost.Berkeley.EDU (localhost.Berkeley.EDU [127.0.0.1]) by nobozo.CS.Berkeley.EDU (8.6.10/8.6.3) with SMTP id AAA28756 for postgres95-redist; Fri, 8 Sep 1995 00:09:27 -0700<br />Received: from ra.sai.msu.su (ra.sai.msu.su [158.250.29.2]) by nobozo.CS.Berkeley.EDU (8.6.10/8.6.3) with ESMTP id AAA14418 for &lt;postgres95@postgres.berkeley.edu&gt;; Fri, 8 Sep 1995 00:09:22 -0700<br />Received: (from megera@localhost) by ra.sai.msu.su (8.6.9/8.6.9) id LAA12681; Fri, 8 Sep 1995 11:08:12 +0400<br />Resent-From: Postgres95 Team &lt;pglite@postgres.berkeley.edu&gt;<br />Resent-Message-Id: &lt;199509080709.AAA28756@nobozo.CS.Berkeley.EDU&gt;<br />X-Authentication-Warning: nobozo.CS.Berkeley.EDU: Host localhost.Berkeley.EDU didn't use HELO protocol<br />Sender: owner-postgres95@postgres.Berkeley.EDU<br />X-Return-Path: andrew_yu<br />Date: Fri, 8 Sep 1995 11:08:09 +0400 (MSK DST)<br />From: "O.Bartunov" &lt;megera@sai.msu.su&gt;<br />X-Sender: megera@ra<br />To: postgres95@nobozo.CS.Berkeley.EDU<br />Subject: Timeout: postgres95 v.1.0 under Solaris 2.4 (Sparc 10)<br />Message-ID: &lt;pine.sv4.3.91.950908110042.12664a-100000@ra&gt;<br />MIME-Version: 1.0<br />Resent-To: postgres95-redist@nobozo.CS.Berkeley.EDU<br />Resent-Date: Fri, 08 Sep 95 00:09:26 -0700<br />Resent-XMts: smtp<br />Content-Type: TEXT/PLAIN; charset=US-ASCII<br />Content-Length: 1079<br />Status: RO<br />X-Status:<br />X-Keywords:<br />X-UID: 497<br /><br />Hi there,<br />I'm new in this group.<br />I try to install postgres95 v.1.0 on my Sparc 10/51 running Solaris 2.4.<br />Compilation (with gcc 2.6.3) proceeded very smoothly, I only edit Makefile<br />for psql (remove -lhistory because it's already included in readline<br />library (v.2.0)). But when I running regression test it's failed: timeout.<br />I used default value 60 sec. and 120 sec. without success.<br />The same situation was also with v.0.3beta.<br />I would very appreciate any help.<br /><br />        thanks,<br />                Oleg<br />=========================================================================================<br /><br />Interesting, that I found Bruce Momjian in post from Jul 17, 1996 with subject: PostGres95 1.01.5.<br />This message was already managed not in Berkeley, but by "Marc G. Fournier" &lt;scrappy@ki.net&gt;
    </div>
    <div class="feedEntry">

        <a href="http://danielpocock.com/debian-maintainer-dashboard-now-provides-icalendar-feeds" title="Daniel Pocock: Debian Maintainer Dashboard now provides iCalendar feeds">
            <h2>Daniel Pocock: Debian Maintainer Dashboard now provides iCalendar feeds</h2>
        </a>

        <p class="discreet">
            
            
                  From Planet PostgreSQL.
            
            
                Published on <span name="publication_time">Feb 05, 2015</span>.
            
        </p>

        <div class="field field-name-body field-type-text-with-summary field-label-hidden"><div class="field-items"><div class="field-item even"><p>Contributors to Debian can now monitor their list of pending activities using <a href="http://en.wikipedia.org/wiki/ICalendar">iCalendar</a> clients on their desktop or mobile device.</p>
<p>Thanks to the tremendous work of the <a href="https://qa.debian.org/">Debian QA team</a>, the <a href="https://udd.debian.org/">Ultimate Debian Database</a> has been scooping up data from all around the Debian universe and storing it in a <a href="http://www.postgresql.org/">PostgreSQL</a> back-end.  The <a href="https://udd.debian.org/dmd/">Debian Maintainer Dashboard</a> allows developers to see a summary of outstanding issues across all their packages in a range of different formats.</p>
<p>With today's update, an aggregated list of Debian tasks and to-dos can now be rendered in iCalendar format and loaded into a range of productivity tools.</p>
<h3>Using the iCalendar URL</h3>
<p>Many productivity tools like <a href="https://www.mozilla.org/en-US/projects/calendar/">Mozilla Lightning</a> (<a href="https://packages.debian.org/iceowl-extension">Iceowl extension</a> on Debian) allow you to poll any calendar or task list just using a URL.</p>
<p>For UDD iCalendar feeds, the URLs look like this:</p>
<pre>
https://udd.debian.org/dmd/?format=ics&amp;email1=daniel%40pocock.pro
</pre><p>You can also get the data by visiting the <a href="https://udd.debian.org/dmd/">Debian Maintainer Dashboard</a>, filling out the form and selecting the iCalendar output format.</p>
<h3>Next steps</h3>
<p>Currently, the priority and deadline attributes are not set on any of the tasks in the feed.  The strategy of prioritizing issues has been raised in <a href="http://bugs.debian.org/777112">bug #777112</a>.</p>
<p>iCalendar also supports other possibilities such as categories and reminders/alarms.  It is likely that each developer has their own personal preferences about using these features.  Giving feedback through the <a href="https://lists.debian.org/debian-qa/">Debian QA mailing list</a> or the bug tracker is welcome.</p>
<h3>Screenshots</h3>
<p><img src="http://danielpocock.com/sites/danielpocock.com/files/dmd-icalendar-setup.png" /></p>
<p><img src="http://danielpocock.com/sites/danielpocock.com/files/dmd-icalendar.png" /></p>
</div></div></div>
    </div>
    <div class="feedEntry">

        <a href="http://theplateisbad.blogspot.com/2015/02/count-is-faster-than-count1-not-in-94.html" title="Ernst-Georg Schmid: count(*) is faster than count(1) - not in 9.4">
            <h2>Ernst-Georg Schmid: count(*) is faster than count(1) - not in 9.4</h2>
        </a>

        <p class="discreet">
            
            
                  From Planet PostgreSQL.
            
            
                Published on <span name="publication_time">Feb 05, 2015</span>.
            
        </p>

        In PostgreSQL 9.4, <span>count(1)</span> speed is equal to <span>count(*)</span>. Another reason to upgrade to 9.4.<br /><br /><span>count(&lt;column&gt;)</span> is still slower if no index is used...
    </div>
    <div class="feedEntry">

        <a href="http://blog.ioguix.net/postgresql/2015/02/05/Partitionning-and-constraints-part-1.html" title="Jehan-Guillaume (ioguix) de Rorthais: Partitioning and constraints part 1 - UNIQUE">
            <h2>Jehan-Guillaume (ioguix) de Rorthais: Partitioning and constraints part 1 - UNIQUE</h2>
        </a>

        <p class="discreet">
            
            
                  From Planet PostgreSQL.
            
            
                Published on <span name="publication_time">Feb 05, 2015</span>.
            
        </p>

        <p>Partitioning in PostgreSQL has been an artisanal work for a long time now. And despite the <a href="http://www.postgresql.org/message-id/20140829155607.GF7705@eldon.alvh.no-ip.org">current discussion</a> running since few month on PostgreSQL&#8217;s hackers mailing list, it will probably stay this way for some time again. Just because it requires a lot of brainstorm and work.</p>
<p>Nowadays, I believe the current state of partitioning under PostgreSQL is quite well documented and under control most of the time. You can find a lot of informations about that online, starting by <a href="http://www.postgresql.org/docs/9.4/static/ddl-partitioning.html">PostgreSQL documentation</a> itself, but about tooling as well, extension, etc.</p>
<p>However, there&#8217;s still a dark side, not well covered or understood about partitioning under PostgreSQL: constraints related to them. More specifically unique constraints covering all partitions of a partitioned table and how to refer to them from foreign keys. This series of article analysis how to implement them by hands ourself thanks to some PostgreSQL great features, detailing how to avoid major traps. You will see that crafting these «constraints» wannabes requires some attention, but is definitely doable, in a clean way.</p>
<p>As this subject requires quite some details and explanations, I decided to split it in multiple articles. This first part is about creating a <span class="caps">UNIQUE</span> constraint across all partitions of a table. Next one covers how to reference a partitioned table. And maybe some other depending on the motivation, inspiration and feedback.</p>
<h2>Study case</h2>
<p>I chose to illustrate this article with a table partitioned by date range. This is a fairly frequent practice and adapting this article to another partitioning scheme is quite easy anyway.</p>
<p>Range partitioning on the PK has no challenge: each value of the PK could only live in strictly one child, each of them enforcing the PK internally. So the uniqueness of this PK across the partitions is already enforced by constraints <span class="caps">CHECK</span> and <span class="caps">UNIQUE</span> of each partition. That&#8217;s why my study case partition range using a <code>timestampstz</code> column. As the CHECKs do not apply on the primary key values, each of its values can be in any partition, which can lead to duplicate values residing in different partitions. Exactly what we really want to avoid.</p>
<p>So here is the dummy schema with table &#8220;master&#8221; partitioned across 5 childs using a date range key partitioning <code>ts</code>.</p>
<div class="highlight"><pre><code class="language-sql"><span class="k">BEGIN</span><span class="p">;</span>

<span class="k">DROP</span> <span class="k">TABLE</span> <span class="n">IF</span> <span class="k">EXISTS</span> <span class="n">master</span><span class="p">,</span>
  <span class="n">child0</span><span class="p">,</span> <span class="n">child1</span><span class="p">,</span> <span class="n">child2</span><span class="p">,</span> <span class="n">child3</span><span class="p">,</span> <span class="n">child4</span><span class="p">;</span>

<span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">master</span> <span class="p">(</span>
  <span class="n">id</span>        <span class="nb">serial</span> <span class="k">PRIMARY</span> <span class="k">KEY</span><span class="p">,</span>
  <span class="n">dummy</span>     <span class="nb">int</span> <span class="k">DEFAULT</span> <span class="p">(</span><span class="n">random</span><span class="p">()</span><span class="o">*</span><span class="mi">31449600</span><span class="p">)::</span><span class="nb">int</span><span class="p">,</span>
  <span class="k">comment</span>   <span class="nb">text</span><span class="p">,</span>
  <span class="n">ts</span>        <span class="n">timestamptz</span>
<span class="p">);</span>

<span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">child0</span> <span class="p">(</span>
  <span class="k">PRIMARY</span> <span class="k">KEY</span> <span class="p">(</span><span class="n">id</span><span class="p">),</span>
  <span class="k">CHECK</span> <span class="p">(</span> <span class="n">ts</span> <span class="o">&gt;=</span> <span class="s1">'2010-01-01 00:00:00'</span> <span class="k">AND</span> <span class="n">ts</span> <span class="o">&lt;</span> <span class="s1">'2011-01-01 00:00:00'</span> <span class="p">)</span>
<span class="p">)</span> <span class="k">INHERITS</span> <span class="p">(</span> <span class="n">master</span> <span class="p">);</span>

<span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">child1</span> <span class="p">(</span>
  <span class="k">PRIMARY</span> <span class="k">KEY</span> <span class="p">(</span><span class="n">id</span><span class="p">),</span>
  <span class="k">CHECK</span> <span class="p">(</span> <span class="n">ts</span> <span class="o">&gt;=</span> <span class="s1">'2011-01-01 00:00:00'</span> <span class="k">AND</span> <span class="n">ts</span> <span class="o">&lt;</span> <span class="s1">'2012-01-01 00:00:00'</span> <span class="p">)</span>
<span class="p">)</span> <span class="k">INHERITS</span> <span class="p">(</span> <span class="n">master</span> <span class="p">);</span>

<span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">child2</span> <span class="p">(</span>
  <span class="k">PRIMARY</span> <span class="k">KEY</span> <span class="p">(</span><span class="n">id</span><span class="p">),</span>
  <span class="k">CHECK</span> <span class="p">(</span> <span class="n">ts</span> <span class="o">&gt;=</span> <span class="s1">'2012-01-01 00:00:00'</span> <span class="k">AND</span> <span class="n">ts</span> <span class="o">&lt;</span> <span class="s1">'2013-01-01 00:00:00'</span> <span class="p">)</span>
<span class="p">)</span> <span class="k">INHERITS</span> <span class="p">(</span> <span class="n">master</span> <span class="p">);</span>

<span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">child3</span> <span class="p">(</span>
  <span class="k">PRIMARY</span> <span class="k">KEY</span> <span class="p">(</span><span class="n">id</span><span class="p">),</span>
  <span class="k">CHECK</span> <span class="p">(</span> <span class="n">ts</span> <span class="o">&gt;=</span> <span class="s1">'2013-01-01 00:00:00'</span> <span class="k">AND</span> <span class="n">ts</span> <span class="o">&lt;</span> <span class="s1">'2014-01-01 00:00:00'</span> <span class="p">)</span>
<span class="p">)</span> <span class="k">INHERITS</span> <span class="p">(</span> <span class="n">master</span> <span class="p">);</span>

<span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">child4</span> <span class="p">(</span>
  <span class="k">PRIMARY</span> <span class="k">KEY</span> <span class="p">(</span><span class="n">id</span><span class="p">),</span>
  <span class="k">CHECK</span> <span class="p">(</span> <span class="n">ts</span> <span class="o">&gt;=</span> <span class="s1">'2014-01-01 00:00:00'</span> <span class="k">AND</span> <span class="n">ts</span> <span class="o">&lt;</span> <span class="s1">'2015-01-01 00:00:00'</span> <span class="p">)</span>
<span class="p">)</span> <span class="k">INHERITS</span> <span class="p">(</span> <span class="n">master</span> <span class="p">);</span>

<span class="k">CREATE</span> <span class="k">INDEX</span> <span class="k">ON</span> <span class="n">child0</span> <span class="p">(</span><span class="n">ts</span><span class="p">);</span>
<span class="k">CREATE</span> <span class="k">INDEX</span> <span class="k">ON</span> <span class="n">child1</span> <span class="p">(</span><span class="n">ts</span><span class="p">);</span>
<span class="k">CREATE</span> <span class="k">INDEX</span> <span class="k">ON</span> <span class="n">child2</span> <span class="p">(</span><span class="n">ts</span><span class="p">);</span>
<span class="k">CREATE</span> <span class="k">INDEX</span> <span class="k">ON</span> <span class="n">child3</span> <span class="p">(</span><span class="n">ts</span><span class="p">);</span>
<span class="k">CREATE</span> <span class="k">INDEX</span> <span class="k">ON</span> <span class="n">child4</span> <span class="p">(</span><span class="n">ts</span><span class="p">);</span>

<span class="k">ALTER</span> <span class="k">TABLE</span> <span class="n">child0</span> <span class="k">ALTER</span> <span class="n">ts</span> <span class="k">SET</span>
  <span class="k">DEFAULT</span> <span class="n">TIMESTAMPTZ</span> <span class="s1">'2010-01-01 00:00:00'</span> <span class="o">+</span> <span class="p">(</span><span class="n">random</span><span class="p">()</span><span class="o">*</span><span class="mi">31449600</span><span class="p">)::</span><span class="nb">int</span> <span class="o">*</span> <span class="nb">INTERVAL</span> <span class="s1">'1s'</span><span class="p">;</span>
<span class="k">ALTER</span> <span class="k">TABLE</span> <span class="n">child1</span> <span class="k">ALTER</span> <span class="n">ts</span> <span class="k">SET</span>
  <span class="k">DEFAULT</span> <span class="n">TIMESTAMPTZ</span> <span class="s1">'2011-01-01 00:00:00'</span> <span class="o">+</span> <span class="p">(</span><span class="n">random</span><span class="p">()</span><span class="o">*</span><span class="mi">31449600</span><span class="p">)::</span><span class="nb">int</span> <span class="o">*</span> <span class="nb">INTERVAL</span> <span class="s1">'1s'</span><span class="p">;</span>
<span class="k">ALTER</span> <span class="k">TABLE</span> <span class="n">child2</span> <span class="k">ALTER</span> <span class="n">ts</span> <span class="k">SET</span>
  <span class="k">DEFAULT</span> <span class="n">TIMESTAMPTZ</span> <span class="s1">'2012-01-01 00:00:00'</span> <span class="o">+</span> <span class="p">(</span><span class="n">random</span><span class="p">()</span><span class="o">*</span><span class="mi">31449600</span><span class="p">)::</span><span class="nb">int</span> <span class="o">*</span> <span class="nb">INTERVAL</span> <span class="s1">'1s'</span><span class="p">;</span>
<span class="k">ALTER</span> <span class="k">TABLE</span> <span class="n">child3</span> <span class="k">ALTER</span> <span class="n">ts</span> <span class="k">SET</span>
  <span class="k">DEFAULT</span> <span class="n">TIMESTAMPTZ</span> <span class="s1">'2013-01-01 00:00:00'</span> <span class="o">+</span> <span class="p">(</span><span class="n">random</span><span class="p">()</span><span class="o">*</span><span class="mi">31449600</span><span class="p">)::</span><span class="nb">int</span> <span class="o">*</span> <span class="nb">INTERVAL</span> <span class="s1">'1s'</span><span class="p">;</span>
<span class="k">ALTER</span> <span class="k">TABLE</span> <span class="n">child4</span> <span class="k">ALTER</span> <span class="n">ts</span> <span class="k">SET</span>
  <span class="k">DEFAULT</span> <span class="n">TIMESTAMPTZ</span> <span class="s1">'2014-01-01 00:00:00'</span> <span class="o">+</span> <span class="p">(</span><span class="n">random</span><span class="p">()</span><span class="o">*</span><span class="mi">31449600</span><span class="p">)::</span><span class="nb">int</span> <span class="o">*</span> <span class="nb">INTERVAL</span> <span class="s1">'1s'</span><span class="p">;</span>

<span class="k">COMMIT</span><span class="p">;</span></code></pre></div><p>The <code>SET DEFAULT</code> are only there to keep other commands simple to read. Note that I do not create the trigger on <span class="caps">INSERT</span> and <span class="caps">UPDATE</span> on the master table. This is out of the scope of this article, will not be needed and add no challenge to the subject.</p>
<h2>The naive solution</h2>
<p>Of course, the whole trick revolves around triggers. We have to check the uniqueness of a PK value across all partitions after any <span class="caps">INSERT</span> or <span class="caps">UPDATE</span> on any of them, for each rows. Let&#8217;s dive in and get wet with a first naive version of such a trigger:</p>
<div class="highlight"><pre><code class="language-sql"><span class="k">CREATE</span> <span class="k">OR</span> <span class="k">REPLACE</span> <span class="k">FUNCTION</span> <span class="n">master_id_pkey</span><span class="p">()</span> 
  <span class="k">RETURNS</span> <span class="k">trigger</span> 
  <span class="k">LANGUAGE</span> <span class="n">plpgsql</span> 
<span class="k">AS</span> <span class="err">$$</span>
<span class="k">BEGIN</span>
  <span class="n">IF</span> <span class="k">count</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="k">FROM</span> <span class="n">master</span> <span class="k">WHERE</span> <span class="n">id</span> <span class="o">=</span> <span class="k">NEW</span><span class="p">.</span><span class="n">id</span> <span class="k">THEN</span>
    <span class="n">RAISE</span> <span class="k">EXCEPTION</span> <span class="s1">'duplicate key value violates unique constraint &quot;%&quot; ON &quot;%&quot;'</span><span class="p">,</span> 
      <span class="n">TG_NAME</span><span class="p">,</span> <span class="n">TG_TABLE_NAME</span> 
      <span class="k">USING</span> <span class="n">DETAIL</span> <span class="o">=</span> <span class="n">format</span><span class="p">(</span><span class="s1">'Key (id)=(%s) already exists.'</span><span class="p">,</span> <span class="k">NEW</span><span class="p">.</span><span class="n">id</span><span class="p">);</span>
  <span class="k">END</span> <span class="n">IF</span><span class="p">;</span>

  <span class="k">RETURN</span> <span class="k">NULL</span><span class="p">;</span>
<span class="k">END</span>
<span class="err">$$</span><span class="p">;</span>

<span class="k">CREATE</span> <span class="k">TRIGGER</span> <span class="n">children_id_pkey</span> <span class="k">AFTER</span> <span class="k">INSERT</span> <span class="k">OR</span> <span class="k">UPDATE</span> <span class="k">ON</span> <span class="n">master</span>
     <span class="k">FOR</span> <span class="k">EACH</span> <span class="k">ROW</span> <span class="k">EXECUTE</span> <span class="k">PROCEDURE</span> <span class="k">public</span><span class="p">.</span><span class="n">master_id_pkey</span><span class="p">();</span>
<span class="k">CREATE</span> <span class="k">TRIGGER</span> <span class="n">children_id_pkey</span> <span class="k">AFTER</span> <span class="k">INSERT</span> <span class="k">OR</span> <span class="k">UPDATE</span> <span class="k">ON</span> <span class="n">child0</span>
     <span class="k">FOR</span> <span class="k">EACH</span> <span class="k">ROW</span> <span class="k">EXECUTE</span> <span class="k">PROCEDURE</span> <span class="k">public</span><span class="p">.</span><span class="n">master_id_pkey</span><span class="p">();</span>
<span class="k">CREATE</span> <span class="k">TRIGGER</span> <span class="n">children_id_pkey</span> <span class="k">AFTER</span> <span class="k">INSERT</span> <span class="k">OR</span> <span class="k">UPDATE</span> <span class="k">ON</span> <span class="n">child1</span>
     <span class="k">FOR</span> <span class="k">EACH</span> <span class="k">ROW</span> <span class="k">EXECUTE</span> <span class="k">PROCEDURE</span> <span class="k">public</span><span class="p">.</span><span class="n">master_id_pkey</span><span class="p">();</span>
<span class="k">CREATE</span> <span class="k">TRIGGER</span> <span class="n">children_id_pkey</span> <span class="k">AFTER</span> <span class="k">INSERT</span> <span class="k">OR</span> <span class="k">UPDATE</span> <span class="k">ON</span> <span class="n">child2</span>
     <span class="k">FOR</span> <span class="k">EACH</span> <span class="k">ROW</span> <span class="k">EXECUTE</span> <span class="k">PROCEDURE</span> <span class="k">public</span><span class="p">.</span><span class="n">master_id_pkey</span><span class="p">();</span>
<span class="k">CREATE</span> <span class="k">TRIGGER</span> <span class="n">children_id_pkey</span> <span class="k">AFTER</span> <span class="k">INSERT</span> <span class="k">OR</span> <span class="k">UPDATE</span> <span class="k">ON</span> <span class="n">child3</span>
     <span class="k">FOR</span> <span class="k">EACH</span> <span class="k">ROW</span> <span class="k">EXECUTE</span> <span class="k">PROCEDURE</span> <span class="k">public</span><span class="p">.</span><span class="n">master_id_pkey</span><span class="p">();</span>
<span class="k">CREATE</span> <span class="k">TRIGGER</span> <span class="n">children_id_pkey</span> <span class="k">AFTER</span> <span class="k">INSERT</span> <span class="k">OR</span> <span class="k">UPDATE</span> <span class="k">ON</span> <span class="n">child4</span>
     <span class="k">FOR</span> <span class="k">EACH</span> <span class="k">ROW</span> <span class="k">EXECUTE</span> <span class="k">PROCEDURE</span> <span class="k">public</span><span class="p">.</span><span class="n">master_id_pkey</span><span class="p">();</span></code></pre></div><p>Obviously, each partition need the trigger to check that the PK value it is about to write does not already exist in one of its siblings. The trigger function itself is quite easy to understand: if we find a row with the same value as the PK, raise an exception. Tests sounds promising:</p>
<div class="highlight"><pre><code class="language-psql"><span class="gp">=#</span> <span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">child0</span> <span class="p">(</span><span class="k">comment</span><span class="p">)</span> <span class="k">VALUES</span> <span class="p">(</span><span class="s1">'test 1'</span><span class="p">);</span>
<span class="gp">=#</span> <span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">child1</span> <span class="p">(</span><span class="k">comment</span><span class="p">)</span> <span class="k">VALUES</span> <span class="p">(</span><span class="s1">'test 2'</span><span class="p">);</span>
<span class="gp">=#</span> <span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">child2</span> <span class="p">(</span><span class="k">comment</span><span class="p">)</span> <span class="k">VALUES</span> <span class="p">(</span><span class="s1">'test 3'</span><span class="p">);</span>
<span class="gp">=#</span> <span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">child3</span> <span class="p">(</span><span class="k">comment</span><span class="p">)</span> <span class="k">VALUES</span> <span class="p">(</span><span class="s1">'test 4'</span><span class="p">);</span>
<span class="gp">=#</span> <span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">child4</span> <span class="p">(</span><span class="k">comment</span><span class="p">)</span> <span class="k">VALUES</span> <span class="p">(</span><span class="s1">'test 5'</span><span class="p">);</span>
<span class="gp">=#</span> <span class="k">SELECT</span> <span class="n">tableoid</span><span class="o">::</span><span class="n">regclass</span><span class="p">,</span> <span class="o">*</span> <span class="k">FROM</span> <span class="n">master</span><span class="p">;</span>
<span class="go"> tableoid | id |  dummy   | comment |           ts           </span>
<span class="go">----------+----+----------+---------+------------------------</span>
<span class="go"> child0   |  1 | 22810434 | test 1  | 2010-07-29 02:49:24+02</span>
<span class="go"> child1   |  2 | 18384970 | test 2  | 2011-01-28 02:57:00+01</span>
<span class="go"> child2   |  3 | 10707988 | test 3  | 2012-05-17 04:58:36+02</span>
<span class="go"> child3   |  4 | 15801904 | test 4  | 2013-08-21 10:31:04+02</span>
<span class="go"> child4   |  5 | 14906458 | test 5  | 2014-10-16 00:09:58+02</span>
<span class="go">(5 rows)</span>


<span class="gp">=#</span> <span class="k">BEGIN</span> <span class="p">;</span>
<span class="gp">=#</span> <span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">child0</span> <span class="p">(</span><span class="n">id</span><span class="p">,</span> <span class="k">comment</span><span class="p">)</span> <span class="k">VALUES</span> <span class="p">(</span><span class="mf">5</span><span class="p">,</span> <span class="s1">'test 6'</span><span class="p">);</span>
<span class="gs">ERROR:</span><span class="gr">  duplicate key value violates unique constraint &quot;children_id_pkey&quot; ON &quot;child0&quot;</span>
<span class="gs">DETAIL:</span><span class="gr">  Key (id)=(5) already exists.</span></code></pre></div><p>OK, it works like expected. But there is two big issues with this situation. The first one is that a race condition involving two transactions or more is able to break our home made unique constraint:</p>
<div class="highlight"><pre><code class="language-psql"><span class="gp">session 1=#</span> <span class="k">BEGIN</span><span class="p">;</span>
<span class="go">BEGIN</span>

<span class="gp">session 2=#</span> <span class="k">BEGIN</span><span class="p">;</span>
<span class="gp">session 2=#</span> <span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">child0</span> <span class="p">(</span><span class="k">comment</span><span class="p">)</span> <span class="k">VALUES</span> <span class="p">(</span><span class="s1">'test 6'</span><span class="p">)</span> <span class="k">RETURNING</span> <span class="n">id</span><span class="p">;</span>
<span class="go"> id</span>
<span class="go">----</span>
<span class="go">  6</span>

<span class="gp">session 1=#</span> <span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">child1</span> <span class="p">(</span><span class="n">id</span><span class="p">,</span> <span class="k">comment</span><span class="p">)</span> <span class="k">VALUES</span> <span class="p">(</span><span class="mf">6</span><span class="p">,</span> <span class="s1">'test 7'</span><span class="p">);</span>
<span class="gp">session 1=#</span> <span class="k">COMMIT</span> <span class="p">;</span>

<span class="gp">session 2=#</span> <span class="k">COMMIT</span> <span class="p">;</span>
<span class="gp">session 2=#</span> <span class="k">SELECT</span> <span class="n">tableoid</span><span class="o">::</span><span class="n">regclass</span><span class="p">,</span> <span class="o">*</span> <span class="k">FROM</span> <span class="n">master</span> <span class="k">WHERE</span> <span class="n">id</span><span class="o">=</span><span class="mf">6</span><span class="p">;</span>
<span class="go"> tableoid | id |  dummy   | comment |           ts           </span>
<span class="go">----------+----+----------+---------+------------------------</span>
<span class="go"> child0   |  6 | 28510860 | test 6  | 2010-01-08 17:36:39+01</span>
<span class="go"> child1   |  6 |  2188136 | test 7  | 2011-07-15 07:13:59+02</span></code></pre></div><p>The second issue is that real constraints can be deferred, which means constraints are disabled during a transaction and enforced on user request and at the end of the transaction by default. In other words, using deferred constraints allows you to violate them temporarilly during a transaction as far as everything is respected at the end. For more information about this mechanism, see the <a href="http://www.postgresql.org/docs/9.4/static/sql-set-constraints.html"><span class="caps">SET</span> <span class="caps">CONSTAINTS</span></a>, <a href="http://www.postgresql.org/docs/9.4/static/sql-createtable.html"><span class="caps">CREATE</span> <span class="caps">TABLE</span></a> and&#8230; the <a href="http://www.postgresql.org/docs/9.4/static/sql-createtrigger.html"><span class="caps">CREATE</span> <span class="caps">TRIGGER</span></a> pages.</p>
<p>Yes, documentation says triggers can be deferred when defined as <code>CONSTRAINT TRIGGER</code>. So we can solve this issue by recreating our triggers:</p>
<div class="highlight"><pre><code class="language-sql"><span class="k">DROP</span> <span class="k">TRIGGER</span> <span class="n">IF</span> <span class="k">EXISTS</span> <span class="n">children_id_pkey</span> <span class="k">ON</span> <span class="n">master</span><span class="p">;</span>
<span class="k">DROP</span> <span class="k">TRIGGER</span> <span class="n">IF</span> <span class="k">EXISTS</span> <span class="n">children_id_pkey</span> <span class="k">ON</span> <span class="n">child0</span><span class="p">;</span>
<span class="k">DROP</span> <span class="k">TRIGGER</span> <span class="n">IF</span> <span class="k">EXISTS</span> <span class="n">children_id_pkey</span> <span class="k">ON</span> <span class="n">child1</span><span class="p">;</span>
<span class="k">DROP</span> <span class="k">TRIGGER</span> <span class="n">IF</span> <span class="k">EXISTS</span> <span class="n">children_id_pkey</span> <span class="k">ON</span> <span class="n">child2</span><span class="p">;</span>
<span class="k">DROP</span> <span class="k">TRIGGER</span> <span class="n">IF</span> <span class="k">EXISTS</span> <span class="n">children_id_pkey</span> <span class="k">ON</span> <span class="n">child3</span><span class="p">;</span>
<span class="k">DROP</span> <span class="k">TRIGGER</span> <span class="n">IF</span> <span class="k">EXISTS</span> <span class="n">children_id_pkey</span> <span class="k">ON</span> <span class="n">child4</span><span class="p">;</span>
<span class="k">CREATE</span> <span class="k">CONSTRAINT</span> <span class="k">TRIGGER</span> <span class="n">children_id_pkey</span> <span class="k">AFTER</span> <span class="k">INSERT</span> <span class="k">OR</span> <span class="k">UPDATE</span> <span class="k">ON</span> <span class="n">master</span>
     <span class="k">DEFERRABLE</span> <span class="k">INITIALLY</span> <span class="k">IMMEDIATE</span> <span class="k">FOR</span> <span class="k">EACH</span> <span class="k">ROW</span> <span class="k">EXECUTE</span> <span class="k">PROCEDURE</span> <span class="k">public</span><span class="p">.</span><span class="n">master_id_pkey</span><span class="p">();</span>
<span class="k">CREATE</span> <span class="k">CONSTRAINT</span> <span class="k">TRIGGER</span> <span class="n">children_id_pkey</span> <span class="k">AFTER</span> <span class="k">INSERT</span> <span class="k">OR</span> <span class="k">UPDATE</span> <span class="k">ON</span> <span class="n">child0</span>
     <span class="k">DEFERRABLE</span> <span class="k">INITIALLY</span> <span class="k">IMMEDIATE</span> <span class="k">FOR</span> <span class="k">EACH</span> <span class="k">ROW</span> <span class="k">EXECUTE</span> <span class="k">PROCEDURE</span> <span class="k">public</span><span class="p">.</span><span class="n">master_id_pkey</span><span class="p">();</span>
<span class="k">CREATE</span> <span class="k">CONSTRAINT</span> <span class="k">TRIGGER</span> <span class="n">children_id_pkey</span> <span class="k">AFTER</span> <span class="k">INSERT</span> <span class="k">OR</span> <span class="k">UPDATE</span> <span class="k">ON</span> <span class="n">child1</span>
     <span class="k">DEFERRABLE</span> <span class="k">INITIALLY</span> <span class="k">IMMEDIATE</span> <span class="k">FOR</span> <span class="k">EACH</span> <span class="k">ROW</span> <span class="k">EXECUTE</span> <span class="k">PROCEDURE</span> <span class="k">public</span><span class="p">.</span><span class="n">master_id_pkey</span><span class="p">();</span>
<span class="k">CREATE</span> <span class="k">CONSTRAINT</span> <span class="k">TRIGGER</span> <span class="n">children_id_pkey</span> <span class="k">AFTER</span> <span class="k">INSERT</span> <span class="k">OR</span> <span class="k">UPDATE</span> <span class="k">ON</span> <span class="n">child2</span>
     <span class="k">DEFERRABLE</span> <span class="k">INITIALLY</span> <span class="k">IMMEDIATE</span> <span class="k">FOR</span> <span class="k">EACH</span> <span class="k">ROW</span> <span class="k">EXECUTE</span> <span class="k">PROCEDURE</span> <span class="k">public</span><span class="p">.</span><span class="n">master_id_pkey</span><span class="p">();</span>
<span class="k">CREATE</span> <span class="k">CONSTRAINT</span> <span class="k">TRIGGER</span> <span class="n">children_id_pkey</span> <span class="k">AFTER</span> <span class="k">INSERT</span> <span class="k">OR</span> <span class="k">UPDATE</span> <span class="k">ON</span> <span class="n">child3</span>
     <span class="k">DEFERRABLE</span> <span class="k">INITIALLY</span> <span class="k">IMMEDIATE</span> <span class="k">FOR</span> <span class="k">EACH</span> <span class="k">ROW</span> <span class="k">EXECUTE</span> <span class="k">PROCEDURE</span> <span class="k">public</span><span class="p">.</span><span class="n">master_id_pkey</span><span class="p">();</span>
<span class="k">CREATE</span> <span class="k">CONSTRAINT</span> <span class="k">TRIGGER</span> <span class="n">children_id_pkey</span> <span class="k">AFTER</span> <span class="k">INSERT</span> <span class="k">OR</span> <span class="k">UPDATE</span> <span class="k">ON</span> <span class="n">child4</span>
     <span class="k">DEFERRABLE</span> <span class="k">INITIALLY</span> <span class="k">IMMEDIATE</span> <span class="k">FOR</span> <span class="k">EACH</span> <span class="k">ROW</span> <span class="k">EXECUTE</span> <span class="k">PROCEDURE</span> <span class="k">public</span><span class="p">.</span><span class="n">master_id_pkey</span><span class="p">();</span></code></pre></div><p>The <code>INITIALLY IMMEDIATE</code> means the trigger constraint will be executed right after the related statement. The opposite <code>DEFERRED</code> behavior fire the trigger at the very end of the transaction unless the user decide to <code>SET CONSTRAINTS { ALL | name [, ...] } IMMEDIATE</code> somewhere during the transaction.</p>
<h2>Defering the trigger to avoid the race condition ?</h2>
<p>Now, if you step back a second to look at what we have, you might wonder if forcing our constraints triggers to be <code>DEFERRABLE INITIALLY DEFERRED</code> would solve the race condition. As constraints are checked at the very end of the transaction, maybe this would work by kind of serializing each transaction and their constraints? Short answer is: no.</p>
<p>For one, deferred constraints comes with a cost in performance we might not want to pay at each transaction. But most importantly, if you declared your trigger as deferrable, one could set it to <span class="caps">IMMEDIATE</span>, even if it is set as <span class="caps">INITIALLY</span> <span class="caps">DEFERRED</span>. So this is definitely not a viable solution. But anyway, occulting this for the purpose of the study, does it work?</p>
<p>Again, no. Even if it solves the &#8220;human timing race condition&#8221;, there&#8217;s another very small window where another race condition is possible in the core of PostgreSQL, when multiple transactions do not conflict and get committed all together at the exact same time. This idea itself sounds suspicious anyway, too fragile. If there is no good ol&#8217;locks floating around, there&#8217;s a race condition close enough to break things. It is pretty easy to prove with the following bash loop hammering each partitions with 100 INSERTs with colliding values as PK. Note that the triggers has been altered to <code>INITIALLY DEFERRED</code>:</p>
<div class="highlight"><pre><code class="language-console"><span class="gp">$</span> psql -c <span class="s1">'\d child*'</span> part <span class="p">|</span> grep children_id_pkey
<span class="go">    children_id_pkey AFTER INSERT OR UPDATE ON child0 DEFERRABLE INITIALLY DEFERRED FOR EACH ROW EXECUTE PROCEDURE master_id_pkey()</span>
<span class="go">    children_id_pkey AFTER INSERT OR UPDATE ON child1 DEFERRABLE INITIALLY DEFERRED FOR EACH ROW EXECUTE PROCEDURE master_id_pkey()</span>
<span class="go">    children_id_pkey AFTER INSERT OR UPDATE ON child2 DEFERRABLE INITIALLY DEFERRED FOR EACH ROW EXECUTE PROCEDURE master_id_pkey()</span>
<span class="go">    children_id_pkey AFTER INSERT OR UPDATE ON child3 DEFERRABLE INITIALLY DEFERRED FOR EACH ROW EXECUTE PROCEDURE master_id_pkey()</span>
<span class="go">    children_id_pkey AFTER INSERT OR UPDATE ON child4 DEFERRABLE INITIALLY DEFERRED FOR EACH ROW EXECUTE PROCEDURE master_id_pkey()</span>

<span class="gp">$</span> psql -c <span class="s1">'truncate master cascade'</span> part

<span class="gp">$</span> <span class="k">for</span> i in <span class="o">{</span>1..100<span class="o">}</span><span class="p">;</span> <span class="k">do</span>
<span class="gp">&gt;</span>   psql -c <span class="s2">&quot;INSERT INTO child0 (id, comment) SELECT count(*)+1, 'duplicated ?' FROM master&quot;</span> part <span class="p">&amp;</span>
<span class="gp">&gt;</span>   psql -c <span class="s2">&quot;INSERT INTO child1 (id, comment) SELECT count(*)+1, 'duplicated ?' FROM master&quot;</span> part <span class="p">&amp;</span>
<span class="gp">&gt;</span>   psql -c <span class="s2">&quot;INSERT INTO child2 (id, comment) SELECT count(*)+1, 'duplicated ?' FROM master&quot;</span> part <span class="p">&amp;</span>
<span class="gp">&gt;</span>   psql -c <span class="s2">&quot;INSERT INTO child3 (id, comment) SELECT count(*)+1, 'duplicated ?' FROM master&quot;</span> part <span class="p">&amp;</span>
<span class="gp">&gt;</span>   psql -c <span class="s2">&quot;INSERT INTO child4 (id, comment) SELECT count(*)+1, 'duplicated ?' FROM master&quot;</span> part <span class="p">&amp;</span>
<span class="gp">&gt;</span> <span class="k">done</span> <span class="p">&amp;</span>&gt; /dev/null <span class="o">&amp;&amp;</span> <span class="nb">wait</span>

<span class="gp">$</span> cat <span class="s">&lt;&lt;EOQ | psql part</span>
<span class="gp">&gt;</span><span class="s"> SELECT count(1), appears, total FROM (</span>
<span class="gp">&gt;</span><span class="s">   SELECT id, count(1) AS appears, sum(count(*)) over () AS total</span>
<span class="gp">&gt;</span><span class="s">   FROM master</span>
<span class="gp">&gt;</span><span class="s">   GROUP BY id</span>
<span class="gp">&gt;</span><span class="s"> ) t </span>
<span class="gp">&gt;</span><span class="s"> GROUP BY 2,3 ORDER BY appears</span>
<span class="gp">&gt;</span><span class="s"> EOQ</span>
<span class="go"> count | appears | total </span>
<span class="go">-------+---------+-------</span>
<span class="go">   149 |       1 |   209</span>
<span class="go">    23 |       2 |   209</span>
<span class="go">     3 |       3 |   209</span>
<span class="go">     1 |       5 |   209</span></code></pre></div><p>Well, that&#8217;s pretty bad, we have a bunch of duplicated key. 23 of them appear in two different partitions, three others in three different partitions and even one in all of them! I could find duplicates like that each time I ran this scenario. Note that on 500 inserts, only 209 survived in total. That makes 291 exceptions raised out of 324 expected, counting the duplicated keys that were not caught.</p>
<h2>Isolation level ?</h2>
<p>Well, last chance. If this many transactions were committed in the exact same time, maybe we can force them to serialize with isolation level <code>SERIALIZABLE</code>?</p>
<div class="highlight"><pre><code class="language-sql"><span class="k">ALTER</span> <span class="k">DATABASE</span> <span class="n">part</span> <span class="k">SET</span> <span class="n">default_transaction_isolation</span> <span class="k">TO</span> <span class="k">SERIALIZABLE</span></code></pre></div><p>After applying the preceding query, I re-ran the same scenario as the previous test: only 76 rows survived out of the 500 INSERTs, all of them unique. At last! Ok, this reflects what we had in mind previously, but we had to force PostgreSQL to <strong>really</strong> serialize transactions. Any other isolation level will just fail. And by the way, this works with <span class="caps">IMMEDIATE</span> and <span class="caps">DEFERRED</span> triggers as transactions are virtually serialized or rollback&#8217;ed. Log file confirms a lot of serialization conflicts were raised, grep&#8217;ing the log file shows 415 serialization exceptions and only 9 from our trigger:</p>
<pre><code>ERROR:  could not serialize access due to read/write dependencies among transactions
DETAIL:  Reason code: Canceled on identification as a pivot, during conflict in checking.
HINT:  The transaction might succeed if retried.
STATEMENT:  INSERT INTO child3 (id, comment) SELECT count(*)+1, 'duplicated ?' FROM master</code></pre>
<p>This solution work, but having to stay in <span class="caps">SERIALIZABLE</span> mode to achieve our goal is a heavy constraint to carry. Moreover, we have the same problem than with <span class="caps">DEFERRED</span> triggers: as a simple user can change its isolation level, any bug in the application or not informed user can lead to scenarios with silent duplications. Fortunately, another simpler and safer solution exist.</p>
<h2>Real solution: adding locks</h2>
<p>The <code>SERIALIZABLE</code> solution works because to emulate serial transaction execution for all transactions, it takes <i>predicate locks</i> behind the scene to detect serialization anomalies. What about taking care of this ourselves? We are used to locks, we know they work fine.</p>
<p>The best solution sounds to acquire a lock before being able to write out the value. This actually boil down to forcing conflicting transactions on a lock to serialize themselves, instead of having the engine do all the works for everyone. The question now is «how can we hold a lock on something that doesn&#8217;t exists yet?». The answer is: <a href="http://www.postgresql.org/docs/9.4/static/explicit-locking.html#ADVISORY-LOCKS">Advisory Locks</a>. Advisory locks offers to applications a lock mechanism and manager on arbitrary integer values. It does not applies on real objects, transaction or rows. As the documentation says: «It is up to the application to use them correctly»</p>
<p>The idea now is simply to acquire an advisory lock on the same value as <span class="caps">NEW</span>.id in the trigger function. It should do the trick, cleanly, safely:</p>
<div class="highlight"><pre><code class="language-sql"><span class="k">CREATE</span> <span class="k">OR</span> <span class="k">REPLACE</span> <span class="k">FUNCTION</span> <span class="k">public</span><span class="p">.</span><span class="n">master_id_pkey</span><span class="p">()</span>
 <span class="k">RETURNS</span> <span class="k">trigger</span>
 <span class="k">LANGUAGE</span> <span class="n">plpgsql</span>
<span class="k">AS</span> <span class="err">$</span><span class="k">function</span><span class="err">$</span>
<span class="k">BEGIN</span>
  <span class="n">PERFORM</span> <span class="n">pg_advisory_xact_lock</span><span class="p">(</span><span class="k">NEW</span><span class="p">.</span><span class="n">id</span><span class="p">);</span>

  <span class="n">IF</span> <span class="k">count</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="k">FROM</span> <span class="n">master</span> <span class="k">WHERE</span> <span class="n">id</span> <span class="o">=</span> <span class="k">NEW</span><span class="p">.</span><span class="n">id</span> <span class="k">THEN</span>
     <span class="n">RAISE</span> <span class="k">EXCEPTION</span> <span class="s1">'duplicate key value violates unique constraint &quot;%&quot; ON &quot;%&quot;'</span><span class="p">,</span> 
      <span class="n">TG_NAME</span><span class="p">,</span> <span class="n">TG_TABLE_NAME</span> 
      <span class="k">USING</span> <span class="n">DETAIL</span> <span class="o">=</span> <span class="n">format</span><span class="p">(</span><span class="s1">'Key (id)=(%s) already exists.'</span><span class="p">,</span> <span class="k">NEW</span><span class="p">.</span><span class="n">id</span><span class="p">);</span>
  <span class="k">END</span> <span class="n">IF</span><span class="p">;</span>

  <span class="k">RETURN</span> <span class="k">NULL</span><span class="p">;</span>
<span class="k">END</span>
<span class="err">$</span><span class="k">function</span><span class="err">$</span><span class="p">;</span></code></pre></div><p>And with this version of <code>master_id_pkey()</code>, in &#8220;read committed&#8221; isolation level, here is result of the same scenario as in the previous chapter, executing 500 INSERTs concurrently with conflicting keys:</p>
<div class="highlight"><pre><code class="language-console"><span class="gp">$</span> psql -f /tmp/count_duplicated_id.sql part
<span class="go"> count | appears | total </span>
<span class="go">-------+---------+-------</span>
<span class="go">    85 |       1 |    85 </span>
<span class="go">(1 row)</span></code></pre></div><p>Sounds good. What about a small pgbench scenario?</p>
<div class="highlight"><pre><code class="language-console"><span class="gp">$</span> cat /tmp/scenario_id.sql 
<span class="go">\setrandom part 0 4</span>
<span class="go">DO $func$ BEGIN EXECUTE format('INSERT INTO child%s (id, comment) SELECT count(*)+1, $1 FROM master', :part) USING 'duplicated ?'; EXCEPTION WHEN OTHERS THEN RAISE LOG 'Duplicate exception caught!'; END $func$;</span>

<span class="gp">$</span> psql -c <span class="s1">'truncate master cascade'</span> part

<span class="gp">$</span> pgbench -n -f /tmp/scenario_id.sql -c <span class="m">5</span> -T <span class="m">300</span> part
<span class="go">transaction type: Custom query</span>
<span class="go">scaling factor: 1</span>
<span class="go">query mode: simple</span>
<span class="go">number of clients: 5</span>
<span class="go">number of threads: 1</span>
<span class="go">duration: 300 s</span>
<span class="go">number of transactions actually processed: 130908</span>
<span class="go">latency average: 11.458 ms</span>
<span class="go">tps = 436.338755 (including connections establishing)</span>
<span class="go">tps = 436.354969 (excluding connections establishing)</span>

<span class="gp">$</span> psql -f /tmp/count_duplicated_id.sql part
<span class="go"> count | appears | total </span>
<span class="go">-------+---------+-------</span>
<span class="go"> 48351 |       1 | 48351</span>

<span class="gp">$</span> grep -c <span class="s2">&quot;LOG:  Duplicate&quot;</span> <span class="nv">$LOGFILE</span>
<span class="go">82557</span></code></pre></div><p>After this 5 minute run with 5 workers inserting as fast as they can highly conflicting data, we have 48,351 rows in the partitions, 82,557 conflicting rows were rejected and not a single duplicate in the table.</p>
<p>I couldn&#8217;t find any duplicated value after stressing this solution. Whatever the number of queries for each parallel sessions working, whatever the pgbench scenario, I had no unique violation across partitions, as expected. This work in any transaction isolation level and user can not turn this off by mistake. This is <strong>safe</strong>&#8230;</p>
<p>&#8230;Well, as far as a superuser or the owner of the table do not disable the trigger on the table, obviously. But hey, they can drop the unique constraint on a normal table as well, right?</p>
<p>Wow, at last, finished. What? No? I can hear you thinking it only applies on integers. OK, bonus.</p>
<h2>Supporting other types</h2>
<p>Supporting unique constraint on integers was straightforward using advisory locks. But how can this applies to other types? Like text for instance ? Easy: hash it<sup class="footnote" id="fnr1"><a href="http://blog.ioguix.net/postgresql/feed.xml#fn1">1</a></sup>! For the purpose of this last chapter, lets add a unique constraint on <code>comment</code>:</p>
<div class="highlight"><pre><code class="language-sql"><span class="k">CREATE</span> <span class="k">OR</span> <span class="k">REPLACE</span> <span class="k">FUNCTION</span> <span class="k">public</span><span class="p">.</span><span class="n">master_comment_unq</span><span class="p">()</span>
 <span class="k">RETURNS</span> <span class="k">trigger</span>
 <span class="k">LANGUAGE</span> <span class="n">plpgsql</span>
<span class="k">AS</span> <span class="err">$</span><span class="k">function</span><span class="err">$</span>
<span class="k">BEGIN</span>
  <span class="n">PERFORM</span> <span class="n">pg_advisory_xact_lock</span><span class="p">(</span><span class="n">hashtext</span><span class="p">(</span><span class="k">NEW</span><span class="p">.</span><span class="k">comment</span><span class="p">));</span>

  <span class="n">IF</span> <span class="k">count</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="k">FROM</span> <span class="n">master</span> <span class="k">WHERE</span> <span class="k">comment</span> <span class="o">=</span> <span class="k">NEW</span><span class="p">.</span><span class="k">comment</span> <span class="k">THEN</span>
    <span class="n">RAISE</span> <span class="k">EXCEPTION</span> <span class="s1">'duplicate key value violates unique constraint &quot;%&quot; ON &quot;%&quot;'</span><span class="p">,</span> 
      <span class="n">TG_NAME</span><span class="p">,</span> <span class="n">TG_TABLE_NAME</span>
      <span class="k">USING</span> <span class="n">DETAIL</span> <span class="o">=</span> <span class="n">format</span><span class="p">(</span><span class="s1">'Key (comment)=(%L) already exists.'</span><span class="p">,</span> <span class="k">NEW</span><span class="p">.</span><span class="k">comment</span><span class="p">);</span>
  <span class="k">END</span> <span class="n">IF</span><span class="p">;</span>

  <span class="k">RETURN</span> <span class="k">NULL</span><span class="p">;</span>
<span class="k">END</span>
<span class="err">$</span><span class="k">function</span><span class="err">$</span><span class="p">;</span>

<span class="k">CREATE</span> <span class="k">CONSTRAINT</span> <span class="k">TRIGGER</span> <span class="n">children_comment_unq</span> <span class="k">AFTER</span> <span class="k">INSERT</span> <span class="k">OR</span> <span class="k">UPDATE</span> <span class="k">ON</span> <span class="n">master</span>
  <span class="k">DEFERRABLE</span> <span class="k">INITIALLY</span> <span class="k">IMMEDIATE</span> <span class="k">FOR</span> <span class="k">EACH</span> <span class="k">ROW</span> <span class="k">EXECUTE</span> <span class="k">PROCEDURE</span> <span class="k">public</span><span class="p">.</span><span class="n">master_comment_unq</span><span class="p">();</span>
<span class="c1">-- [...]</span>
<span class="k">CREATE</span> <span class="k">CONSTRAINT</span> <span class="k">TRIGGER</span> <span class="n">children_comment_unq</span> <span class="k">AFTER</span> <span class="k">INSERT</span> <span class="k">OR</span> <span class="k">UPDATE</span> <span class="k">ON</span> <span class="n">child4</span>
  <span class="k">DEFERRABLE</span> <span class="k">INITIALLY</span> <span class="k">IMMEDIATE</span> <span class="k">FOR</span> <span class="k">EACH</span> <span class="k">ROW</span> <span class="k">EXECUTE</span> <span class="k">PROCEDURE</span> <span class="k">public</span><span class="p">.</span><span class="n">master_comment_unq</span><span class="p">();</span></code></pre></div><p>If you followed this far, no need to play the &#8220;find the error game&#8221; to identify what&#8217;s the most important change here. The lock is taken on the result of the simple text to integer hash function <code>hashtext</code>, already provided in PostgreSQL&#8217;s core.</p>
<p>Ok, I can hear optimization freaks crying. Theoretically, two <strong>different</strong> strings can collide. But this hash function is supposed to compute uniform results amongst 4 billion possible values. I can live with the probability of two <strong>concurrent</strong> writes involving two different strings colliding here. The &#8220;1 case&#8221; out of 4 billion is already enough for me, but these colliding strings has to show up at the <strong>exact same time</strong> (at least in the same bunch of few milliseconds). And even if you are unlucky enough to experience this, these two transactions will just be serialized, not a big deal.</p>
<p>And if you are really not comfortable with this, you understood the trick here anyway: find a way to hold a lock somewhere to avoid concurrency. Use some other hashing function, create an extension with its own lock machinery in memory, write in an unlogged table (erk), whatever you want.</p>
<p>Time to test now.</p>
<div class="highlight"><pre><code class="language-console"><span class="gp">$</span> cat /tmp/scenario_comment.sql 
<span class="go">\setrandom part 0 4</span>
<span class="go">DO $func$ BEGIN EXECUTE format('INSERT INTO child%s (comment) SELECT ''duplicated ''||count(1) from master', :part); EXCEPTION WHEN OTHERS THEN RAISE LOG 'Duplicate exception caught!'; END $func$;</span>

<span class="gp">$</span> psql -c <span class="s1">'truncate master cascade'</span> part

<span class="gp">$</span> pgbench -n -f /tmp/scenario_comment.sql -c <span class="m">5</span> -T <span class="m">300</span> part
<span class="go">transaction type: Custom query</span>
<span class="go">scaling factor: 1</span>
<span class="go">query mode: simple</span>
<span class="go">number of clients: 5</span>
<span class="go">number of threads: 1</span>
<span class="go">duration: 300 s</span>
<span class="go">number of transactions actually processed: 93902</span>
<span class="go">latency average: 15.974 ms</span>
<span class="go">tps = 312.971273 (including connections establishing)</span>
<span class="go">tps = 312.987557 (excluding connections establishing)</span>

<span class="gp">$</span> cat <span class="s">&lt;&lt;EOQ | psql part</span>
<span class="gp">&gt;</span><span class="s"> SELECT count(1), appears, total FROM (</span>
<span class="gp">&gt;</span><span class="s">   SELECT comment, count(1) AS appears, sum(count(*)) over () AS total</span>
<span class="gp">&gt;</span><span class="s">   FROM master</span>
<span class="gp">&gt;</span><span class="s">   GROUP BY comment</span>
<span class="gp">&gt;</span><span class="s"> ) t </span>
<span class="gp">&gt;</span><span class="s"> GROUP BY 2,3 ORDER BY appears</span>
<span class="gp">&gt;</span><span class="s"> EOQ</span>
<span class="go"> count | appears | total </span>
<span class="go">-------+---------+-------</span>
<span class="go"> 29785 |       1 | 29785</span></code></pre></div><p>Wow (again), only 29,785 rows out of 93,902 transactions escaped of that intense-colliding scenario. And we only find unique values across all partitions, as expected. Aaaaand grep-ing from the log file, I can find 64,117 rejected rows&#8230;</p>
<h2>Conclusion</h2>
<p>Such a long way already. Thank you for reading so far. At first I thought I could write about unique and foreign keys in the same article, but look at what we already covered&#8230;We talked about constraint triggers, race conditions, isolation level, advisory locks and hashing&#8230; few!</p>
<p>I do realize the solution provided here requires some skills and attention. This is not all magic and easy to play with. As long as this feature is not handled directly by the core, partitioning will require people to craft their tools themselves. In the meantime, it is a nice subject to learn more about these concepts, your favorite <span class="caps">RDBMS</span> and play with it.</p>
<p>I think this way of guaranteeing unicity over several partitions is bulletproof. If you think you found a loophole, please send me some feedback, I&#8217;ll be pleased to learn about them.</p>
<p>And don&#8217;t forget, we are not done! Lot of fun with foreign keys in the next part! Stay tuned!</p>
<hr style="width: 100px; text-align: left;" />
<p class="footnote" id="fn1"><a href="http://blog.ioguix.net/postgresql/feed.xml#fnr1"><sup>1</sup></a> No data has been harmed during this test.</p>
    </div>
    <div class="feedEntry">

        <a href="http://johtopg.blogspot.com/2015/02/allas-connection-pooling-for-listen.html" title="Marko Tiikkaja: allas: connection pooling for LISTEN / NOTIFY">
            <h2>Marko Tiikkaja: allas: connection pooling for LISTEN / NOTIFY</h2>
        </a>

        <p class="discreet">
            
            
                  From Planet PostgreSQL.
            
            
                Published on <span name="publication_time">Feb 04, 2015</span>.
            
        </p>

        Lately I've been working on a connection pooler which only supports LISTEN / NOTIFY.  The idea is to be able to keep the number of Postgres connections down without having to give up (or come up with a workaround for) notifications.  With allas you can e.g. use pgbouncer or your environment's native connection pool and open a separate connection for notifications only.  allas internally uses only
    </div>
    <div class="feedEntry">

        <a href="http://okbob.blogspot.com/2015/02/simple-multicolumn-ouput-in-psql.html" title="Pavel Stehule: Simple multicolumn ouput in psql">
            <h2>Pavel Stehule: Simple multicolumn ouput in psql</h2>
        </a>

        <p class="discreet">
            
            
                  From Planet PostgreSQL.
            
            
                Published on <span name="publication_time">Feb 04, 2015</span>.
            
        </p>

        There are interesting idea on <a href="http://www.depesz.com/2015/02/04/returning-data-in-multiple-columns/">Depesz's blog</a> .<br /><br />But some possibility has a Linux itself. There is simple pager <code>column</code>.<br /><br />You can try (blogger engine break formatting):<br /><pre>postgres=# \pset tuples_only<br />postgres=# \setenv PAGER column<br /><br />postgres=# select typname from pg_type limit 100;<br /> bool   pg_type  line   _bool   _varchar  _inet   _numeric<br /> bytea   pg_attribute  _line   _bytea   _int8   _cidr   timetz<br /> char   pg_proc  float4   _char   _point   _cstring  _timetz<br /> name   pg_class  float8   _name   _lseg   bpchar   bit<br /> int8   json   abstime  _int2   _path   varchar  _bit<br /> int2   xml   reltime  _int2vector  _box   date   varbit<br /> int2vector  _xml   tinterval  _int4   _float4  time   _varbit<br /> int4   _json   unknown  _regproc  _float8  timestamp  numeric<br /> regproc  pg_node_tree  circle   _text   _abstime  _timestamp  refcursor<br /> text   smgr   _circle  _oid   _reltime  _date   _refcursor<br /> oid   point   money   _tid   _tinterval  _time<br /> tid   lseg   _money   _xid   _polygon  timestamptz<br /> xid   path   macaddr  _cid   aclitem  _timestamptz<br /> cid   box   inet   _oidvector  _aclitem  interval<br /> oidvector  polygon  cidr   _bpchar  _macaddr  _interval<br /><br />postgres=# <br /></pre>It works together with <code>less</code><br /><pre>postgres=# \setenv PAGER '(column | less)'<br />postgres=# select typname from pg_type;<br /> ...<br /></pre><br />Do you know some other nice pagers?
    </div>
    <div class="feedEntry">

        <a href="http://www.depesz.com/2015/02/04/returning-data-in-multiple-columns/" title="Hubert 'depesz' Lubaczewski: Returning data in multiple columns">
            <h2>Hubert 'depesz' Lubaczewski: Returning data in multiple columns</h2>
        </a>

        <p class="discreet">
            
            
                  From Planet PostgreSQL.
            
            
                Published on <span name="publication_time">Feb 04, 2015</span>.
            
        </p>

        I was working today on some updates to client database. While doing it, I figured it would be simpler if I saw all &#8220;codenames" and ids of rows from dictionary table &#8211; not so big. But it was bigger than my screen &#8211; I have only 90 lines of text on screen, and there were [&#8230;]
    </div>
    <div class="feedEntry">

        <a href="http://toastdriven.com/blog/2015/feb/02/haystack-tastypie-orgs/" title="Haystack &amp;amp; Tastypie Orgs">
            <h2>Haystack &amp; Tastypie Orgs</h2>
        </a>

        <p class="discreet">
            
                  By Daniel Lindsley from Django community aggregator: Community blog posts.
            
            
            
                Published on <span name="publication_time">Feb 02, 2015</span>.
            
        </p>

        Haystack & Tastypie Orgs
    </div>
    <div class="feedEntry">

        <a href="http://feedproxy.google.com/~r/djangotricks/~3/dUW2x_4IekM/performance-bottlenecks-in-django-views.html" title="How to Find the Performance Bottlenecks in Your Django Views?">
            <h2>How to Find the Performance Bottlenecks in Your Django Views?</h2>
        </a>

        <p class="discreet">
            
                  By DjangoTricks from Django community aggregator: Community blog posts.
            
            
            
                Published on <span name="publication_time">Jan 30, 2015</span>.
            
        </p>

        <p>Once you have your Django projects running, you come to situations, when you need to optimize for performance. The rule of thumb is to find the bottlenecks and then to take action to eliminate them by more idiomatic Python code, database denormalization, caching, or other techniques.</p> <p>What is a bottleneck? Literally it refers to the top narrow part of a bottle. In engineering, bottleneck is a case where the performance or capacity of an entire system is limited by a single or small number of components or resources.</p> <p>How to find these parts of your code? The most trivial way is to check the current time before specific code execution and after that code execution, and then count the time difference:</p> <pre><br />from datetime import datetime<br />start = datetime.now()<br /># heavy execution ...<br />end = datetime.now()<br />d = end - start  # datetime.timedelta object<br />print d.total_seconds()  # prints something like 7.861985<br /></pre> <p>However, measuring code performance for Django projects like this is inefficient, because you need a lot of such wrappers for your code until you find which part is the most critical. Also you need a lot of manual computation to find the critical parts.</p> <p>Recently I found <a href="https://github.com/rkern/line_profiler">line_profiler</a> module that can inspect the performance of the code line by line. By default, to use line_profiler for your functions, you should decorate them with @profile decorator and then to execute the script:</p>  <pre><br />$ kernprof -l some_script_to_profile.py<br /></pre><p>This script will execute your script, analize the decorated function, and will save results to a binary file that can later be inspected with:</p><pre><br />$ python -m line_profiler some_script_to_profile.py.lprof<br /></pre> <p>That's quite complicated, but to use line_profiler for Django views, you can install <a href="https://github.com/dcramer/django-devserver">django-devserver</a> which replaces the original development server of Django and will output the performance calculations immediately in the shell like this:</p> <pre><br />[30/Jan/2015 02:26:40] "GET /quotes/json/ HTTP/1.1" 200 137<br />    [sql] 1 queries with 0 duplicates<br />    [profile] Total time to render was 0.01s<br />    [profile] Timer unit: 1e-06 s<br /><br />          Total time: 0.001965 s<br />          File: /Users/archatas/Projects/quotes_env/project/inspirational/quotes/views.py<br />          Function: quote_list_json at line 27<br /><br />          Line #      Hits         Time  Per Hit   % Time  Line Contents<br />          ==============================================================<br />              27                                           def quote_list_json(request):<br />              28         1            2      2.0      0.1      quote_dict_list = []<br />              29         2         1184    592.0     60.3      for quote in InspirationQuote.objects.all():<br />              30         1            1      1.0      0.1          quote_dict = {<br />              31         1            1      1.0      0.1              'author': quote.author,<br />              32         1            1      1.0      0.1              'quote': quote.quote,<br />              33         1          363    363.0     18.5              'picture': quote.get_medium_picture_url(),<br />              34                                                   }<br />              35         1            1      1.0      0.1          quote_dict_list.append(quote_dict)<br />              36<br />              37         1           42     42.0      2.1      json_data = json.dumps(quote_dict_list)<br />              38         1          370    370.0     18.8      return HttpResponse(json_data, content_type="application/json")<br /></pre> <p>The most interesting data in this table is the "% Time" column, giving an overview in percentage which lines of the Django view function are the most time-consuming. For example, here it says that I should pay the most attention to the QuerySet, the method get_medium_picture_url() and the HttpResponse object.</p> <p>To setup line profiling, install line_profiler and django-devserver to you virtual environment:</p> <pre><br />(myproject_env)$ pip install line_profiler<br />(myproject_env)$ pip install django-devserver<br /></pre> <p>Then make sure that you have the following settings in your settings.py or local_settings.py:</p> <pre><br /># settings.py<br />INSTALLED_APPS = (<br />    # ...<br />    'devserver',<br />)<br /><br />MIDDLEWARE_CLASSES = (<br />    # ...<br />    'devserver.middleware.DevServerMiddleware',<br />)<br /><br />DEVSERVER_MODULES = (<br />    'devserver.modules.sql.SQLRealTimeModule',<br />    'devserver.modules.sql.SQLSummaryModule',<br />    'devserver.modules.profile.ProfileSummaryModule',<br /><br />    # Modules not enabled by default<br />    'devserver.modules.profile.LineProfilerModule',<br />)<br /><br />DEVSERVER_AUTO_PROFILE = True  # profiles all views without the need of function decorator<br /></pre> <p>When you execute</p><pre><br />(myproject_env)$ python manage.py runserver<br /></pre><p>it will run the development server from django-devserver and for each visited view, it will show the analysis of code performance. I have tested this setup with Django 1.7, but it should work since Django 1.3.</p> <p>Do you know any more useful tools to check for performance bottlenecks?</p><div class="feedflare">
<a href="http://feeds.feedburner.com/~ff/djangotricks?a=dUW2x_4IekM:mK4cF1at3SY:4cEx4HpKnUU"><img border="0" src="http://feeds.feedburner.com/~ff/djangotricks?i=dUW2x_4IekM:mK4cF1at3SY:4cEx4HpKnUU" /></a> <a href="http://feeds.feedburner.com/~ff/djangotricks?a=dUW2x_4IekM:mK4cF1at3SY:F7zBnMyn0Lo"><img border="0" src="http://feeds.feedburner.com/~ff/djangotricks?i=dUW2x_4IekM:mK4cF1at3SY:F7zBnMyn0Lo" /></a>
</div><img alt="" height="1" src="https://feeds.feedburner.com/~r/djangotricks/~4/dUW2x_4IekM" width="1" />
    </div>
    <div class="feedEntry">

        <a href="http://feedproxy.google.com/~r/GoDjango/~3/4-D8sU0FYE8/" title="Account Control part 1">
            <h2>Account Control part 1</h2>
        </a>

        <p class="discreet">
            
                  By GoDjango - Django Screencasts from Django community aggregator: Community blog posts.
            
            
            
                Published on <span name="publication_time">Jan 30, 2015</span>.
            
        </p>

        This is the first in a series of videos on creating a site which utilizes other services to help your users stay informed. We start the series with getting our users setup with an account, and giving them the ability to log in and out.<br /><a href="https://godjango.com/81-account-control-part-1/">Watch Now...</a><img alt="" height="1" src="https://feeds.feedburner.com/~r/GoDjango/~4/4-D8sU0FYE8" width="1" />
    </div>
    <div class="feedEntry">

        <a href="http://www.caktusgroup.com/blog/2015/01/29/astro-code-school-tapped-teach-app-development-unc-journalism-school/" title="Astro Code School Tapped to Teach App Development at UNC Journalism School">
            <h2>Astro Code School Tapped to Teach App Development at UNC Journalism School</h2>
        </a>

        <p class="discreet">
            
                  By Caktus Consulting Group from Django community aggregator: Community blog posts.
            
            
            
                Published on <span name="publication_time">Jan 29, 2015</span>.
            
        </p>

        <p>Our own <a href="http://www.caktusgroup.com/about/caleb-smith">Caleb Smith</a>, <a href="https://www.djangoproject.com/rss/community/blogs/www.astrocodeschool.com">Astro Code School</a> lead instructor, is teaching this semester at UNC’s School of Journalism, one of the nation’s leading journalism schools. He’s sharing his enthusiasm for Django application development with undergraduate and graduate media students in a 500-level course, Advanced Interactive Development. </p>
<p>For additional details about the course and why UNC School of Journalism selected Caktus and Astro Code School, please see our <a href="http://www.prweb.com/releases/2015/01/prweb12478722.htm">press release</a>.</p>
    </div>
    <div class="feedEntry">

        <a href="http://seeknuance.com/2015/01/28/solinea-is-looking-for-a-senior-backend-engineer-python-django-elasticsearch/" title="Solinea is looking for a Senior Backend Engineer (Python, Django, Elasticsearch)">
            <h2>Solinea is looking for a Senior Backend Engineer (Python, Django, Elasticsearch)</h2>
        </a>

        <p class="discreet">
            
                  By John DeRosa from Django community aggregator: Community blog posts.
            
            
            
                Published on <span name="publication_time">Jan 28, 2015</span>.
            
        </p>

        <p>This is my second week at Solinea, and I&#8217;m loving it! A position just opened up on our development team for a backend developer, and I wanted to share the love. <span class="wp-smiley wp-emoji wp-emoji-smile" title=":-)">:-)</span></p>
<p>The company supports remote employees. Its headquarters is in Berkeley, CA, and I&#8217;m in Seattle, and I feel more connected now than, well, I did at some other companies I&#8217;ve worked for.</p>
<p>If you&#8217;re in Seattle, I&#8217;d be happy to meet for coffee to talk at length about the job.</p>
<p>To apply for this job, you can contact me at john@seeknuance.com, or click the <a href="https://solinea.recruiterbox.com/jobs/fk0nvn">&#8220;Apply for this position&#8221; button at the bottom of the job&#8217;s Recruiterbox page.</a></p>
<h2>Senior Backend Engineer (Python, Django, Elasticsearch)</h2>
<h3>Location</h3>
<p>Berkeley, CA, US, or remote</p>
<p>This position is only open to candidates based in and eligible to work in the United States.</p>
<h3>Responsibilities</h3>
<p>As a backend developer at Solinea, you will be primarily working on our <a href="http://www.solinea.com/goldstone">flagship product</a> from the API back, as well as committing to the OpenStack codebase.</p>
<p>You will work in a sprint-based agile development team, and will participate in the full cycle including release/sprint planning, feature design, story definition, daily standups, development, testing, code review, and release packaging. You will also work on the automated build, test, and package environment, as well as participate in maintenance of the development lab. Most of all, you will have the opportunity to have fun, be challenged, and grow as a developer while creating a game-changing product to help our fellow cloud operators.</p>
<h3>Requirements</h3>
<p>The ideal person to fill the role will have a solid track record of cloud, open source, virtualization, real-time data, and API development. You should have the &#8216;play all fields&#8217; mentality required to be successful in a startup environment. Bring your passion for solving large problems, exploring new technology frontiers, and helping to bootstrap a development organization.</p>
<p>The goldstone backend technology stack primarily consists of Python, Django, Celery, Redis, Logstash, and Elasticsearch. You should be an expert-level developer in the Python/Django ecosystem, and hands-on experience with OpenStack or some other cloud management framework.</p>
<p>In addition to the core skills, things like systems automation, machine learning, data visualization, and prior startup experience are definitely relevant to the position.</p>
<p>The ideal candidate will have at least a BS degree in CS or related field along with relevant work experience.</p>
<h3>Benefits</h3>
<p>Solinea offers comprehensive benefits including:</p>
<ul>
<li>Medical, dental, vision, life, disability insurance, 401k plan</li>
<li>Flexible spending accounts</li>
<li>Pre-tax commuter benefits</li>
<li>Free coffee/tea in offices</li>
<li>20 days of PTO/yr</li>
<li>Flexible working environment</li>
<li>Joel Test score: 8 out of 12</li>
</ul>
<h4>The Joel Test is a twelve-question measure of a software team&#8217;s quality.</h4>
<p>Do you use source control? Yes<br />
Can you make a build in one step? Yes<br />
Do you make daily builds? Yes<br />
Do you have a bug database? Yes<br />
Do you fix bugs before writing new code? Depends on severity<br />
Do you have an up-to-date schedule? No<br />
Do you have a spec? Yes<br />
Do programmers have quiet working conditions? Yes<br />
Do you use the best tools money can buy? Yes<br />
Do you have testers? No<br />
Do new candidates write code during their interview? Yes<br />
Do you do hallway usability testing? No</p><br /> Tagged: <a href="http://seeknuance.com/tag/django/">Django</a>, <a href="http://seeknuance.com/tag/jobs/">jobs</a>, <a href="http://seeknuance.com/tag/python/">Python</a> <a href="http://feeds.wordpress.com/1.0/gocomments/seeknuance.wordpress.com/8210/" rel="nofollow"><img alt="" border="0" src="http://feeds.wordpress.com/1.0/comments/seeknuance.wordpress.com/8210/" /></a> <a href="http://feeds.wordpress.com/1.0/godelicious/seeknuance.wordpress.com/8210/" rel="nofollow"><img alt="" border="0" src="http://feeds.wordpress.com/1.0/delicious/seeknuance.wordpress.com/8210/" /></a> <a href="http://feeds.wordpress.com/1.0/gofacebook/seeknuance.wordpress.com/8210/" rel="nofollow"><img alt="" border="0" src="http://feeds.wordpress.com/1.0/facebook/seeknuance.wordpress.com/8210/" /></a> <a href="http://feeds.wordpress.com/1.0/gotwitter/seeknuance.wordpress.com/8210/" rel="nofollow"><img alt="" border="0" src="http://feeds.wordpress.com/1.0/twitter/seeknuance.wordpress.com/8210/" /></a> <a href="http://feeds.wordpress.com/1.0/gostumble/seeknuance.wordpress.com/8210/" rel="nofollow"><img alt="" border="0" src="http://feeds.wordpress.com/1.0/stumble/seeknuance.wordpress.com/8210/" /></a> <a href="http://feeds.wordpress.com/1.0/godigg/seeknuance.wordpress.com/8210/" rel="nofollow"><img alt="" border="0" src="http://feeds.wordpress.com/1.0/digg/seeknuance.wordpress.com/8210/" /></a> <a href="http://feeds.wordpress.com/1.0/goreddit/seeknuance.wordpress.com/8210/" rel="nofollow"><img alt="" border="0" src="http://feeds.wordpress.com/1.0/reddit/seeknuance.wordpress.com/8210/" /></a> <img alt="" border="0" height="1" src="http://pixel.wp.com/b.gif?host=seeknuance.com&#038;blog=2611216&#038;post=8210&#038;subd=seeknuance&#038;ref=&#038;feed=1" width="1" />
    </div>
    <div class="feedEntry">

        <a href="http://w.wol.ph/2015/01/28/readingwriting-3d-stl-files-numpy-stl/" title="Reading/writing 3D STL files with numpy-stl">
            <h2>Reading/writing 3D STL files with numpy-stl</h2>
        </a>

        <p class="discreet">
            
                  By wol.ph from Django community aggregator: Community blog posts.
            
            
            
                Published on <span name="publication_time">Jan 28, 2015</span>.
            
        </p>

        <p>As a followup of my earlier <a href="http://w.wol.ph/2014/10/11/reading-writing-binary-stl-files-numpy/" target="_blank" title="Reading and writing binary STL files with Numpy">article</a> about reading and writing STL files with Numpy, I&#8217;ve created a <a href="https://pypi.python.org/pypi/numpy-stl" target="_blank">library</a> that can be used easily to read, modify and write STL files in both binary and ascii format.</p>
<p>The library automatically detects whether your file is in ascii or binary STL format and is very fast due to all operations being done by numpy.</p>
<p>First, install using pip or easy_install:</p>
<div class="highlighted-source monokai bash">
<pre>pip install numpy-stl
<span class="c"># Or if you don't have pip available</span>
easy_install numpy-stl
</pre>
</div>
<p>Note that <code>numpy</code> numpy and python-utils version 1.6 or greater are required. While these should both be installed automatically by pip/easy_install, for numpy it&#8217;s generally recommended to download a binary release so it installs a bit faster.</p>
<p>Example usage: <a href="https://github.com/WoLpH/numpy-stl">https://github.com/WoLpH/numpy-stl</a></p>
<div class="highlighted-source monokai python">
<pre><span class="kn">from</span> <span class="nn">stl</span> <span class="kn">import</span> <span class="n">stl</span>

<span class="n">mesh</span> <span class="o">=</span> <span class="n">stl</span><span class="o">.</span><span class="n">StlMesh</span><span class="p">(</span><span class="s">'some_file.stl'</span><span class="p">)</span>
<span class="c"># The mesh normals (calculated automatically)</span>
<span class="n">mesh</span><span class="o">.</span><span class="n">normals</span>
<span class="c"># The mesh vectors</span>
<span class="n">mesh</span><span class="o">.</span><span class="n">v0</span><span class="p">,</span> <span class="n">mesh</span><span class="o">.</span><span class="n">v1</span><span class="p">,</span> <span class="n">mesh</span><span class="o">.</span><span class="n">v2</span>
<span class="c"># Accessing individual points (concatenation of v0, v1 and v2 in triplets)</span>
<span class="n">mesh</span><span class="o">.</span><span class="n">points</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">mesh</span><span class="o">.</span><span class="n">v0</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">mesh</span><span class="o">.</span><span class="n">points</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">mesh</span><span class="o">.</span><span class="n">v1</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">mesh</span><span class="o">.</span><span class="n">points</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">==</span> <span class="n">mesh</span><span class="o">.</span><span class="n">v2</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">mesh</span><span class="o">.</span><span class="n">points</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span> <span class="o">==</span> <span class="n">mesh</span><span class="o">.</span><span class="n">v0</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

<span class="n">mesh</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s">'new_stl_file.stl'</span><span class="p">)</span>
</pre>
</div>
<p>Documentation can be found here: <a href="http://numpy-stl.readthedocs.org/en/latest/">http://numpy-stl.readthedocs.org/en/latest/</a><br />
Please let me know if you have any problems using it or just to tell me that you like the project <img alt=":)" class="wp-smiley" src="http://a.wol.ph/wp-includes/images/smilies/icon_smile.gif" /></p>
<div class="su-linkbox" id="post-228-linkbox"><div class="su-linkbox-label">Link to this post!</div><div class="su-linkbox-field"><input readonly="readonly" style="width: 100%;" type="text" value="&lt;a href=&quot;http://w.wol.ph/2015/01/28/readingwriting-3d-stl-files-numpy-stl/&quot;&gt;Reading/writing 3D STL files with numpy-stl&lt;/a&gt;" /></div></div>
    </div>
    <div class="feedEntry">

        <a href="http://www.caktusgroup.com/blog/2015/01/27/Django-Logging-Configuration-logging_config-default-settings-logger/" title="Django Logging Configuration: How the Default Settings Interfere with Yours">
            <h2>Django Logging Configuration: How the Default Settings Interfere with Yours</h2>
        </a>

        <p class="discreet">
            
                  By Caktus Consulting Group from Django community aggregator: Community blog posts.
            
            
            
                Published on <span name="publication_time">Jan 27, 2015</span>.
            
        </p>

        <p>My colleague <a href="http://www.caktusgroup.com/about/vinod-kurup/">Vinod</a> recently found the answer on Stack Overflow to something that's been bugging me for a long time - why do my Django logging configurations so often not do what I think they should?</p>
<h2>Short answer</h2>
<p>If you want your logging configuration to behave sensibly, set <code>LOGGING_CONFIG</code> to <code>None</code> in your Django settings, and do the logging configuration from scratch using the Python APIs:</p>
<div class="codehilite"><pre><span class="n">LOGGING_CONFIG</span> <span class="o">=</span> <span class="n">None</span>
<span class="n">LOGGING</span> <span class="o">=</span> <span class="p">{</span><span class="o">...</span><span class="p">}</span>  <span class="c1"># whatever you want</span>

<span class="nb">import</span> <span class="n">logging</span><span class="o">.</span><span class="n">config</span>
<span class="n">logging</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">dictConfig</span><span class="p">(</span><span class="n">LOGGING</span><span class="p">)</span>
</pre></div>
<h2>Explanation</h2>
<p>The kernel of the explanation is in this <a href="http://stackoverflow.com/questions/20282521/django-request-logger-not-propagated-to-root/22336174#22336174">Stack Overflow answer</a> by <a href="http://stackoverflow.com/users/260365/jcotton">jcotton</a>; kudoes to jcotton for the answer:  before processing your settings, Django establishes a default configuration for Python's logging system, but you can't override it the way you would think, because <code>disable_existing_loggers</code> doesn't work quite the way the Django documentation implies.</p>
<p>The <a href="https://docs.djangoproject.com/en/1.7/topics/logging/#configuring-logging">Django documentation</a> for <code>disable_existing_loggers</code> in 1.6, 1.7, and dev (as of January 8, 2015) says "If the <code>disable_existing_loggers</code> key in the LOGGING dictConfig is set to True (which is the default) the default configuration <em>is completely overridden</em>."  (emphasis added)</p>
<p>That made me think that I could set <code>disable_existing_loggers</code> to <code>True</code> (or leave it out) and Django's previously established default configuration would have no effect.</p>
<p>Unfortunately, that's not what happens. The <code>disable_existing_loggers</code> flag only does literally what it says: it disables the existing loggers, which is different from deleting them. The result is that they stay in place, they don't log any messages, but they also <em>don't propagate any messages to any other loggers</em> that might otherwise have logged them, regardless of whether they're configured to do so.</p>
<p>What if you try the other option, and set <code>disable_existing_loggers</code> to <code>False</code>? Then your configuration is merged with the previous one (the default configuration that Django has already set up), without disabling the existing loggers.  If you use Django's <code>LOGGING</code> setting with the default <code>LOGGING_CONFIG</code>, there is no setting that will simply replace Django's default configuration.</p>
<p>Because Django installs several <code>django</code> loggers, the result is that unless you happened to have specified your own configuration for each of them (replacing Django's default loggers), you have some hidden loggers possibly blocking what you expect to happen.</p>
<p>For example - when I wasn't sure what was going on in a Django project, sometimes I'd try just adding a root logger, to the console or to a file, so I could see everything. I didn't know that the default Django loggers were blocking most log messages from Django itself from ever reaching the root logger, and I would get very frustrated trying to see what was wrong with my logging configuration. In fact, my own logging configuration was probably fine; it was just being blocked by a hidden, overriding configuration I didn't know about.</p>
<p>We could work around the problem by carefully providing our own configuration for each logger included in the Django default logging configuration, but that's subject to breaking if the Django default configuration changes.</p>
<p>The most fool-proof solution is to disable Django's own log configuration mechanism by setting <code>LOGGING_CONFIG</code> to None, then setting the log configuration explicitly ourselves using the Python logging APIs. There's an example above.</p>
<h2>The nitty-gritty</h2>
<p>The <a href="https://docs.python.org/3/library/logging.config.html?highlight=disable_existing_loggers#logging.config.fileConfig">Python documentation</a> is more accurate: "<code>disable_existing_loggers</code> – If specified as False, loggers which exist when this call is made are left enabled. The default is True because this enables old behavior in a backward- compatible way. This behavior is to disable any existing loggers unless they or their ancestors are explicitly named in the logging configuration."</p>
<p>In other words, <code>disable_existing_loggers</code> does  literally what it says: it leaves existing loggers in place, it just changes them to disabled.</p>
<p>Unfortunately, Python doesn't seem to document exactly what it means for a logger to be disabled, or even how to do it. The <a href="https://hg.python.org/cpython/file/3.4/Lib/logging/config.py#l182">code</a> seems to set a <code>disabled</code> attribute on the logger object.  The <a href="https://hg.python.org/cpython/file/3.4/Lib/logging/__init__.py#l1418">effect</a> is to stop the logger from calling any of its handlers on a log event.  An additional effect of not calling any handlers is to also block propagation of the event to any parent loggers.</p>
<h2>Status of the problem</h2>
<p>There's been some recent <a href="https://groups.google.com/forum/#!topic/django-developers/BgjVkqwyP-w">discussion on the developers' list</a> about at least improving the documentation, with a core developer offering to review anything submitted. And that's where things stand.</p>
    </div>
    <div class="feedEntry">

        <a href="http://www.caktusgroup.com/blog/2015/01/26/were-launching-django-code-school-astro-code-school/" title="We’re launching a Django code school: Astro Code School">
            <h2>We’re launching a Django code school: Astro Code School</h2>
        </a>

        <p class="discreet">
            
                  By Caktus Consulting Group from Django community aggregator: Community blog posts.
            
            
            
                Published on <span name="publication_time">Jan 26, 2015</span>.
            
        </p>

        <p>One of the best ways to grow the Django community is to have more high-quality Django developers. The good news is that we’ve seen sharply increasing demand for Django web applications. The challenge that we and many other firms face is that there’s much higher demand than there is supply: there aren’t enough high-quality Django developers. We’ve talked about this issue intensely internally and with our friends while at DjangoCon and PyCon. We decided that we can offer at least one solution: a new Django-focused code school.</p>
<p>We’re pleased to announce the launch of <a href="http://astrocodeschool.com">Astro Code School</a> in Spring 2015. Astro will be the first Django code school on the East Coast. Programs include private trainings and weekend, 3-week, and 12-week full-time courses. In addition to Django, students will learn Python (of course), HTML, CSS, and JavaScript. They will come away being able to build web applications. The shorter programs will be geared towards beginners. The longer program will are for those with previous programming experience. Astro will also provide on-site, private corporate training, another area we frequently get asked about.</p>
<p>Astro will be a separate company under Caktus. To support Astro, we welcome <a href="http://www.caktusgroup.com/about/brian-russell/">Brian Russell</a>, the new director of Astro. Brian is the former owner of Carrboro Creative Coworking, the place where Caktus got its start. In addition to being a long-term supporter of new developers, Brian is also an artist and entrepreneur. He has a special interest in increasing diversity within open source. Django itself is one of the most respectful and welcoming places for women and minorities and he’s excited to contribute.</p>
<p>Our first and leading instructor will be <a href="http://www.caktusgroup.com/about/caleb-smith/">Caleb Smith</a>, a Caktus developer since 2011. Caleb first joined Caktus as an intern, straight from his days as a public school music teacher. He continued to teach while at Caktus, supporting free and low-cost courses for women through the nonprofit Girl Develop It RDU. He’s also currently teaching an advanced web application course at the University of North Carolina’s School of Journalism and Mass Communication.</p>
<p>We’re building out the space for Astro currently on the first floor of our new headquarters in Downtown Durham. Astro Code School will have a dedicated 1,795 square feet of space. Construction should be complete by April.</p>
    </div>
    <div class="feedEntry">

        <a href="http://www.caktusgroup.com/blog/2015/01/23/why-i-love-technical-blogging/" title="Why I Love Technical Blogging">
            <h2>Why I Love Technical Blogging</h2>
        </a>

        <p class="discreet">
            
                  By Caktus Consulting Group from Django community aggregator: Community blog posts.
            
            
            
                Published on <span name="publication_time">Jan 23, 2015</span>.
            
        </p>

        <p>I love writing blog posts, and today I’m setting out to do something I’ve never tried before: write a blog post about writing blog posts. A big part of our mission at Caktus is to foster and help grow the Python and Django development communities, both locally and nationally. Part of how we’ve tried to accomplish this in the past is through hosting development sprints, sponsoring and attending conferences such as PyCon and DjangoCon, and building a knowledge base of common problems in Python and Django development in our blog. Many in the Django community first get to know Caktus through our blog, and it’s both gratifying and humbling when I meet someone at a conference and the person thanks me for a post Caktus wrote that helped him or her solve a technical problem at some point in the past.</p>
<p>While I personally don’t do as much software development as I used to and hence no longer write as many technical posts, the Caktus blog and many others in the community continue as a constant source of inspiration and education to me. As software developers we are constantly trying to work ourselves out of a job, building tools that organize information and help people communicate. Sharing a brief, highly specific technical blog post serves in a similar capacity; after I’ve spent 1-2 hours or more researching something that ultimately took 5-10 minutes to fix, I’d hate for someone else to have to go through the same experience. Writing up a quick, 1-2 paragraph technical post about the issue not only helps me think through the problem, but also hopefully saves a few minutes of someone else’s life at some point in the future.</p>
<p>To help me better understand what I like so much about blogging, I went back and reviewed the history of Caktus blogging efforts over the past 5 years and separated our posts into categories. While I’m sure there are innumerable ways to do this, in case it serves as a source of inspiration to others, what follows are the categories I came up with:</p>
<ul>
<li>
<p><strong>Technical Tidbits.</strong> These types of posts are small, usually a paragraph or two, along with a code or configuration snippet. They might cover upgrading a specific open source package or reusable app in your project, or augment existing Django release notes when you find the built-in Django documentation lacking for a specific use case. Posts in this category that we’ve written in the past at Caktus include <a href="http://www.caktusgroup.com/blog/2009/03/27/migrating-from-django-photologue-1x-to-2x/">upgrading django-photologue</a> and <a href="http://www.caktusgroup.com/blog/2009/08/13/setting-postgresqls-shmmax-in-mac-os-x-105-leopard/">changing or SHMMAX setting (for PostgreSQL) on a Mac</a>. <em>These are great posts to write after you’ve just done something for the first time. You’ll have a fresher perspective than someone who’s done the task many times before. Because of this, you can easily anticipate many of the common problems someone coming to the task for the first time might face.</em></p>
</li>
<li>
<p><strong>Debugging Sugar.</strong> Posts handy for debugging purposes often rely on a specific error message or stack trace. Another good candidate for this type of post is documenting an existing Django bug that requires a specific workaround. Posts we’ve written in this category include <a href="http://www.caktusgroup.com/blog/2013/10/30/using-strace-debug-stuck-celery-tasks/">using strace to debug stuck celery tasks</a> and the (thankfully now obsolete) <a href="http://www.caktusgroup.com/blog/2009/05/26/parsing-microseconds-in-a-django-form/">parsing microseconds in the Django admin</a>. <em>A good sign you need to write a post like this is that you had to spend more than 5-10 minutes Googling for an answer to something or asking your co-workers. If you’re looking for an answer and having trouble finding it, there’s a good chance someone else out there is doing the same and would benefit from your blog post.</em></p>
</li>
<li>
<p><strong>Open Source Showcase.</strong> Open Source Showcase posts are a great way to spread the word about a project you have or a teammate has written, or to validate a 3rd party app or Django feature you’ve found particularly helpful. These are typically longer, more in-depth analyses of a project or feature rather than an answer to a specific technical problems (though the two are not always mutually exclusive). At Caktus we’ve written about our <a href="http://www.caktusgroup.com/blog/2012/10/30/django-scribbler-a-lightweight-front-end-interface-for-Django-template-editing/">django-scribbler</a> app as well as several new features in Django, including <a href="http://www.caktusgroup.com/blog/2011/09/20/bulk-inserts-django/">bulk inserts</a>, <a href="http://www.caktusgroup.com/blog/2011/12/29/class-based-views-django-13/">class-based views</a>, and support for <a href="http://www.caktusgroup.com/blog/2013/08/07/migrating-custom-user-model-django/">custom user models</a>. <em>While these posts can require a significant time investment to get right, their value as augmentation to or 3rd-party validation of Python and Django development patterns cannot be underrated. Patterns are set through a community rallying around an open source package or approach. Proposing and sharing these ideas openly is what drives the open source community forward.</em></p>
</li>
<li>
<p><strong>Mini How-tos.</strong> Mini How-tos are generally a combination of other types of posts. They start with a specific goal in mind -- setting up a server, installing a reusable app -- and walk the reader through all the necessary steps, services, and packages required to get there. If you feel passionately that something should be done in a certain way, this is a great way to set a standard for the community to be aware of and potentially follow. This could cover anything from <a href="http://www.caktusgroup.com/blog/2012/01/10/configuring-jenkins-slave/">configuring a Jenkins slave</a> to <a href="http://www.caktusgroup.com/blog/2014/11/10/Using-Amazon-S3-to-store-your-Django-sites-static-and-media-files/">using Amazon S3 to store your static and uploaded media</a>. <em>Similar to an Open Source Showcase, Mini How-tos are an asset to the community insofar as they help advance and disseminate common approaches to software development problems. At the same time, they’re open to review and critique by the wider open source community.</em></p>
</li>
</ul>
<p>A big thank you to everyone in the Python and Django community for being open and willing to share your experiences and problem solving efforts. Without this, Caktus would not be where it is today and for that I am deeply grateful. If this post happens to inspire at least one short technical post from someone who hasn’t written one before, I’ll consider it a success.</p>
    </div>
    <div class="feedEntry">

        <a href="http://gc-taylor.com/blog/2015/01/23/why-you-should-donate-django-fellowship/" title="Why you should donate to the Django fellowship program">
            <h2>Why you should donate to the Django fellowship program</h2>
        </a>

        <p class="discreet">
            
                  By Greg Taylor from Django community aggregator: Community blog posts.
            
            
            
                Published on <span name="publication_time">Jan 23, 2015</span>.
            
        </p>

        <p><em>Disclaimer: I do not represent the Django Software Foundation in any way,
nor has anything below been endorsed by the <span class="caps">DSF</span>. The following opinions
are my own, unsolicited&nbsp;rambling.</em></p>
<p>If you hadn&#8217;t been looking for it specifically, you may have missed it. The
<a class="reference external" href="https://www.djangoproject.com/foundation/">Django Softare Foundation</a> is running a <a class="reference external" href="https://www.djangoproject.com/fundraising/">fundraising effort</a> for the new
Django Fellowship program. It sounds like they&#8217;re still trying to figure out
how to get the word out, so I wanted to do what I could to tell <em>you</em>
why you should chip&nbsp;in.</p>
<p>This particular blog post is going to focus on encouraging (peer-pressuring)
commercial Django users in particular, though enthusiasts are welcome to
read&nbsp;along!</p>
<div class="section" id="humble-beginnings">
<h2>Humble&nbsp;beginnings</h2>
<p>Django is free and open source. Just provide the expertise and the
infrastructure and you can build just about whatever web powered
contraption you&#8217;d like. So you end up doing just&nbsp;that.</p>
<p>Your first stop is the Django <a class="reference external" href="https://docs.djangoproject.com/en/1.7/intro/overview/">tutorial</a>, written and maintained by a community
of volunteers (just like the rest framework itself). You stumble along,
slowly at first. Perhaps you find yourself frustrated at times, or maybe things
move along at a faster pace. In no time, you&#8217;ve got &quot;Hello World!&quot; rendering,
and here comes a business&nbsp;idea!</p>
<p>One hundred lines of code turns into a thousand, then five thousand, and
beyond. You start seeing signups, and revenue begins to trickle in. You
toil away at your codebase, making improvements and dealing with the
&quot;accidental features&quot; that crept in during one of your late night dev&nbsp;sessions.</p>
<p>You could have built your business on one of any number of frameworks, but
you chose Django. You like how it&#8217;s a very productive way to build a web app.
You appreciate how it&#8217;s not impossible to find Django developers to work
with you. There are probably some things you don&#8217;t like, but you might not
have the time to work on fixing them yourself. You&#8217;re just busy shipping
and&nbsp;growing.</p>
</div>
<div class="section" id="but-it-could-be-better-still">
<h2>But it could be better&nbsp;still!</h2>
<p>You&#8217;re happily using Django, it serves you well. There are a few things you&#8217;d
love to see fixed or improved, but you don&#8217;t really have the time or
expertise to contribute directly. As luck would have it, all of the Django
core developers have day jobs themselves. Things would progress much more
quickly if we had someone working full-time on&nbsp;Django&#8230;</p>
<p>Enter: Django Fellowship Program. The idea is to fund at least one Django
developer to work for the <span class="caps">DSF</span> part or full-time for a while. During this
fellowship, said developer sets aside some or all of their other
responsibilities to focus on improving Django. The <span class="caps">DSF</span>, in turn, pays the
developer a fair (but low rate) for their&nbsp;work.</p>
<p>As per the Tim Graham&#8217;s recent <a class="reference external" href="https://www.djangoproject.com/weblog/2015/jan/21/django-fellowship-retrospective/">retrospective</a> blog post, we&#8217;ve see some huge
leaps forward for the project during these fellowships. These are periods of
focus and rapid improvement that everyone (including your business) benefit&nbsp;from.</p>
<p>The only problem is that we&#8217;re not going to see the benefits of this program
unless it gets (and stays) funded. A well-funded fellowship program
could mean one (or more) developers working on Django full-time at any
given point in time. That would be huge for the project (and you and&nbsp;I).</p>
</div>
<div class="section" id="why-you-should-donate">
<h2>Why you should&nbsp;donate</h2>
<p>As a business, we are donating to the fellowship program to see one of our
critical components improved. Due to the fellowship application process,
you can be assured that your money will be paying a capable, trusted
developer to get things&nbsp;done.</p>
<p>Consequently, you can view a donation to the Django Fellowship program
as an investment with an almost assuredly positive return. If you are making
money with Django, consider making a (potentially tax-deductible)
<a class="reference external" href="https://www.djangoproject.com/fundraising/">investment</a> in what may be the foundation of your&nbsp;business.</p>
<p>At the end of the first full day of fund-raising, there are precious few
commercial donors listed in the &quot;Django Heroes&quot; leaderboard. Let&#8217;s help
change&nbsp;that!</p>
<p>If you don&#8217;t hold the purse strings at your business, get in touch with
someone who does and tell them about this <a class="reference external" href="https://www.djangoproject.com/fundraising/">investment</a> with near-guaranteed&nbsp;returns.</p>
</div>
    </div>
    <div class="feedEntry">

        <a href="http://www.caktusgroup.com/blog/2015/01/22/caktus-looking-web-design-director/" title="Caktus is looking for a Web Design Director">
            <h2>Caktus is looking for a Web Design Director</h2>
        </a>

        <p class="discreet">
            
                  By Caktus Consulting Group from Django community aggregator: Community blog posts.
            
            
            
                Published on <span name="publication_time">Jan 22, 2015</span>.
            
        </p>

        <p>Over the last two years Caktus’ <a href="https://dribbble.com/caktusgroup">design portfolio</a> has rapidly been growing. We’ve taken on new <a href="https://us.pycon.org/2015/">projects</a> <a href="http://www.ncgetcovered.org/">primarily</a> focused on design and have <a href="http://www.caktusgroup.com/blog/2014/11/12/weve-won-two-w3-awards-creative-excellence-1/">received community recognition</a> for those efforts. We are happy to have grown our design capabilities to match the level of quality we demand from our Django developers. We have found it’s important to have strength on both sides of the table as each side challenges the other and forces the final product of our process to be as high quality as possible.</p>
<p>In an effort to continue to push ourselves and expand our web design skill sets, Caktus is looking to <a href="http://www.caktusgroup.com/careers/#op-44289-web-design-director">hire a new Web Design Director</a>. We’re searching for someone who can do a bit of wireframing and user experience and then has the tools necessary to design and code pages. We’re looking for someone who is attune to both form and function and knows where to focus depending on clients’ needs. Caktus is committed to doing good in our development communities as well as through the projects that we choose to work on, so we are also interested in finding someone who is engaged in the design community.</p>
<p>If you or someone you know would be a good fit, <a href="http://www.caktusgroup.com/careers/#op-44289-web-design-director">please apply to the position</a>! If you have any questions <a href="http://www.caktusgroup.com/contact/">get in touch</a>.</p>
    </div>
    <div class="feedEntry">

        <a href="https://lincolnloop.com/blog/introducing-high-performance-django-expert-session/" title="Introducing High Performance Django Expert Sessions">
            <h2>Introducing High Performance Django Expert Sessions</h2>
        </a>

        <p class="discreet">
            
                  By Lincoln Loop from Django community aggregator: Community blog posts.
            
            
            
                Published on <span name="publication_time">Jan 21, 2015</span>.
            
        </p>

        <p>With the launch of our book, <a href="https://highperformancedjango.com">High Performance Django</a>, we’ve received a number of inquiries from people asking for advice, for which the answers are too specific to their application to give good general advice, and too short to sign a consulting engagement.</p>

<p>Rather than decline to help, we now offer <a href="https://lincolnloop.com/expert-sessions/">Expert Sessions</a> - a one-hour online consultation with a member (or members) of the Lincoln Loop team.</p>

<p>Schedule an Expert Session and we'll meet up with you via Google Hangouts, Skype, or phone to answer any questions or provide expertise on building and scaling your complex Django application.</p>

<p>In the past, we've answered such questions as:</p>

<ul>
<li><p>What technologies should we use for building a complex, high-performance application? </p></li>
<li><p>Our app is super complex and it takes us 3 days to onboard a new developer. How can we simplify things to speed up onboarding?</p></li>
<li><p>Should we move our infrastructure to Amazon Web Services or Heroku? What are the benefits and how do we perform the correct analysis?</p></li>
<li><p>How can we make our deploys more reliable?</p></li>
<li><p>How do we move from our legacy system to Django in order to improve reliability and cut costs?</p></li>
<li><p>Should we use MongoDB or Redis?</p></li>
<li><p>How do we properly load balance across our app servers?</p></li>
<li><p>How can we optimize our development workflow?</p></li>
</ul>

<p>We can also provide expertise in other technologies, such as SaltStack, Go (golang), Javascript (React.js and Backbone), MySQL, and Postgres.</p>

<p>To schedule an Expert Session, or for more information, please see our <a href="https://lincolnloop.com/expert-sessions/">Expert Sessions page</a>.</p>
    </div>
    <div class="feedEntry">

        <a href="http://www.caktusgroup.com/blog/2015/01/20/webinar-testing-client-side-applications-django/" title="Webinar: Testing Client-Side Applications with Django">
            <h2>Webinar: Testing Client-Side Applications with Django</h2>
        </a>

        <p class="discreet">
            
                  By Caktus Consulting Group from Django community aggregator: Community blog posts.
            
            
            
                Published on <span name="publication_time">Jan 20, 2015</span>.
            
        </p>

        <p>Technical Director <a href="http://www.caktusgroup.com/about/mark-lavin/">Mark Lavin</a> will be hosting a free <a href="http://www.oreilly.com/pub/e/3302">O’Reilly webinar</a> today at 4PM EST or 1PM PT on Testing Client-Side Applications with Django. Mark says testing is one of the most popular question topics he receives. It’s also a topic near and dear to Caktus’ quality-loving heart. Mark’s last webinar garnered more than 500 viewers, so sign up quick!</p>
<p>Here’s a description from Mark:</p>
<blockquote>During the session we'll examine a simple REST API with Django connected to a single page application built with Backbone. We'll look at some of the tools available to test the application with both Javascript unit tests and integration tests written in Python. We'll also look at how to organize them in a sane way for your project workflow.</blockquote>
<p>To sign up, visit the <a href="http://www.oreilly.com/pub/e/3302">webinar page on O’Reilly’s site</a>.</p>
    </div>
    <div class="feedEntry">

        <a href="https://www.rossp.org/blog/uptime-robot-s3/" title="Self-Hosted Server Status Page with Uptime Robot, S3, and Upscuits">
            <h2>Self-Hosted Server Status Page with Uptime Robot, S3, and Upscuits</h2>
        </a>

        <p class="discreet">
            
                  By Ross Poulton from Django community aggregator: Community blog posts.
            
            
            
                Published on <span name="publication_time">Jan 20, 2015</span>.
            
        </p>

        <p>For quite a while I've had a public "Status" page online for <a href="http://pingdom.com/">WhisperGifts</a> via Pingdom. It basically just shows uptime over the past few days, but given my site is relatively low-volume and not ovely critical to my customers, the $10/month for Pingdom was actually one of my largest expenses after hosting.</p>
<p>So, I started looking for an alternative. </p>
<p>Today I re-deployed the <a href="http://status.whispergifts.net/">WhisperGifts Status Page</a> using a combination of <a href="https://uptimerobot.com/">Uptime Robot</a>, <a href="https://github.com/digibart/upscuits">Upscuits</a> and <a href="http://aws.amazon.com/">Amazon S3</a>.</p>
<p>In short, I have Uptime Robot checking the uptime of my site (including it's subsites, such as the admin and user pages). The statistics are gathered and presented by Upscuits, which is entirely client-side JavaScript hosted on S3.</p>
<p>My basic todo list for next time:</p>
<ol>
<li><a href="https://uptimerobot.com/">Sign up for Uptime Robot</a>. I'd been using them for ages on their Free plan as a backup to Pingdom; this gives 5-minute checks. Their paid plan gives 1-minute resolution.</li>
<li>Add your sites, make sure they're being monitored correct.</li>
<li>On the Uptime Robot dashboard, click <em>My Settings</em>. Open the section labelled <em>Monitor-Specific API Keys</em> and search for your Monitor. Copy the API key to a text file for later; repeat this step for subsequent monitors you want to include on your status page.</li>
<li>Download <a href="https://github.com/digibart/upscuits">the latest Upscuits release</a> to your PC.</li>
<li>In the <code>public</code> folder of the upscuits package, rename <code>config.example.js</code> to <code>config.js</code>. Paste your API key(s) inside it.</li>
<li>Create an AWS bucket called eg <code>status.mysite.com</code> and enable website mode. Setup your DNS etc to point to this bucket.</li>
<li>Upload the contents of <code>public/</code> to your AWS bucket</li>
<li>Visit <a href="http://status.whispergifts.net/">your new status page</a> and view your last 12 months of Uptime Robot statistics</li>
<li><s>Close your Pingdom account saving $10 a month</s>
Profit!</li>
</ol>
<p>For a small site like mine this has a couple of obvious benefits. It's free (or $4.50/month if you want higher resolution - still half the price of the most basic Pingdom plan); it uses a tiny amount of S3 storage which is as good as free, and doesn't involve running any server-side code. The included <code>index.html</code> is also easily customisable if you like, since it's just plain HTML (using the Bootstrap framework, by default). This is a big win over hosted solutions, IMO.</p>
    </div>
    <div class="feedEntry">

        <a href="http://evennia.blogspot.com/2015/01/building-django-proxies-and-mud.html" title="Building Django proxies and MUD libraries">
            <h2>Building Django proxies and MUD libraries</h2>
        </a>

        <p class="discreet">
            
                  By Griatch's Evennia musings (MU* creation with Django+Twisted) from Django community aggregator: Community blog posts.
            
            
            
                Published on <span name="publication_time">Jan 19, 2015</span>.
            
        </p>

        <div class="separator" style="clear: both; text-align: center;"><a href="http://upload.wikimedia.org/wikipedia/commons/5/5e/Bibliothek_St._Florian.jpg" style="clear: left; float: left; margin-bottom: 1em; margin-right: 1em;"><img border="0" height="320" src="http://upload.wikimedia.org/wikipedia/commons/5/5e/Bibliothek_St._Florian.jpg" width="240" /></a></div><span style="font-size: large;">2015 is here <span style="font-size: small;">and t</span></span>here is a lot of activity going on in Evennia's repository, mailing list and IRC channel right now, with plenty of people asking questions and starting to use the system to build online games.<br /><br />We get newcomers of all kinds, from experienced coders wanting to migrate from other code bases to newbies who are well versed in mudding but who aim to use Evennia for learning Python. At the moment the types of games planned or under development seems rather evenly distributed between RPI-style MUDs and MUSH games (maybe with a little dominance of MUSH) but there are also a couple of hack-and-slash concepts thrown into the mix. We also get some really wild concepts pitched to us now and then. What final games actually comes of it, who can tell, but people are certainly getting their MU*-creative urges scratched in greater numbers, which is a good sign. <br /><br />Since Christmas our <i>"devel"</i> branch is visible online and is teeming with activity. So I thought I'd post an summary about it in this blog. The more detailed technical details for active developers can be found on Evennia's mailing list <a href="https://groups.google.com/forum/#%21topic/evennia/6ug7m872GIk" target="_blank">here</a> (note that full docs are not yet written for devel-branch). <br /><br /><span style="font-size: large;">Django proxies for Typeclasses</span><br /><br /><span style="font-size: large;"><span style="font-size: small;">I have written about Evennia's Typeclass system before on this blog. It is basically a way to "decorate" Django database models with a second set of classes to allow Evennia developers to create any type of game entity without having to modify the database schema. It does so by connecting one django model instance to one typeclass instance and overloading <span>__setattr__ </span>and <span>__getattribute__</span> to transparently communicate between the two.</span></span><br /><span style="font-size: large;"><span style="font-size: small;">&nbsp;</span></span><br /><span style="font-size: large;"><span style="font-size: small;">For the devel branch I have refactored our typeclass system to make use of Django's <i><a href="https://docs.djangoproject.com/en/dev/topics/db/models/#proxy-models" target="_blank">proxy models</a> </i>instead<i>. </i>Proxy models have existed for quite a while in Django, but they simply slipped under my radar until a user pointed them out to me late last year. A proxy model is basically a way to "replace the Python representation of a database table with a proxy class". Sounds like a Typeclass, doesn't it? </span></span><br /><br /><span style="font-size: large;"><span style="font-size: small;">Now, proxy models doesn't work <i>quite</i> like typeclasses out of the box - for one thing if you query for them you will get back the original model and not the proxy one. They also do not allow multiple inheritance. Finally I don't want Evennia users to have to set up django <span>Meta</span> info every time they use a proxy. So most work went into overloading the proxy multiclass inheritance check (there is a django issue about how to fix this). Along the way I also&nbsp;redefined the default managers and <span>__init__</span> methods to always load the proxy actually searched for and not the model. I finally created metaclasses to handle all  the boilerplate. We choose to keep the name <i>Typeclass</i> also for this extended proxy. This is partly for legacy reasons, but typeclasses do have their own identity: they are not vanilla Django-proxies nor completely normal Python classes (although they are very close to the latter from the perspective of the end user). </span></span><br /><span style="font-size: large;">&nbsp;</span><br />Since typeclasses now are directly inheriting from the base class (due to metaclassing this looks like normal Python inheritance), it makes things a lot easier to visualize, explain and use. Performance-wise this system is en par with the old, or maybe a little faster, but it will also be a lot more straight forward to cache than the old. I have done preliminary testing with threading and it looks promising (but more on that in a future post).&nbsp; <br /><br /><br /><span style="font-size: large;">Evennia as a Python library package</span><br />&nbsp;Evennia has until now been solely distributed as a version controlled source tree (first under SVN, then Mercurial and now via GIT and Github). In its current inception you clone the tree and find inside it a <span>game/</span> directory where you create your game. A problem we have when helping newbies is that we can't easily put pre-filled templates in there - if people used them there might be merge conflicts when we update the templates upstream. So the way people configure Evennia is to make copies of template modules and then change the settings to point to that copy rather than the default module. This works well but it means a higher threshold of setup for new users and a lot of describing text. Also, while learning GIT is a useful skill, it's another hurdle to get past for those who just want to change something minor to see if Evennia is for them. <br /><br />In the devel branch, Evennia is now a library. The <span>game/</span> folder is no longer distributed as part of the repository but is created dynamically by using the new binary <span>evennia</span> launcher program, which is also responsible for creating (or migrating) the database as well as operating the server: <br /><br /><blockquote class="tr_bq"><span>evennia --init mygame</span><br /><span>cd mygame</span><br /><span>evennia migrate</span><br /><span>evennia start</span> </blockquote><br />Since this new folder is <i>not </i>under our source tree, we can set up and copy pre-made template modules to it that people can just immediately start filling in without worrying about merge conflicts. We can also dynamically create a setting file that fits the environment as well as set up a correct tree for overloading web functionality and so on. It also makes it a lot easier for people wanting to create multiple games and to put their work under separate version control. <br /><br />Rather than traversing the repository structure as before you henceforth will just do <span>import evennia</span> in your code to have access to the entirety of the API. And finally this means it will (eventually) be possible to install Evennia from <a href="https://pypi.python.org/pypi/Evennia-MUD-Server/Beta" target="_blank">pypi</a> with something like <span>pip install evennia</span>. This will greatly ease the first steps for those not keen on learning GIT. <br /><br /><span style="font-size: large;">For existing users</span><br /><br />Both the typeclasses-as-proxies and the evennia library changes are now live in the devel branch. Some brave users have already started taking it through its paces but it will take some time before it merges into master. <br /><br />The interesting thing is that despite all this sounding like a huge change  to Evennia, the coding API doesn't change very much, the database schema almost not at  all. With the exception of some properties specific to the old  connection between the typeclass and model, code translate over pretty  much without change from the developer's standpoint. <br /><br />The main translation work for existing developers lies in copying over their code from the old <span>game/</span> directory to the new dynamically created game folder. They need to do a search-and-replace so that they import from <span>evennia</span> rather than from <span>src</span> or <span>ev. </span>There may possibly be some other minor things. But so far testers have not found it too cumbersome or time consuming to do. And all agree that the new structure is worth it.<br /><br />So, onward into 2015!<br /><br /><br /><span style="font-size: xx-small;"><i>Image: "Bibliothek St. Florian" by Original uploader was Stephan Brunker at de.wikipedia Later versions were uploaded by Luestling at de.wikipedia. - Originally from de.wikipedia; description page is/was here.. Licensed under CC BY-SA 3.0 via Wikimedia Commons - http://commons.wikimedia.org/wiki/File:Bibliothek_St._Florian.jpg#mediaviewer/File:Bibliothek_St._Florian.jpg</i></span><br /><br />
    </div>
    <div class="feedEntry">

        <a href="https://karthikabinav.wordpress.com/2015/01/18/mirroring-my-article-on-chennai-36-the-alumni-blog-of-iitm/" title="Mirroring my article on Chennai 36 – The Alumni Blog of IITM">
            <h2>Mirroring my article on Chennai 36 – The Alumni Blog of IITM</h2>
        </a>

        <p class="discreet">
            
                  By Django for beginners from Django community aggregator: Community blog posts.
            
            
            
                Published on <span name="publication_time">Jan 18, 2015</span>.
            
        </p>

        <p>Recently, I wrote an article to Chennai36 which is a blog maintained by the Alumni Association of IITM. The article was about my opinions on how to apply to graduate school for an undergrad at IITM. In this post, I am mirroring that article on this blog.</p>
<p>&nbsp;</p>
<p>The original article can be found <a href="http://chennai36.iitm.ac.in/the-grad-guru-karthik-abinav-at-university-of-maryland-college-park/" target="_blank" title="Chennai36 Article">here</a>.</p>
<p>&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;</p>
<p>The Grad Guru : Karthik Abinav at University of Maryland, College Park</p>
<p>Note :<em> Whenever I mean grad school, I am going to be referring to a </em>PhD<em> program. Though most of this advice also applies to MS programs, you should bear in mind that my focus is on </em>PhD<em> program. Since, I do not have much knowledge about the MS programs, I will not comment much </em>about<em> them in this article.</em><br />
<strong>1.  Please tell us about yourself, the university you are studying at, the research field you are working on, and the scope it has to offer after an MS or PhD. Also tell us about a typical day in the life of a postgraduate student.<br />
</strong><br />
I recently started my PhD in Computer Science at University of Maryland at College Park. I am broadly interested in theoretical computer science. At a high level, this area deals with the mathematical formalism for many of the fundamental computer science problems. The direct application of the work in this area is primarily in computer science, but not limited to it. Due to its extreme mathematical nature, most problems are abstracted sufficiently, to be applicable in a variety of other fields. Some of the common fields where work in this area is used are Economics, Operations Research, Computational Biology, etc. In terms of a researcher in this field, you have multiple options after a PhD. The most obvious choice is academia, either as a research scientist at one of the research labs in industry or a professor at one of the universities. But, due to the versatility of this subject, you can work at a number of other places, which at first do not seem related. For example, a quant researcher at a financial service is one such place. The kind of ideas required in those places requires a strong training in mathematics and computer science. Theoretical computer science is one way, which gives those particular skills to a researcher. Without going into great detail I would list down some places where one could join if one is not too keen on academia. Places such as Google, eBay, Amazon, etc. which does a so-called “Product oriented research” is yet another great place where a PhD in theoretical computer science can be of great help. In recent days, with computational biology relying heavily on techniques from computer science, a career as a computational biologist at industry is yet another lucrative option. With both the industry and academia moving at such a fast pace these days, one should also account for the options, which do not exist as of now, but will be a real option when one graduates.<br />
A typical day in the life of a grad student varies widely on what stage of a PhD one is in. For example, most universities have some form of course requirement to be completed in the first few years. Hence, a significant part of the first couple of years is spent doing graduate coursework. In my particular case, I spend about 8 hours a week attending classes and doing related work. Since, I serve as a teaching assistant, I spend another 7-8 hours teaching classes, holding office hours and grading. I spend about 15 hours doing research in the form of thinking about problems, reading relevant materials, attending talks etc. Since, these activities are amortized over a week, one can scale it appropriately to get an idea about the workload per day. The most important lesson I have started to learn is that a high amount of self-discipline is required, as a grad student, to get all the work done. If you want to give your fullest towards your research, classes and yet have a life outside the university, it is highly critical that you make a strict schedule and stick to it. This is yet another important skill you learn in pursuit of a PhD.<br />
<strong>2.  When did you decide to apply for further studies? What are the necessary skills, according to you, a person should develop in order to make himself cut out for research and not just getting a good Grad school?</strong><br />
My decision to apply to grad school was somewhere in third year, where I felt I might like the process of doing research. My first sparks came from thinking about problems from class work and the idea of figuring out solutions after toiling with it for a while. A typical “undergrad attitude”(which I admit, I too had at that point) is to believe that solving hard problems from a course work is in fact a great indicator about liking research. But in reality, doing research involves a lot more activities (sometimes mundane) and one should ensure they like the whole package before diving into it. I tried my hands at some simple research problems at institute and during my internship in summer. What struck me most about these experiences was the fact that I actually liked almost all of the associated activities along with solving problems. Critical thinking, evaluating multiple solutions, collaborating with other researchers, effective communication, a lot of writing, are some, among the many associated activities accompanying doing research. I realized that I would like to have these skills and would also enjoy the process of developing them. So for anyone considering research, I would suggest they try out working on some research problem. The only way to know if you like running a marathon is by running a marathon. No amount of short sprints will prepare you for a marathon.<br />
<strong>3.  How did you make the choice between placements and applying? Aren’t people who are working on projects and making their resume good enough to apply to Grad school less preferred by recruiters?</strong><br />
Though I had pretty much made up my mind to go to grad school, I went through the placement process nonetheless. In Computer Science, a lot of companies in the industry work on exciting stuff. They tackle problems that are challenging and the skill set required to be a competitive candidate there has a large overlap with skill set required to be a researcher. Hence, the conflict of “preparing a resume for grad school” is not too evident. However, one downside of going through both is the preparation process for the interviews alongside with preparing your grad school application. The interview process for most of these companies requires a focused practice, without which you would not stand a chance. This to me is the most important factor when considering both applying to grad school and going through the placement process. You need to put in double the effort and time than usual. However, if one is considering grad school against a so-called “non-core” company, then that’s a different ball game. I would suspect, in such cases one should make a clear decision upfront and prepare accordingly. But since, I never had to make such a decision, I may not be the right person to comment about it.<br />
<strong>4.  Is a high CGPA required for applying? How do you derive the motivation to study and get high grades in subjects not at all related to your research interests? Is it all lost for people below the ‘astronomical’ 9 point CGPA? How can they make up for not crossing the barrier? Does pursuing Honors add weight to his/her Grad school application?</strong><br />
A high CGPA is neither a necessary nor a sufficient condition when it comes to grad school. It is just one of the factors among the many factors that decides admission to grad school. But, this should not be interpreted as; having a low CGPA doesn’t hurt your chances. A good CGPA always helps, although the principle of higher the better is not necessarily correct. Similarly, a low CGPA doesn’t mean all is lost. But you have to make up with sufficient quality research to compensate for low CGPA.<br />
Very few people would have a research interest fixed in mind early in undergraduate. So, the concept of a course not aligning with one’s research interest does not make much sense. In fact, these courses are the one that would give you first sparks about which research area might suit you. In my opinion, every course has something to offer and one should look to gain these things out of every course. Also, as with any other aspect in life, the good and the bad always come together. If getting a good CGPA means higher chances of an admit to grad school and getting an admit to grad school means that much to you, you would definitely find the motivation to study hard for it. Also, the ‘astronomical’ 9-point CGPA is more of an artificial thing in my opinion. As I said before, CGPA is not the only factor and hence one should also do some quality research to increase one’s chances. It also helps one fully realize if a career in research is a right path for one.<br />
Honors program (at least in Computer Science) gives you the flexibility of taking more graduate electives. This particularly helps if you are unsure about what area excites you the most. But, if you would rather like to explore that by doing more research and fewer courses, then honors program doesn’t necessarily add more value. For most parts of grad school, you should show potential of a good researcher. Hence, doing more research is the best way to convince the committee that you are cut out for research. If you would like to seek these experiences from graduate level electives or otherwise is a choice that is personal to you.</p>
<p><strong>5.  How relevant are extra-curricular and Positions of Responsibility? If any, what position did you hold, and how did it help you?</strong><br />
With respect to direct impact on application, extra-curricular/positions of responsibility have almost no effect. They are looking for promising researchers and they want just about that. It does not really matter if you were a Shaastra Core or a Saarang Pro-show Coordinator, since those things aren’t going to give evidence about whether you will be a good researcher. But, this doesn’t mean one should not try their hands at them. They should do so only for personal pleasures and shouldn’t look at them as an investment, which would eventually reap some direct returns in terms of grad school applications. Among many things, they teach you a lot of life skills, which you will otherwise never learn from classroom. In my particular case, I remember doing some webops/mobops activities during Shaastra, Saarang, and placements. I did them since, at that time they seemed challenging and nice to me. The biggest thing that helped me from those experiences was that I got to make a lot of friends with many of the smart people in insti.<br />
<strong>6.  Can you tell us about the other schools you applied to ? Did you have alternate options? How did you select between them? How do we gauge the authenticity of world rankings of a university and to which extent are they reliable? </strong><br />
I applied to about 10 schools overall with a mix of Computer Science and Operations Research programs. I had to make a decision between University of Michigan and University of Maryland, and ended up choosing University of Maryland. Personally, my criteria included a mix of department, potential advisors with whom I would work with, strength of the allied departments like Electrical Engineering, Math, etc., location of the university and proximity to the closest city. A lot of people underestimate the last factor. In my opinion, that is as important a factor as, choosing whom you work with. Grad school is a long journey spanning for at least half a decade. I personally didn’t prefer to work at an isolated college town located in the middle of nowhere, with the travel to the nearest city requiring an hour’s flight journey.<br />
Another method for selection that seems to work quite well is to identify some of the top conferences in your field of research. You can see who are the researchers that are publishing consistently and look at the universities they are associated with. This will also give you a good idea about the strength of these places. Finally, you should also mail current grad students working at those places and find out more specific details about the places. Each of this process involves a lot of work, but unfortunately, there is no shorter alternative. Ultimately, you are looking at where you would want to spend your next five or so years. You might as well put in the effort in making sure it’s the best fit for you.<br />
World rankings are an extremely tricky topic that makes a lot of people uncomfortable. One way to interpret them is by not looking at them as an absolute number but as a range. Does the university rank in the top 5, top 15 etc. Beyond that, it is hard to distinguish various universities, because for most parts they are all similar. Also, most of the rankings lag the reality by almost 3-5 years. Also, within academia, since professors move around a lot, it is hard to assign the strength of a university with a single number. Hence, the best way is to speak to your professors and find out what is happening in the universities, who are the people currently doing good research etc. Academia is a closely-knit circle, and usually professors in your department are the experts when it comes to choosing universities. In my particular case, I am extremely thankful to Prof. Jayalal Sarma, who helped me, and three of my batch mates in choosing the right places to apply to. He spent a considerable amount of time researching about the work people are doing currently. Without that, it would have been extremely hard for us to come to a good list of places.<br />
<strong>7.  How did you identify your recos? What matters in LORs, the proximity with the referee or his stature in the research field? What is the relevance of SOPs, and how does one write ‘the perfect SOP? Does an exchange program help?How important are recos, SOPs, CGPA, GRE score, projects/internships, publications etc. in relative percentage of weightage? </strong><br />
Usually, a good recommender is someone who knows you well on a professional basis, can vouch for your skills, commitment and has particular instances he can cite in the letter. Stature in the research field is a criterion to consider, but that should come after all the above holds true. An average letter or a letter without any details, from a top-notch researcher does more harm than good. Good way to identify who are your suitable recommenders is to talk with professors whom you think you have either worked with well enough or done some quality research with and see what they feel about you. Most professors are open about their opinions and would say they would not recommend you or not recommend you well enough, if they do not have a strong opinion about you. Your internships also come in handy here. You would most likely have worked closely with researchers during that time and if they were impressed with your work, would give you strong recommendations. Also, a recommendation from a manager in the industry is not so strong as compared to a researcher in academia. Some universities explicitly place restrictions on having at most one recommendation from outside academia.<br />
Statement of Purpose is a one-and-half to two-page document explaining why you are a suitable and strong candidate for the program. It is the place where you can talk about goals, motivations and some of the technical and non-technical skills you have accumulated during your undergraduate. The best way to write a so-called ‘perfect SoP’ is to be honest about one and clearly write out one’s motivations, strengths and goals in general. You can look at SoP as an advertisement for a product. A bad advertisement is surely going to repel customers away from the product. A good SoP, would give your product the first look it deserves. But, beyond that it’s the quality of the product that ultimately decides its popularity in the market. Similarly, beyond that initial attention, it’s the other components in your application that will ultimately decide if you would be admitted.<br />
Though there is no magical formula for how admission works, but for most parts, I feel, the following ordering holds true:<br />
Letter of Recommendation &gt;top-tier publications / research experience &gt; CGPA &gt; SoP, GRE, others<br />
Since, most of academia works by word of mouth, a good recommendation from one person is more than enough to sway the decision in your favor. Similarly, one bad recommendation is enough to ensure your application being rejected.</p>
<p><strong>8.  Does work experience hold any importance, if yes, is it not advisable to work for a couple of years and then apply to Grad schools? </strong><br />
Work experience is a tricky situation to consider when considering grad school. Many people, especially in the US, come to grad school after working for a while. They seem to have a better idea about the importance of their research as opposed to many people straight out of undergrad. On the other hand, when it comes to reaching one’s full potential, most people believe the earlier you start; the more chances you have on reaching your full potential. Hence, in conclusion, there is no correct answer, and depends on a case-to-case basis. But, if you think you do not have sufficient research experience, or do not yet know if you can commit yourself fully for a PhD, working, as a research assistant is one nice option. This gives you a flavor of research and also strengthens your application to grad school. You can search for research assistant opportunities at a number of places, including IITM, IISc, etc. Here again, your professor will be your best guide who can direct you to the right people.<br />
<strong>9.  What are the research internship avenues a student can look at? Could you please share with us your list of internships/projects and also the ones you are aware about? How did it help you? When is an ideal time to apply, and how does one go about it? Are students expected to do projects in the same field of research as they are applying, as they might not have decided on their topic of interest before actually working on it? How important is a foreign research internship, and how does it weigh as compared to an industrial internship?</strong><br />
There are a number of avenues to seek research experience as an undergrad. There is no place like home; hence working on a research problem with one of your professors is a great way to step into research. There would surely be a course or two that would have excited you and you would want to explore further. Speaking up with the professor and letting him know that you are interested is a great first step.<br />
Other places for internships include programs like DAAD, MITACS, SN Bose program, etc. Most of these flyers are circulated around throughout the institute and one should definitely check these options. These programs are usually highly structured to help undergrads get a concrete problem to work on. The program usually has a number of hosts participating, who have a specific problem in mind. These are problems chosen such that, it is approachable by an undergrad, can be completed in the given timeframe of summer and possibly lead to a good publication. In many cases, students are also open to suggest the own problems they would like to work with and most researchers are open to working on those problems.<br />
Some other opportunities are research labs such as IBM, Microsoft Research, etc. For most parts, they have a similar model as to working at a university, where the host mentor has a specific problem in mind and you go ahead and work on it.<br />
Most of the application process happens between September to January before the summer. The best way to search for internships is to keep a lookout for interesting opportunities that are circulated by the department branch counselors. It is also a nice idea to talk to a professor you know and see if he has some ideas about where you could spend the summer. A “foreign” internship is not that important; what is important is you work on some research problem. Since, your ultimate goal is to see if you like research and apply with the required credentials to a good grad school, it is really important you work on research. As to where exactly you seek these opportunities is not so important. An industrial internship is not so relevant, especially if you plan to apply to grad school. With respect to computer science, most industrial internships are software engineer positions and you are expected to write code for software. They are equally challenging and fun, but they do not help prepare you for grad school.<br />
<strong>10.  Please tell us about the funding options for a Grad school? Did you apply for scholarships? Who is eligible for them? Is working part time over there a way to meet tuition fees/etc.? How much does one generally have to spend from his own pocket (savings/loans)? What is the cost of living for married research scholars, approximately?</strong><br />
Since, in the entire article I have been referring to grad school as a PhD program, almost all grad students are completely funded by the department in the form of RA, TA, department fellowship, etc. The funds given by various departments vary according to the location, cost of living, the amount of funds the department receives, etc. Nobody ever becomes rich by attending grad school, but the funding is sufficient for a comfortable living. These funding sources usually also cover the tuition and give a monthly stipend for covering living expenses.<br />
Besides, there are a number of external fellowships one has access to. I will give some details with respect to the universities in the United States. In computer science, there are fellowships such as Google PhD fellowships, Microsoft PhD fellowships, Facebook PhD fellowships,etc. that are open to international students. Though most of these fellowships are only eligible for grad students in later years of their studies. If you are a citizen of the US or a permanent resident, then you have a wider access to fellowships. One such extremely popular fellowship is the National Science Foundation Fellowship. Usually, one has to apply to this before joining grad school and no later than two years into grad school. This usually covers tuition, provides stipend for fours years of your study in the program. Hence, if you are eligible, it is a highly prestigious fellowship to apply to, irrespective of your other funding sources.<br />
All in all, funding is not a major concern for most PhD programs in Computer Science. You will not have to end up taking student loans or borrowing money from others. As far as married research scholars are concerned, its slightly more tricky, but still manageable. If both the members have some form of income, then one can easily manage with the funding available in grad school. In case, the family depends on a single source of income, it is still manageable, but one has to live a frugal life.<br />
<strong>11.  Students fear that, later, they might realize that they have no interest in the research field they have chosen, and hence hesitate to commit such a long duration of their lifetime. What do you suggest should one do/think in such a case? Also, how to choose among MS, PhD and an MS+PhD integrated program?</strong><br />
Just to clarify things upfront, in the US most schools have an MS program and a PhD program, which by default is an MS+PhD program. What this means is that you will get an MS “on the way” to your PhD. Some schools explicitly force you to finish MS requirements within a stipulated time and earn the degree while some other give you liberty till the time you finish your PhD to earn the requirements and hence the MS degree. If I am not wrong, very few schools have a PhD program where they do not give you an MS, if you choose to drop out at a later stage.<br />
It is indeed a valid concern, but that is not something to really worry about. You should be more concerned about whether or not you like doing research in general. A lot of people switch areas at various points in their career. In some sense, a PhD prepares you to work on a new area by overcoming the steep learning curve as quickly as possible. Hence, if at any stage of your PhD, you lose the spark you had for your area, you can still switch to an interesting area (as long as its not too far away from your original area) and continue research in that area. In fact, most graduate schools recommend first year PhD students to keep an open mind and explore areas before fixing upon an area. Hence, in summary, the only question is whether you wish to commit such a long time towards research or not. Do not fret too much whether you would have the sustained enthusiasm for a single topic you have in mind before joining grad school. You can always find interesting problems to work on as long as you like the process of doing research.</p>
<p>To choose between a MS and a PhD program, there are multiple criteria. Firstly, most MS programs are based on courses. Your objective is to finish a set of courses and may be a short project. On the other hand, primary purpose of a PhD is to make you an independent researcher. You do take courses, but they are just to help you supplement your research. Your focus would always be on doing good research. Hence, if one has an idea about what one would want to accomplish, then the choice to be made is almost obvious. Sometimes, people may wonder if doing a MS first would good them a better idea about if they are cut for a PhD or not. This is not true in most cases, since the primary purpose of a MS degree is different. The only way to know if you like research is to do research.<br />
<strong>12.  Did you consider the options offered in other countries, says Germany/ Australia/ Singapore/ France/ Canada? If yes, can you please discuss the pros and cons of choosing them over graduation in the ‘famous’ school in States, in terms of fees and cost of living, quality of research and education, scope of jobs after graduating from those schools and the quality of life in those countries, as you see it?</strong><br />
I didn’t apply to any schools outside the United States. Though there are some schools in Europe and Canada, for example, which are comparable to a top university at the US. It just was my personal choice to not apply to any schools there. Both in Canada and in Europe, I believe one has to first apply to a MS program, complete the requirements and only then apply to a PhD program. Unlike the US they may not offer a direct PhD program. If anything, this just increases the total time spent in MS+PhD program. Since, I didn’t go through the specifics of the universities and weigh pros and cons in greater detail at those places, I may not be able to comment much about the cost of living, quality of research etc.<br />
<strong>13.  What work do you plan to do after you finish your doctoral, and where do you see yourself after 5-10 years?</strong></p>
<p>I am still undecided about a particular career path. Broadly, it would be in the domain of a researcher, but as to whether it is in academia or in industry or elsewhere is something I do not have a clue about right now. Partly, this is because of multiple factors that affect one’s decision. For example, one of the major factors is the limited amount of positions in the job market for academia. Roughly about one in every ten of the graduating PhD student can realistically expect to find a position in academia. Other major factors include preference for teaching vs. doing only research, contributing to product research against intellectual pleasure, etc.</p>
<p>&nbsp;</p><br />  <a href="http://feeds.wordpress.com/1.0/gocomments/karthikabinav.wordpress.com/205/" rel="nofollow"><img alt="" border="0" src="http://feeds.wordpress.com/1.0/comments/karthikabinav.wordpress.com/205/" /></a> <img alt="" border="0" height="1" src="https://pixel.wp.com/b.gif?host=karthikabinav.wordpress.com&#038;blog=25175693&#038;post=205&#038;subd=karthikabinav&#038;ref=&#038;feed=1" width="1" />
    </div>
    <div class="feedEntry">

        <a href="https://karthikabinav.wordpress.com/2015/01/17/installation-of-phonegap-on-debian-system/" title="Installation of PhoneGap on Debian system">
            <h2>Installation of PhoneGap on Debian system</h2>
        </a>

        <p class="discreet">
            
                  By Django for beginners from Django community aggregator: Community blog posts.
            
            
            
                Published on <span name="publication_time">Jan 17, 2015</span>.
            
        </p>

        <p>I have recently been developing an application for IOS using <a href="http://phonegap.com/" target="_blank" title="PhoneGap Homepage">phonegap</a>. I was extremely fascinated by the simplicity of its usage. In this post, I will guide through a step-by-step procedure to setup phone gap on a Debian system.</p>
<p><strong>Setting Up PhoneGap application on a local system</strong></p>
<p>You will come across the term Cordova often when one talks about PhoneGap. Please note that for most purposes, both are essentially interchangeable. Here, I will give instructions to setup cordova on a Linux Debian system. You can make appropriate modifications for your operating system.</p>
<p>The first step is to install the latest version of cordova on your system. The installation using the Command-Line Interface is extremely straight forward.</p>
<p>1) Install NodeJS on your system from their <a href="http://nodejs.org/" target="_blank" title="Node JS">website</a>.</p>
<p>2) Run the following to install cordova</p>
<pre class="brush: plain; title: ; notranslate">
sudo npm install -g cordova
</pre>
<p>3) Once cordova is installed, now create a new project. To do that run the following command</p>
<pre class="brush: plain; title: ; notranslate">
sudo cordova create photoFilter com.photoFilter.filter photoFilter
</pre>
<p>Note: I am calling my example application as photoFilter.</p>
<p>This will create folder called photoFilter in the current directory. The important files to note here are the config.xml file and the www folder. The config.xml file is where you will mention the plugins you are going to use, the various permissions needed for the application, etc. The www folder is the root folder for your HTML, CSS and JS files. If you read the phonegap features, the key feature that lets you develop applications quickly is that you can use web technologies to create a web application. Hence, the entire development of the application will happen using HTML, CSS and JS.</p>
<p>4) We will now add the required platforms on which we wish to deploy the phonegap application on. In this example, I am going to run this application on an android device. Hence, I will just add the android platform. Note, you need to install the android SDK from the android site before performing this step. I will assume that the required SDK is installed on your system.</p>
<pre class="brush: plain; title: ; notranslate">
cd photoFilter
cordova platform add android
</pre>
<p>Note: The common error while running this command is that your Android SDK may not be set in the PATH variable. Set the appropriate paths and re-try this command. You will now have a folder called android within the platforms folder of your application.</p>
<p>You are now all set to start development of the application.</p>
<p>Sometime in the future, I will give a step-by-step guide to code the simple photoFilter application in android.</p><br />  <a href="http://feeds.wordpress.com/1.0/gocomments/karthikabinav.wordpress.com/190/" rel="nofollow"><img alt="" border="0" src="http://feeds.wordpress.com/1.0/comments/karthikabinav.wordpress.com/190/" /></a> <img alt="" border="0" height="1" src="https://pixel.wp.com/b.gif?host=karthikabinav.wordpress.com&#038;blog=25175693&#038;post=190&#038;subd=karthikabinav&#038;ref=&#038;feed=1" width="1" />
    </div>
    <div class="feedEntry">

        <a href="http://www.freehackers.org/thomas/2015/01/17/mercurial-mirror-for-django-1-8-branch/" title="Mercurial Mirror For Django 1.8 Branch">
            <h2>Mercurial Mirror For Django 1.8 Branch</h2>
        </a>

        <p class="discreet">
            
                  By Thomas Capricelli from Django community aggregator: Community blog posts.
            
            
            
                Published on <span name="publication_time">Jan 17, 2015</span>.
            
        </p>

        Another year, another alpha release for Django and &#8230; another &#8220;production&#8221; mirror for me and anybody else interested. Django has just released the first alpha for Django-1.8. As usual, I create the mirror as soon as the corresponding branch is opened (stable/1.8.x), but this is still alpha stuff for you to test, not anything stable you [&#8230;]
    </div>
    <div class="feedEntry">

        <a href="http://feedproxy.google.com/~r/Agiliq/~3/TscKD5Row0Q/" title="Importing your old comments to Disqus site">
            <h2>Importing your old comments to Disqus site</h2>
        </a>

        <p class="discreet">
            
                  By Agiliq Blog: Django web development from Django community aggregator: Community blog posts.
            
            
            
                Published on <span name="publication_time">Jan 16, 2015</span>.
            
        </p>

        <p>In one of my latest <a href="http://agiliq.com/blog/2014/11/disqus-and-disqus-sso/">blogpost</a> on disqus I covered topics on integrating Disqus to the website and disqus SSO. In this post, I will let you know how to migrate the older comments to Disqus. </p>
<p>If you sneak peek in to the alluring features of disqus you may make your mind to migrate your custom commenting system on your blog to use disqus commenting system. The threaded comments and replies, powerful moderation and admin tools, RSS options and many more features come in as battaries included with Disqus which makes the commenting more interactive and easy to deal with.</p>
<p>Let us kick start the process. Till date importing the old comments directly from the blogger and wordpress to disqus is feasible. This can be achieved by using tools and plugins that are already existing in them and its pretty straight forward. In this post our prime concern will be laid on custom XML import format. If you are using neither blogger, nor wordpress the custom XML import format which is based on the WXR (WordPress eXtended RSS) schema comes to the rescue. Disqus also supports MovableType, and IntenseDebate but preferably WXR is of more concern.</p>
<p>I consider a case in a Django project, which does adopt a custom commenting system in which the comments are stored in a postgresql database. This process of migrating the comments to disqus comprises of two steps in this case.</p>
<ol>
<li>Creating a WXR schema of the existing comments</li>
<li>Importing the WXR file to Disqus site.</li>
</ol>
<h2>1. Creating a WXR schema of the existing comments</h2>
<p>WXR format is based on the Rss specification. This format is normally used for importing or exporting data from wordpress servers. Now the aim is to create a WXR file from the existing comments in our storage. For that we are going to write a python script. Disqus has prescribed a format of the file that we are planning to import to Disqus. The format looks in the following way.</p>
<div class="highlight"><pre><span class="cp">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span>
<span class="nt">&lt;rss</span> <span class="na">version=</span><span class="s">&quot;2.0&quot;</span>
  <span class="na">xmlns:content=</span><span class="s">&quot;http://purl.org/rss/1.0/modules/content/&quot;</span>
  <span class="na">xmlns:dsq=</span><span class="s">&quot;http://www.disqus.com/&quot;</span>
  <span class="na">xmlns:dc=</span><span class="s">&quot;http://purl.org/dc/elements/1.1/&quot;</span>
  <span class="na">xmlns:wp=</span><span class="s">&quot;http://wordpress.org/export/1.0/&quot;</span>
<span class="nt">&gt;</span>
  <span class="nt">&lt;channel&gt;</span>
    <span class="nt">&lt;item&gt;</span>
      <span class="c">&lt;!-- title of article --&gt;</span>
      <span class="nt">&lt;title&gt;</span>Foo bar<span class="nt">&lt;/title&gt;</span>
      <span class="c">&lt;!-- absolute URI to article --&gt;</span>
      <span class="nt">&lt;link&gt;</span>http://foo.com/example<span class="nt">&lt;/link&gt;</span>
      <span class="c">&lt;!-- body of the page or post; use cdata; html allowed (though will be formatted to DISQUS specs) --&gt;</span>
      <span class="nt">&lt;content:encoded&gt;</span><span class="cp">&lt;![</span><span class="nx">CDATA</span><span class="err">[</span><span class="nx">Hello</span> <span class="nx">world</span><span class="cp">]]&gt;</span><span class="nt">&lt;/content:encoded&gt;</span>
      <span class="c">&lt;!-- value used within disqus_identifier; usually internal identifier of article --&gt;</span>
      <span class="nt">&lt;dsq:thread_identifier&gt;</span>disqus_identifier<span class="nt">&lt;/dsq:thread_identifier&gt;</span>
      <span class="c">&lt;!-- creation date of thread (article), in GMT. Must be YYYY-MM-DD HH:MM:SS 24-hour format. --&gt;</span>
      <span class="nt">&lt;wp:post_date_gmt&gt;</span>2010-09-20 09:13:44<span class="nt">&lt;/wp:post_date_gmt&gt;</span>
      <span class="c">&lt;!-- open/closed values are acceptable --&gt;</span>
      <span class="nt">&lt;wp:comment_status&gt;</span>open<span class="nt">&lt;/wp:comment_status&gt;</span>
      <span class="nt">&lt;wp:comment&gt;</span>
        <span class="c">&lt;!-- sso only; see docs --&gt;</span>
        <span class="nt">&lt;dsq:remote&gt;</span>
          <span class="c">&lt;!-- unique internal identifier; username, user id, etc. --&gt;</span>
          <span class="nt">&lt;dsq:id&gt;</span>user id<span class="nt">&lt;/dsq:id&gt;</span>
          <span class="c">&lt;!-- avatar --&gt;</span>
          <span class="nt">&lt;dsq:avatar&gt;</span>http://url.to/avatar.png<span class="nt">&lt;/dsq:avatar&gt;</span>
        <span class="nt">&lt;/dsq:remote&gt;</span>
        <span class="c">&lt;!-- internal id of comment --&gt;</span>
        <span class="nt">&lt;wp:comment_id&gt;</span>65<span class="nt">&lt;/wp:comment_id&gt;</span>
        <span class="c">&lt;!-- author display name --&gt;</span>
        <span class="nt">&lt;wp:comment_author&gt;</span>Foo Bar<span class="nt">&lt;/wp:comment_author&gt;</span>
        <span class="c">&lt;!-- author email address --&gt;</span>
        <span class="nt">&lt;wp:comment_author_email&gt;</span>foo@bar.com<span class="nt">&lt;/wp:comment_author_email&gt;</span>
        <span class="c">&lt;!-- author url, optional --&gt;</span>
        <span class="nt">&lt;wp:comment_author_url&gt;</span>http://www.foo.bar/<span class="nt">&lt;/wp:comment_author_url&gt;</span>
        <span class="c">&lt;!-- author ip address --&gt;</span>
        <span class="nt">&lt;wp:comment_author_IP&gt;</span>93.48.67.119<span class="nt">&lt;/wp:comment_author_IP&gt;</span>
        <span class="c">&lt;!-- comment datetime, in GMT. Must be YYYY-MM-DD HH:MM:SS 24-hour format. --&gt;</span>
        <span class="nt">&lt;wp:comment_date_gmt&gt;</span>2010-09-20 13:19:10<span class="nt">&lt;/wp:comment_date_gmt&gt;</span>
        <span class="c">&lt;!-- comment body; use cdata; html allowed (though will be formatted to DISQUS specs) --&gt;</span>
        <span class="nt">&lt;wp:comment_content&gt;</span><span class="cp">&lt;![</span><span class="nx">CDATA</span><span class="err">[</span><span class="nx">Hello</span> <span class="nx">world</span><span class="cp">]]&gt;</span><span class="nt">&lt;/wp:comment_content&gt;</span>
        <span class="c">&lt;!-- is this comment approved? 0/1 --&gt;</span>
        <span class="nt">&lt;wp:comment_approved&gt;</span>1<span class="nt">&lt;/wp:comment_approved&gt;</span>
        <span class="c">&lt;!-- parent id (match up with wp:comment_id) --&gt;</span>
        <span class="nt">&lt;wp:comment_parent&gt;</span>0<span class="nt">&lt;/wp:comment_parent&gt;</span>
      <span class="nt">&lt;/wp:comment&gt;</span>
    <span class="nt">&lt;/item&gt;</span>
  <span class="nt">&lt;/channel&gt;</span>
<span class="nt">&lt;/rss&gt;</span>
</pre></div>


<ul>
<li>Things to keep in mind:</li>
</ul>
<p>As recommended by the Disqus we need some points to keep in mind while creating a WXR file of the existing comments.</p>
<ol>
<li>Only use the "dsq:remote" tag (and its children) if you're using Single Sign-On; otherwise remove it.</li>
<li>If you're manually filling in  make sure it's unique to each user or else all comments will display the same author name.</li>
<li>Each "item" tag can parent an infinite number of "wp:comment" tags.</li>
<li>There is a minimum character requirement for each comment message, which is 3 characters.</li>
</ol>
<p>Every item is supposed to be a comment on the site. As I am not using the SSO in the site, we can remove the . The link specifies the site url to the specific post. In my case I happened to find some encoding issues with the  which does take the whole body of the post so I preferred removing it from the WXR file and it worked fine. </p>
<p>The script appears to be in the below manner. I accessed my comment model to get the comment data. And then I created the xml file in the format prescribed by Disqus. I skipped some tags which ought to mess up encryption issues. But beware, try to create as the disqus prescribes for the easy flow. The script looks like the following way.</p>
<div class="highlight"><pre><span class="nb">from</span> <span class="nx">mysite.models</span> <span class="k">import</span> <span class="nx">Comment</span>
<span class="nb">from</span> <span class="nx">django.contrib.sites.models</span> <span class="k">import</span> <span class="nx">Site</span>

<span class="n">site</span> <span class="o">=</span> <span class="nx">Site.objects.all</span><span class="p">()</span><span class="err">[</span><span class="mi">0</span><span class="cp">]</span>

comments = Comment.objects.all()
xml_data_header = &quot;&quot;&quot;<span class="cp">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span>
                <span class="nt">&lt;rss</span> <span class="na">version=</span><span class="s">&quot;2.0&quot;</span>
                  <span class="na">xmlns:content=</span><span class="s">&quot;http://purl.org/rss/1.0/modules/content/&quot;</span>
                  <span class="na">xmlns:dsq=</span><span class="s">&quot;http://www.disqus.com/&quot;</span>
                  <span class="na">xmlns:dc=</span><span class="s">&quot;http://purl.org/dc/elements/1.1/&quot;</span>
                  <span class="na">xmlns:wp=</span><span class="s">&quot;http://wordpress.org/export/1.0/&quot;</span>
                <span class="nt">&gt;</span>
                      <span class="nt">&lt;channel&gt;</span>
                  &quot;&quot;&quot;
xml_data_footer = &quot;&quot;&quot;
                      <span class="nt">&lt;/channel&gt;</span>
                    <span class="nt">&lt;/rss&gt;</span>
                  &quot;&quot;&quot;
file_dis = open('disqus.xml','wb')
file_dis.write(xml_data_header)
for comment in comments:
    xml_data_all = ''
    xml_data = &quot;&quot;&quot;
                <span class="nt">&lt;item&gt;</span>
                  <span class="nt">&lt;title&gt;</span>{0}<span class="nt">&lt;/title&gt;</span>
                  <span class="nt">&lt;link&gt;</span>http://{1}<span class="nt">&lt;/link&gt;</span>
                  <span class="nt">&lt;content:encoded&gt;</span><span class="cp">&lt;![</span><span class="nx">CDATA</span><span class="err">[</span><span class="p">{</span><span class="mi">2</span><span class="p">}</span><span class="cp">]]&gt;</span><span class="nt">&lt;/content:encoded&gt;</span>
                  <span class="nt">&lt;dsq:thread_identifier&gt;</span>{3}<span class="nt">&lt;/dsq:thread_identifier&gt;</span>
                  <span class="nt">&lt;wp:post_date_gmt&gt;</span>{4}<span class="nt">&lt;/wp:post_date_gmt&gt;</span>
                  <span class="nt">&lt;wp:comment_status&gt;</span>open<span class="nt">&lt;/wp:comment_status&gt;</span>
                  <span class="nt">&lt;wp:comment&gt;</span>
                    <span class="nt">&lt;wp:comment_id&gt;</span>{5}<span class="nt">&lt;/wp:comment_id&gt;</span>
                    <span class="nt">&lt;wp:comment_author&gt;</span>{6}<span class="nt">&lt;/wp:comment_author&gt;</span>
                    <span class="nt">&lt;wp:comment_author_email&gt;</span>{7}<span class="nt">&lt;/wp:comment_author_email&gt;</span>
                    <span class="nt">&lt;wp:comment_author_url&gt;</span>{8}<span class="nt">&lt;/wp:comment_author_url&gt;</span>
                    <span class="nt">&lt;wp:comment_author_IP&gt;</span>{9}<span class="nt">&lt;/wp:comment_author_IP&gt;</span>
                    <span class="nt">&lt;wp:comment_date_gmt&gt;</span>{10}<span class="nt">&lt;/wp:comment_date_gmt&gt;</span>
                    <span class="nt">&lt;wp:comment_content&gt;</span><span class="cp">&lt;![</span><span class="nx">CDATA</span><span class="err">[</span><span class="p">{</span><span class="mi">11</span><span class="p">}</span><span class="cp">]]&gt;</span><span class="nt">&lt;/wp:comment_content&gt;</span>
                    <span class="nt">&lt;wp:comment_approved&gt;</span>1<span class="nt">&lt;/wp:comment_approved&gt;</span>
                  <span class="nt">&lt;/wp:comment&gt;</span>
                <span class="nt">&lt;/item&gt;</span>

                &quot;&quot;&quot;.format(comment.comment_for.title.encode('utf-8'), site.domain+comment.comment_for.get_absolute_url().encode('utf-8'), comment.comment_for.text.raw.encode('utf-8'), comment.comment_for.pk, comment.comment_for.created_on, comment.pk, \
                    comment.user_name.encode('utf-8'), comment.email_id.encode('utf-8'), comment.user_ip, comment.created_on, comment.text.encode('utf-8'), \
                    )
    # xml_data_all += xml_data
    file_dis.write(xml_data)

file_dis.write(xml_data_footer)
file_dis.close()
</pre></div>


<p>Once you run the above script the resultant will be a "disqus.xml" file. An example output of the file looks like this:</p>
<div class="highlight"><pre><span class="cp">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span>
            <span class="nt">&lt;rss</span> <span class="na">version=</span><span class="s">&quot;2.0&quot;</span>
              <span class="na">xmlns:content=</span><span class="s">&quot;http://purl.org/rss/1.0/modules/content/&quot;</span>
              <span class="na">xmlns:dsq=</span><span class="s">&quot;http://www.disqus.com/&quot;</span>
              <span class="na">xmlns:dc=</span><span class="s">&quot;http://purl.org/dc/elements/1.1/&quot;</span>
              <span class="na">xmlns:wp=</span><span class="s">&quot;http://wordpress.org/export/1.0/&quot;</span>
            <span class="nt">&gt;</span>
                  <span class="nt">&lt;channel&gt;</span>                  
                    <span class="nt">&lt;item&gt;</span>
                      <span class="nt">&lt;title&gt;</span>Google Appengine - First Impressions<span class="nt">&lt;/title&gt;</span>
                      <span class="nt">&lt;link&gt;</span>http://agiliq.com/blog/2008/04/google-appengine-first-impressions/<span class="nt">&lt;/link&gt;</span>
                      <span class="nt">&lt;content:encoded&gt;</span><span class="cp">&lt;![</span><span class="nx">CDATA</span><span class="err">[</span><span class="mi">245</span><span class="cp">]]&gt;</span><span class="nt">&lt;/content:encoded&gt;</span>
                      <span class="nt">&lt;dsq:thread_identifier&gt;</span>245<span class="nt">&lt;/dsq:thread_identifier&gt;</span>
                      <span class="nt">&lt;wp:post_date_gmt&gt;</span>2008-04-09 04:02:57<span class="nt">&lt;/wp:post_date_gmt&gt;</span>
                      <span class="nt">&lt;wp:comment_status&gt;</span>open<span class="nt">&lt;/wp:comment_status&gt;</span>
                      <span class="nt">&lt;wp:comment&gt;</span>
                        <span class="nt">&lt;wp:comment_id&gt;</span>482<span class="nt">&lt;/wp:comment_id&gt;</span>
                        <span class="nt">&lt;wp:comment_author&gt;</span>Ivan<span class="nt">&lt;/wp:comment_author&gt;</span>
                        <span class="nt">&lt;wp:comment_author_email&gt;</span>suchy.ivan@gmail.com<span class="nt">&lt;/wp:comment_author_email&gt;</span>
                        <span class="nt">&lt;wp:comment_author_url&gt;&lt;/wp:comment_author_url&gt;</span>
                        <span class="nt">&lt;wp:comment_author_IP&gt;</span>None<span class="nt">&lt;/wp:comment_author_IP&gt;</span>
                        <span class="nt">&lt;wp:comment_date_gmt&gt;</span>2008-04-09 08:48:53<span class="nt">&lt;/wp:comment_date_gmt&gt;</span>
                        <span class="nt">&lt;wp:comment_content&gt;</span><span class="cp">&lt;![</span><span class="nx">CDATA</span><span class="err">[</span><span class="o">&lt;</span><span class="nx">p</span><span class="o">&gt;</span><span class="k">On</span> <span class="nx">dev</span> <span class="nx">server</span> <span class="kd">data</span> <span class="nx">is</span> <span class="n">stored</span> <span class="k">in</span> <span class="p">/</span><span class="nx">tmp</span> <span class="nx">folder</span><span class="o">&lt;/</span><span class="nx">p</span><span class="o">&gt;</span><span class="cp">]]&gt;</span><span class="nt">&lt;/wp:comment_content&gt;</span>
                        <span class="nt">&lt;wp:comment_approved&gt;</span>1<span class="nt">&lt;/wp:comment_approved&gt;</span>
                      <span class="nt">&lt;/wp:comment&gt;</span>
                    <span class="nt">&lt;/item&gt;</span>

                     <span class="nt">&lt;/channel&gt;</span>
            <span class="nt">&lt;/rss&gt;</span>
</pre></div>


<p>Once we are done with creating the WXR schema we should import it to the disqus site.</p>
<p>2.Importing the WXR file to Disqus site.</p>
<p>To attain the second part you need to have a disqus account and a disqus site available for you. You can get to know more about creating a disqus site in the linked <a href="http://agiliq.com/blog/2014/11/disqus-and-disqus-sso/">blogpost</a> </p>
<p>Once you are done with the creation of disqus site go to the settings which can be accessible on admin panel. There appears the settings page, click on the discussion on the right top panel. Click "import" tab and there appears the different types of import formats that disqus supports. Select generic(WXR) and click on browse. Upload the disqus.xml file and once the process get completed it shows up if there are any errors in the uploaded file. If there are any errors, the process of importing comments will be kept on hold. If the comments are successfully imported it takes some time to get those comments reflected in your site.</p>
<p>TIP: The best practice would be to try importing in to test disqus site and once it works perfectly, move towards importing them to the main site.</p>
    </div>
    <div class="feedEntry">

        <a href="http://blog.isotoma.com/2015/01/ssl-broken-in-gevent-on-python-2-7-9-a-debugging-tale-of-woe/" title="SSL broken in gevent on Python 2.7.9 – a debugging tale of woe">
            <h2>SSL broken in gevent on Python 2.7.9 – a debugging tale of woe</h2>
        </a>

        <p class="discreet">
            
                  By Isotoma Blog from Django community aggregator: Community blog posts.
            
            
            
                Published on <span name="publication_time">Jan 14, 2015</span>.
            
        </p>

        <p>I thought it would be worth writing this up quickly as a blog post, just so it&#8217;s documented, though I&#8217;m guessing the bug is common knowledge by now. The process of finding out the issue was (eventually) enlightening for me though, especially how far the initial problem was from the bug.</p>
<p>I was having problems last week deploying changes to one of our projects hosted on <a href="http://www.heroku.com">Heroku</a>. I&#8217;d done a full run-down of dependencies trying to bring in security and bug fixes, making everything python 2.7 and Trusty compatible (or, for Heroku, cedar-14 stack compatible). Everything worked fine locally, even using <code>foreman</code> (which is the heroku tool that runs your code as if it was deployed on Heroku &#8211; in this case running through gunicorn with gevent). However, on deploying to a clean app and database on Heroku, the <a href="https://www.mozilla.org/en-US/persona/">Persona Single-Sign-On</a> authentication wasn&#8217;t working. The project&#8217;s settings are slightly involved, but the fact the admin site was working and the fact I was getting a login at all indicated that things were probably okay on the Django side of things. Persona itself worked fine locally, and on stage and production deployments on Heroku. I suspected DNS issues, but this turned out not to be the case, and site domains and urls were being resolved correctly.</p>
<p>The only difference I could see between my new app and the stage deployment (that was working) was the database version (I&#8217;d deliberately matched the PostgreSQL version on my new app to that used in production, while staging was a point release ahead, for some reason) and the build stack that Heroku was using (part of what I was doing was testing the <a href="https://devcenter.heroku.com/articles/stack">cedar-14 stack</a>, which is based on trusty and supports python 2.7.9). The customer was keen on having a test instance, so I decided to deploy on staging instead, but with an updated stack. I provisioned a new database to match production (and with production data), and used the cedar-14 stack, and everything worked fine (well apart from the bugs in my pre-christmas development changes, but that was why I needed a test deployment for them to look at).</p>
<p>So there was something iffy in the test Heroku deployment I had. Off I set trying to debug a live Heroku deployment. Now after this experience, I must say I am in the market for decent logging/debugging tools for Heroku, so any suggestions are welcome. Papertrail, I found to be almost useless in this scenario, so was reduced to using django logging and running &#8220;<code>heroku logs --app &lt;app_name&gt;</code>&#8221; to see the output. So basically, <code>print</code> statement debugging, urgh. This was thwarted temporarily by a Heroku outage last night where they put all apps into maintenance mode, preventing build updates. Eventually I worked out that while the Persona authentication was working ok, the authentication on the Django side was failing (using an old version of <a href="https://github.com/mozilla/django-browserid/tree/v0.7.1">django-browserid</a>). However, nothing was blowing up or throwing errors, the authentication was just failing.</p>
<p>Being unable to directly inject debugging into a 3rd party library, I decided to call the deeper API directly, and immediately I got a 500 error, and a stack trace &#8211; the definition of some internal SSL calls had changed in python 2.7.9, and gevent was relying on them: reported here <a href="http://bugs.python.org/issue22438">http://bugs.python.org/issue22438</a>. So technically not a python bug, but it basically blew up SSL URL querying when running in gunicorn + gevent. Which caused my authentication issue, as NetPositive doesn&#8217;t run over SSL, but Persona verification does. This was not initially causing 500 errors, as it was raising a <code>TypeError</code> in an authentication backend, so Django was then just falling back to the default authentication, failing and returning no user found.</p>
<p>So, bug found, and my current work-around is to stick to a Python 2.7.8 runtime (technically unsupported by Heroku), until either gevent or Python is updated. But why did I not see the issue on staging or locally using <code>foreman</code>? The Heroku stack on staging turned out to be using Python 2.7.4, and locally my virtualenv was running Python 2.7.3.</p>
<p>So &#8211; a few lessons I suppose. One, make sure you include Python runtime in your list of dependencies to check and versions to match on Development vs. Staging vs. Production. Two, that sometimes underlying components silently riding over errors can mask the true source of odd behaviour (I really should have twigged about the authentication backends, but also custom backends should deal with <code>TypeErrors</code> from internal calls properly). Three, logging is super-useful, I should probably use it more, and in a smarter way. Four, I would love a decent debugging tool for Heroku. Five, don&#8217;t rely on underscore methods in Python internal libraries *<em>stares daggers at the gevent developers</em>*.</p>
<p>If you weren&#8217;t aware of this bug, watch out for it!</p>
<p><strong>Update</strong>: According to comments on the <a href="https://github.com/gevent/gevent/issues/477">gevent issue on github</a>, this might be an issue on Amazon even with Python 2.7.8 as they have backported the SSL code from 2.7.9 to their 2.7 runtimes on AWS. This emphasises the need to be aware of what Python runtimes are being deployed on cloud services, where debugging may be more difficult.</p>
    </div>
    <div class="feedEntry">

        <a href="http://reinout.vanrees.org/weblog/2015/01/14/updated-black-screen-macbook-instructions.html" title="Updated instructions to fix macbook pro with black screen">
            <h2>Updated instructions to fix macbook pro with black screen</h2>
        </a>

        <p class="discreet">
            
                  By Reinout van Rees' weblog from Django community aggregator: Community blog posts.
            
            
            
                Published on <span name="publication_time">Jan 13, 2015</span>.
            
        </p>

        <div class="document">
<p>Last week <a class="reference external" href="http://reinout.vanrees.org/weblog/2015/01/06/macbook-pro-black-screen.html">I wrote about my macbook pro</a>
and its screen that suddenly stayed black after waking it from
sleep. Including instructions on how to fix it. I now have improved
instructions...</p>
<p><strong>The piece of crap did it again</strong>. (This time there was no external monitor
in play, btw)</p>
<p>Symptoms: you open up your late 2014 macbook pro 15&quot; and expect it to wake
from sleep in 0.5 seconds. Instead the screen stays black.</p>
<ul class="simple">
<li>Press <strong>shift-option-control-power</strong> and release them all at the same time. This
resets the &quot;system management controller&quot;, amongst others it makes sure the
&quot;power&quot; button actually reacts.</li>
<li>Now look at the back of your mac's screen. Make sure the light of the apple
logo is off. If necessary, keep the power button pressed for 5 seconds to
force a shutdown. (The power button should work again after step 1).</li>
<li>Keep your fingers ready for pressing <strong>command-option-p-r</strong> at the same
time. You need both hands for this weird combination. Press the power button
and then hold these four keys. Your mac will now actually boot, give you the
startup sound and lo and behold, you've got your screen back.</li>
</ul>
<p>I do hope apple will fix this Real Soon. I suspect a software bug. I hope it
isn't a hardware one. It was a hardware bug (wrong solder being used for the
video card connection) that brought down my previous macbook after four
years... Apples are great machines for programming (python) and I'm in love
with the retina display, but...</p>
</div>
    </div>
    <div class="feedEntry">

        <a href="http://reinout.vanrees.org/weblog/2015/01/14/actually-doing-work.html" title="Actually doing work - proof by blogging">
            <h2>Actually doing work - proof by blogging</h2>
        </a>

        <p class="discreet">
            
                  By Reinout van Rees' weblog from Django community aggregator: Community blog posts.
            
            
            
                Published on <span name="publication_time">Jan 13, 2015</span>.
            
        </p>

        <div class="document">
<p>I'm a programmer. Which means it is not always clear when I'm working. What I
mean is that, if I'm sitting behind my screen, I might be reading an article
about postgres performance improvements, but I might also be reading the
news. And clicking on my ipad might mean I'm keeping my python knowledge up to
date by reading weblogs, but I might also be reading some comics. Typing
furiously on my keyboard might indicate great productivity, but it also might
indicate a long personal email.</p>
<p>The other way around, sitting nicely in the living room at home, clicking away
on the laptop, might mean I'm relaxing by writing an <a class="reference external" href="http://forum.beneluxspoor.net/index.php/topic,60917.0.html">update on my model
railway work</a> on
a forum, but it might also mean I'm finishing off a work project in my own
time.</p>
<p>&quot;Doing research&quot; is a potential problem for me. I've spend a ton of time
reading about <a class="reference external" href="http://docs.ansible.com/">Ansible</a> and on how to use it. But
it was only when I actually started <strong>doing something with it</strong> that I started
to wrap my head around it. So... just reading and thinking is dangerous to my
productivity.</p>
<p>I <strong>want</strong> to be productive.</p>
<p>One of the simplest tricks I can use is <strong>to blog about it</strong>. Thinking about
something for two days is fine, but I should at least get a blog entry out of
it. Writing forces me to think things through. It focuses my thinking.</p>
<p>If I don't blog for a full week, I'm probably not hard at work programming:
otherwise I'd have encountered some dreadful mistake I made or some horrible
bug, all of which are blog-worthy. Or I've started thinking too much about
something without taking a higher-level view after a few days (again,
resulting in a blog entry).</p>
<p>So... I'll prove I'm working by blogging about it :-)</p>
</div>
    </div>
    <div class="feedEntry">

        <a href="http://reinout.vanrees.org/weblog/2015/01/14/variabledoesnotexist-haystack-search.html" title="VariableDoesNotExist: Failed lookup for key [text] in 'None'">
            <h2>VariableDoesNotExist: Failed lookup for key [text] in 'None'</h2>
        </a>

        <p class="discreet">
            
                  By Reinout van Rees' weblog from Django community aggregator: Community blog posts.
            
            
            
                Published on <span name="publication_time">Jan 13, 2015</span>.
            
        </p>

        <div class="document">
<p><tt class="docutils literal">VariableDoesNotExist: Failed lookup for key [text] in 'None'</tt>, that was the
error that I got out of an internal django app that I wrote. The app is the
most error-free one that I ever build, so I was quite surprised.</p>
<p>I was even more surprised when I started debugging it. The error was in the
search functionality. Searching for &quot;lizard&quot; would give an &quot;error
500&quot; page. Searching for &quot;lizar&quot; gave 0 results (which is fine), for
&quot;lizardd&quot;, too. &quot;lidard&quot; also gave 0 results. Only a search for &quot;lizard&quot;
crashed the site.</p>
<p>Huh? Weird. I got the question whether I put a hidden message into this app
(as &quot;lizard&quot; is one of our main products) :-)</p>
<p>Locally it all worked fine, of course. Only on the server did I see the error.</p>
<p>Here's the relevant part of the traceback:</p>
<pre class="literal-block">
Stacktrace (most recent call last):
File &quot;django/core/handlers/base.py&quot;, line 112, in get_response
  response = wrapped_callback(request, *callback_args, **callback_kwargs)
File &quot;haystack/views.py&quot;, line 50, in __call__
  return self.create_response()
File &quot;haystack/views.py&quot;, line 144, in create_response
  return render_to_response(self.template, context, context_instance=self.context_class(self.request))
File &quot;django/shortcuts/__init__.py&quot;, line 29, in render_to_response
  return HttpResponse(loader.render_to_string(*args, **kwargs), **httpresponse_kwargs)
File &quot;django/template/loader.py&quot;, line 169, in render_to_string
  return t.render(context_instance)
File &quot;django/template/base.py&quot;, line 140, in render
  return self._render(context)
...
File &quot;django/template/base.py&quot;, line 840, in render
  bit = self.render_node(node, context)
File &quot;django/template/debug.py&quot;, line 78, in render_node
  return node.render(context)
File &quot;django/template/defaulttags.py&quot;, line 196, in render
  nodelist.append(node.render(context))
File &quot;haystack/templatetags/highlight.py&quot;, line 30, in render
  text_block = self.text_block.resolve(context)
File &quot;django/template/base.py&quot;, line 735, in resolve
  value = self._resolve_lookup(context)
File &quot;django/template/base.py&quot;, line 781, in _resolve_lookup
  (bit, current))  # missing attribute
</pre>
<p>Eventually I found it. Via <a class="reference external" href="https://groups.google.com/forum/#!topic/django-haystack/0gjqYHb05u8">this django-haystack post</a>. Haystack,
which I use for searching, <strong>by default doesn't deal with deleted
objects</strong>. And, of course, yesterday I removed an object via the admin
interface. A project with &quot;lizard&quot; in the title. Normally nothing is removed
in this app, so the problem didn't surface earlier.</p>
<p>Haystack's results include the deleted now-non-existing object, which crashes
the template. Which is a little bit weird, as normally django's template layer
is quite forgiving about <tt class="docutils literal">None</tt>. It might be the <tt class="docutils literal">{% highlight %}</tt>
templatetag that I'm using.</p>
<p>Anyway, the solution is to run the <tt class="docutils literal">update_index</tt> command with the
<tt class="docutils literal"><span class="pre">--remove</span></tt> option. Or run <tt class="docutils literal">rebuild_index</tt>. The second replaces the index,
but is quicker. The first takes more resources, but leaves the index in
place. Take whatever fits your usecase best.</p>
</div>
    </div>
    <div class="feedEntry">

        <a href="http://plope.com/is_open_source_consulting_dead" title="Is Open Source Consulting Dead?">
            <h2>Is Open Source Consulting Dead?</h2>
        </a>

        <p class="discreet">
            
                  By chrism from plope.
            
            
            
                Published on <span name="publication_time">Sep 10, 2013</span>.
            
        </p>

        Has Elvis left the building?  Will we be able to sustain ourselves as open source consultants?
    </div>
    <div class="feedEntry">

        <a href="http://plope.com/consulting_and_patent_indemnification" title="Consulting and Patent Indemification">
            <h2>Consulting and Patent Indemification</h2>
        </a>

        <p class="discreet">
            
                  By chrism from plope.
            
            
            
                Published on <span name="publication_time">Aug 09, 2013</span>.
            
        </p>

        Article about consulting and patent indemnification
    </div>
    <div class="feedEntry">

        <a href="http://plope.com/Members/chrism/python_advent_2012" title="Python Advent Calendar 2012 Topic">
            <h2>Python Advent Calendar 2012 Topic</h2>
        </a>

        <p class="discreet">
            
                  By chrism from plope.
            
            
            
                Published on <span name="publication_time">Dec 24, 2012</span>.
            
        </p>

        An entry for the 2012 Japanese advent calendar at http://connpass.com/event/1439/
    </div>
    <div class="feedEntry">

        <a href="http://plope.com/Members/chrism/why_i_like_zodb" title="Why I Like ZODB">
            <h2>Why I Like ZODB</h2>
        </a>

        <p class="discreet">
            
                  By chrism from plope.
            
            
            
                Published on <span name="publication_time">May 15, 2012</span>.
            
        </p>

        Why I like ZODB better than other persistence systems for writing real-world web applications.
    </div>
    <div class="feedEntry">

        <a href="http://plope.com/Members/chrism/python_2_vs_python_3_str_iter" title="A str. __iter__ Gotcha in Cross-Compatible Py2/Py3 Code">
            <h2>A str. __iter__ Gotcha in Cross-Compatible Py2/Py3 Code</h2>
        </a>

        <p class="discreet">
            
                  By chrism from plope.
            
            
            
                Published on <span name="publication_time">Mar 03, 2012</span>.
            
        </p>

        A bug caused by a minor incompatibility can remain latent for long periods of time in a cross-compatible Python 2 / Python 3 codebase.
    </div>
    <div class="feedEntry">

        <a href="http://plope.com/Members/chrism/in_praise_of_complaining" title="In Praise of Complaining">
            <h2>In Praise of Complaining</h2>
        </a>

        <p class="discreet">
            
                  By chrism from plope.
            
            
            
                Published on <span name="publication_time">Jan 01, 2012</span>.
            
        </p>

        In praise of complaining, even when the complaints are absurd.
    </div>
    <div class="feedEntry">

        <a href="http://plope.com/Members/chrism/2012_python_meme" title="2012 Python Meme">
            <h2>2012 Python Meme</h2>
        </a>

        <p class="discreet">
            
                  By chrism from plope.
            
            
            
                Published on <span name="publication_time">Dec 24, 2011</span>.
            
        </p>

        My "Python meme" replies.
    </div>
    <div class="feedEntry">

        <a href="http://plope.com/Members/chrism/in_defense_of_zope_libraries" title="In Defense of Zope Libraries">
            <h2>In Defense of Zope Libraries</h2>
        </a>

        <p class="discreet">
            
                  By chrism from plope.
            
            
            
                Published on <span name="publication_time">Dec 19, 2011</span>.
            
        </p>

        A much too long defense of Pyramid's use of Zope libraries.
    </div>
    <div class="feedEntry">

        <a href="http://plope.com/Members/chrism/ploneconf_2011_pyramid_sprint" title="Plone Conference 2011 Pyramid Sprint">
            <h2>Plone Conference 2011 Pyramid Sprint</h2>
        </a>

        <p class="discreet">
            
                  By chrism from plope.
            
            
            
                Published on <span name="publication_time">Nov 10, 2011</span>.
            
        </p>

        An update about the happenings at the recent 2011 Plone Conference Pyramid sprint.
    </div>
    <div class="feedEntry">

        <a href="http://plope.com/Members/chrism/oss_jobsification" title="Jobs-Ification of Software Development">
            <h2>Jobs-Ification of Software Development</h2>
        </a>

        <p class="discreet">
            
                  By chrism from plope.
            
            
            
                Published on <span name="publication_time">Oct 17, 2011</span>.
            
        </p>

        Try not to Jobs-ify the task of software development.
    </div>
    <div class="feedEntry">

        <a href="http://plope.com/Members/chrism/webob_py3" title="WebOb Now on Python 3">
            <h2>WebOb Now on Python 3</h2>
        </a>

        <p class="discreet">
            
                  By chrism from plope.
            
            
            
                Published on <span name="publication_time">Oct 15, 2011</span>.
            
        </p>

        Report about porting to Python 3.
    </div>
    <div class="feedEntry">

        <a href="http://plope.com/Members/chrism/oss_sarcasm" title="Open Source Project Maintainer Sarcastic Response Cheat Sheet">
            <h2>Open Source Project Maintainer Sarcastic Response Cheat Sheet</h2>
        </a>

        <p class="discreet">
            
                  By chrism from plope.
            
            
            
                Published on <span name="publication_time">Jun 12, 2011</span>.
            
        </p>

        Need a sarcastic response to a support interaction as an open source project maintainer?  Look no further!
    </div>
    <div class="feedEntry">

        <a href="http://plope.com/Members/chrism/minicon0_wrapup" title="Pylons Miniconference #0 Wrapup">
            <h2>Pylons Miniconference #0 Wrapup</h2>
        </a>

        <p class="discreet">
            
                  By chrism from plope.
            
            
            
                Published on <span name="publication_time">May 04, 2011</span>.
            
        </p>

        Last week, I visited the lovely Bay Area to attend the 0th Pylons
Miniconference in San Francisco.
    </div>
    <div class="feedEntry">

        <a href="http://plope.com/Members/chrism/pylons_project_minicon" title="Pylons Project Meetup / Minicon">
            <h2>Pylons Project Meetup / Minicon</h2>
        </a>

        <p class="discreet">
            
                  By chrism from plope.
            
            
            
                Published on <span name="publication_time">Apr 14, 2011</span>.
            
        </p>

        In the SF Bay Area on the 28th, 29th, and 30th of this month (April), 3 separate Pylons Project events.
    </div>
    <div class="feedEntry">

        <a href="http://plope.com/Members/chrism/pycon_2011" title="PyCon 2011 Report">
            <h2>PyCon 2011 Report</h2>
        </a>

        <p class="discreet">
            
                  By chrism from plope.
            
            
            
                Published on <span name="publication_time">Mar 19, 2011</span>.
            
        </p>

        My personal PyCon 2011 Report
    </div>

    

    <div class="visualClear"><!-- --></div>

    <div class="documentActions">
        

        

    </div>


                        </div>
                    

                    
                </div>
            

            <div id="viewlet-below-content">

<div id="portlets-below" class="row">
     
         
             <div class="cell BelowPortletManager2 width-1:2 position-0">


<div id="portletwrapper-436f6e74656e7457656c6c506f72746c6574732e42656c6f77506f72746c65744d616e61676572320a636f6e746578740a2f506c6f6e652f636f7665720a6c61746573742d706c6f6e652d706f737473" class="portletWrapper kssattr-portlethash-436f6e74656e7457656c6c506f72746c6574732e42656c6f77506f72746c65744d616e61676572320a636f6e746578740a2f506c6f6e652f636f7665720a6c61746573742d706c6f6e652d706f737473"><dl class="portlet portletfeedmixer">

    <dt class="portletHeader">
        <span class="portletTopLeft"></span>
        <span>Latest Plone Posts</span>
        <span class="portletTopRight"></span>
    </dt>

    
        <dd class="portletItem odd">

            <a href="http://feeds.plone.org/~r/ploneblogs/~3/G_zk4WxCnug/" title="Adding SCORM packages to Open edX via SCORMCloud and LTI">
                Adding SCORM packages to Open edX via SCORMCloud and LTI
                <span class="portletItemDetails">Feb 15, 2015</span>
            </a>
        </dd>
    
    
        <dd class="portletItem even">

            <a href="http://feeds.plone.org/~r/ploneblogs/~3/GY4DAohvyYo/customizing-javascript-pattern-options-in-plone-5" title="Customizing JavaScript pattern settings in Plone 5">
                Customizing JavaScript pattern settings in Plone 5
                <span class="portletItemDetails">Feb 14, 2015</span>
            </a>
        </dd>
    
    
        <dd class="portletItem odd">

            <a href="http://feeds.plone.org/~r/ploneblogs/~3/La5UfDFslGk/magic-templates-in-plone-5" title="Magic templates in Plone 5">
                Magic templates in Plone 5
                <span class="portletItemDetails">Feb 13, 2015</span>
            </a>
        </dd>
    
    
        <dd class="portletItem even">

            <a href="http://feeds.plone.org/~r/ploneblogs/~3/e22wNVd3xM4/the-7th-annual-great-backyard-plone.html" title="The 7th Annual Great Backyard Plone Count">
                The 7th Annual Great Backyard Plone Count
                <span class="portletItemDetails">Feb 12, 2015</span>
            </a>
        </dd>
    
    
        <dd class="portletItem odd">

            <a href="http://feeds.plone.org/~r/ploneblogs/~3/cp_XmtxsCZE/displaying-easyslideshow-on-your-homepage-with-diazo" title="Displaying EasySlideshow on your Homepage with Diazo">
                Displaying EasySlideshow on your Homepage with Diazo
                <span class="portletItemDetails">Feb 12, 2015</span>
            </a>
        </dd>
    
    
    <dd class="portletFooter">
      <a href="http://crisewing.com/cover/++contextportlets++ContentWellPortlets.BelowPortletManager2/latest-plone-posts/full_feed" class="tile">More&hellip;</a>
        <span class="portletBottomLeft"></span>
        <span class="portletBottomRight"></span>
    </dd>

</dl>
</div>

</div> 

         
         
             <div class="cell BelowPortletManager3 width-1:2 position-1:2">


<div id="portletwrapper-436f6e74656e7457656c6c506f72746c6574732e42656c6f77506f72746c65744d616e61676572330a636f6e746578740a2f506c6f6e652f636f7665720a6f70656e2d736f757263652d706f737473" class="portletWrapper kssattr-portlethash-436f6e74656e7457656c6c506f72746c6574732e42656c6f77506f72746c65744d616e61676572330a636f6e746578740a2f506c6f6e652f636f7665720a6f70656e2d736f757263652d706f737473"><dl class="portlet portletfeedmixer">

    <dt class="portletHeader">
        <span class="portletTopLeft"></span>
        <span>Open Source Posts</span>
        <span class="portletTopRight"></span>
    </dt>

    
        <dd class="portletItem odd">

            <a href="http://adpgtech.blogspot.com/2015/02/i-feel-so-proud.html" title="Andrew Dunstan: I feel so proud :-)">
                Andrew Dunstan: I feel so proud :-)
                <span class="portletItemDetails">Feb 16, 2015</span>
            </a>
        </dd>
    
    
        <dd class="portletItem even">

            <a href="http://blog.taadeem.net///english/2015/02/16/Introducing_PostgreSQL_Dashboard" title="damien clochard: Introducing PostgreSQL Dashboard">
                damien clochard: Introducing PostgreSQL Dashboard
                <span class="portletItemDetails">Feb 16, 2015</span>
            </a>
        </dd>
    
    
        <dd class="portletItem odd">

            <a href="http://www.databasesoup.com/2015/02/running-with-scissors-mode.html" title="Josh Berkus: Running with scissors mode">
                Josh Berkus: Running with scissors mode
                <span class="portletItemDetails">Feb 15, 2015</span>
            </a>
        </dd>
    
    
        <dd class="portletItem even">

            <a href="http://willmcgugan.com/blog/tech/2015/2/15/a-method-for-rendering-templates-with-python/" title="A method for rendering templates with Python">
                A method for rendering templates with Python
                <span class="portletItemDetails">Feb 15, 2015</span>
            </a>
        </dd>
    
    
        <dd class="portletItem odd">

            <a href="http://feedproxy.google.com/~r/no0p/~3/sy3Oy8JjBhQ/artisanal-stopwords.html" title="robert berry: Artisanal Stop Words">
                robert berry: Artisanal Stop Words
                <span class="portletItemDetails">Feb 14, 2015</span>
            </a>
        </dd>
    
    
    <dd class="portletFooter">
      <a href="http://crisewing.com/cover/++contextportlets++ContentWellPortlets.BelowPortletManager3/open-source-posts/full_feed" class="tile">More&hellip;</a>
        <span class="portletBottomLeft"></span>
        <span class="portletBottomRight"></span>
    </dd>

</dl>
</div>

</div> 

         
     
</div>


</div>
        </div>

        
        

        
        
    </div>


    <div class="row">
        <div id="portlets-footer" class="row">
     
     
</div>



<div class="row">
    <div class="cell width-full position-0">
        <div id="portal-footer">
          <a id="license-img" rel="license" href="http://creativecommons.org/licenses/by-nc-sa/3.0/">
            <img alt="Creative Commons License" style="border-width:0" src="http://i.creativecommons.org/l/by-nc-sa/3.0/88x31.png" />
          </a>
          <p>
            This site and its content is licensed under a
            <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/3.0/">Creative
              Commons Attribution-NonCommercial-ShareAlike 3.0 Unported License</a>, 
              2011&mdash;2015
          </p>
          <div class="visualClear"><!-- clear floats --></div>
        </div>

    </div>
</div>
<div id="portal-colophon">

<div class="colophonWrapper">
<ul>
  <li>
    <a href="http://plone.org" title="This site was built using the Plone Open Source CMS/WCM.">
      Powered by Plone &amp; Python</a>
  </li>
</ul>
</div>
</div>

<ul id="portal-siteactions">

    <li id="siteaction-sitemap"><a href="http://crisewing.com/sitemap" accesskey="3" title="Site Map">Site Map</a></li>
    <li id="siteaction-accessibility"><a href="http://crisewing.com/accessibility-info" accesskey="0" title="Accessibility">Accessibility</a></li>
    <li id="siteaction-contact"><a href="http://crisewing.com/about/contact" accesskey="9" title="Contact">Contact</a></li>
</ul>

<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-22486368-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>
        <div id="kss-spinner">
            <img alt="" src="http://crisewing.com/spinner.gif" />
        </div>
    </div>

</div>
</body>
</html>



